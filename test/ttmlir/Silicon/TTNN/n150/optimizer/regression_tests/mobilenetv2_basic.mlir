// REQUIRES: opmodel, regression
// RUN: ttmlir-opt --ttir-to-ttnn-backend-pipeline="system-desc-path=%system_desc_path% enable-optimizer=true memory-layout-analysis-enabled=false enable-fusing-pass=true" -o mobilenetv2_basic_ttnn.mlir %s
// RUN: ttmlir-translate --ttnn-to-flatbuffer mobilenetv2_basic_ttnn.mlir > %t.ttnn
#loc = loc("MobileNetv2Basic":0:0)
module @MobileNetv2Basic {
  func.func @forward(%arg0: tensor<8x3x224x224xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "input_1"} loc("MobileNetv2Basic":0:0), %arg1: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3"} loc("MobileNetv2Basic":0:0), %arg2: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3_fork_clone1205"} loc("MobileNetv2Basic":0:0), %arg3: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_19"} loc("MobileNetv2Basic":0:0), %arg4: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_19_fork_clone1183"} loc("MobileNetv2Basic":0:0), %arg5: tensor<1x16x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_34"} loc("MobileNetv2Basic":0:0), %arg6: tensor<1x16x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_34_fork_clone1155"} loc("MobileNetv2Basic":0:0), %arg7: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_48"} loc("MobileNetv2Basic":0:0), %arg8: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_48_fork_clone1123"} loc("MobileNetv2Basic":0:0), %arg9: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_64"} loc("MobileNetv2Basic":0:0), %arg10: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_64_fork_clone1076"} loc("MobileNetv2Basic":0:0), %arg11: tensor<1x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_79"} loc("MobileNetv2Basic":0:0), %arg12: tensor<1x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_79_fork_clone1029"} loc("MobileNetv2Basic":0:0), %arg13: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_93"} loc("MobileNetv2Basic":0:0), %arg14: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_93_fork_clone1128"} loc("MobileNetv2Basic":0:0), %arg15: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_109"} loc("MobileNetv2Basic":0:0), %arg16: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_109_fork_clone1083"} loc("MobileNetv2Basic":0:0), %arg17: tensor<1x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_124"} loc("MobileNetv2Basic":0:0), %arg18: tensor<1x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_124_fork_clone1033"} loc("MobileNetv2Basic":0:0), %arg19: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_139"} loc("MobileNetv2Basic":0:0), %arg20: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_139_fork_clone974"} loc("MobileNetv2Basic":0:0), %arg21: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_155"} loc("MobileNetv2Basic":0:0), %arg22: tensor<1x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_155_fork_clone906"} loc("MobileNetv2Basic":0:0), %arg23: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_170"} loc("MobileNetv2Basic":0:0), %arg24: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_170_fork_clone839"} loc("MobileNetv2Basic":0:0), %arg25: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_184"} loc("MobileNetv2Basic":0:0), %arg26: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_184_fork_clone979"} loc("MobileNetv2Basic":0:0), %arg27: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_200"} loc("MobileNetv2Basic":0:0), %arg28: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_200_fork_clone913"} loc("MobileNetv2Basic":0:0), %arg29: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_215"} loc("MobileNetv2Basic":0:0), %arg30: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_215_fork_clone843"} loc("MobileNetv2Basic":0:0), %arg31: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_230"} loc("MobileNetv2Basic":0:0), %arg32: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_230_fork_clone967"} loc("MobileNetv2Basic":0:0), %arg33: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_246"} loc("MobileNetv2Basic":0:0), %arg34: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_246_fork_clone899"} loc("MobileNetv2Basic":0:0), %arg35: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_261"} loc("MobileNetv2Basic":0:0), %arg36: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_261_fork_clone831"} loc("MobileNetv2Basic":0:0), %arg37: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_276"} loc("MobileNetv2Basic":0:0), %arg38: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_276_fork_clone758"} loc("MobileNetv2Basic":0:0), %arg39: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_292"} loc("MobileNetv2Basic":0:0), %arg40: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_292_fork_clone671"} loc("MobileNetv2Basic":0:0), %arg41: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_307"} loc("MobileNetv2Basic":0:0), %arg42: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_307_fork_clone580"} loc("MobileNetv2Basic":0:0), %arg43: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_321"} loc("MobileNetv2Basic":0:0), %arg44: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_321_fork_clone763"} loc("MobileNetv2Basic":0:0), %arg45: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_337"} loc("MobileNetv2Basic":0:0), %arg46: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_337_fork_clone678"} loc("MobileNetv2Basic":0:0), %arg47: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_352"} loc("MobileNetv2Basic":0:0), %arg48: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_352_fork_clone584"} loc("MobileNetv2Basic":0:0), %arg49: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_367"} loc("MobileNetv2Basic":0:0), %arg50: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_367_fork_clone748"} loc("MobileNetv2Basic":0:0), %arg51: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_383"} loc("MobileNetv2Basic":0:0), %arg52: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_383_fork_clone659"} loc("MobileNetv2Basic":0:0), %arg53: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_398"} loc("MobileNetv2Basic":0:0), %arg54: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_398_fork_clone571"} loc("MobileNetv2Basic":0:0), %arg55: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_413"} loc("MobileNetv2Basic":0:0), %arg56: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_413_fork_clone734"} loc("MobileNetv2Basic":0:0), %arg57: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_429"} loc("MobileNetv2Basic":0:0), %arg58: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_429_fork_clone642"} loc("MobileNetv2Basic":0:0), %arg59: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_444"} loc("MobileNetv2Basic":0:0), %arg60: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_444_fork_clone555"} loc("MobileNetv2Basic":0:0), %arg61: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_459"} loc("MobileNetv2Basic":0:0), %arg62: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_459_fork_clone486"} loc("MobileNetv2Basic":0:0), %arg63: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_475"} loc("MobileNetv2Basic":0:0), %arg64: tensor<1x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_475_fork_clone418"} loc("MobileNetv2Basic":0:0), %arg65: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_490"} loc("MobileNetv2Basic":0:0), %arg66: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_490_fork_clone351"} loc("MobileNetv2Basic":0:0), %arg67: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_504"} loc("MobileNetv2Basic":0:0), %arg68: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_504_fork_clone491"} loc("MobileNetv2Basic":0:0), %arg69: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_520"} loc("MobileNetv2Basic":0:0), %arg70: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_520_fork_clone425"} loc("MobileNetv2Basic":0:0), %arg71: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_535"} loc("MobileNetv2Basic":0:0), %arg72: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_535_fork_clone355"} loc("MobileNetv2Basic":0:0), %arg73: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_550"} loc("MobileNetv2Basic":0:0), %arg74: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_550_fork_clone479"} loc("MobileNetv2Basic":0:0), %arg75: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_566"} loc("MobileNetv2Basic":0:0), %arg76: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_566_fork_clone411"} loc("MobileNetv2Basic":0:0), %arg77: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_581"} loc("MobileNetv2Basic":0:0), %arg78: tensor<1x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_581_fork_clone343"} loc("MobileNetv2Basic":0:0), %arg79: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_596"} loc("MobileNetv2Basic":0:0), %arg80: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_596_fork_clone277"} loc("MobileNetv2Basic":0:0), %arg81: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_612"} loc("MobileNetv2Basic":0:0), %arg82: tensor<1x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_612_fork_clone209"} loc("MobileNetv2Basic":0:0), %arg83: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_627"} loc("MobileNetv2Basic":0:0), %arg84: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_627_fork_clone142"} loc("MobileNetv2Basic":0:0), %arg85: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_641"} loc("MobileNetv2Basic":0:0), %arg86: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_641_fork_clone282"} loc("MobileNetv2Basic":0:0), %arg87: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_657"} loc("MobileNetv2Basic":0:0), %arg88: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_657_fork_clone216"} loc("MobileNetv2Basic":0:0), %arg89: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_672"} loc("MobileNetv2Basic":0:0), %arg90: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_672_fork_clone146"} loc("MobileNetv2Basic":0:0), %arg91: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_687"} loc("MobileNetv2Basic":0:0), %arg92: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_687_fork_clone270"} loc("MobileNetv2Basic":0:0), %arg93: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_703"} loc("MobileNetv2Basic":0:0), %arg94: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_703_fork_clone202"} loc("MobileNetv2Basic":0:0), %arg95: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_718"} loc("MobileNetv2Basic":0:0), %arg96: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_718_fork_clone136"} loc("MobileNetv2Basic":0:0), %arg97: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_733"} loc("MobileNetv2Basic":0:0), %arg98: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_733_fork_clone93"} loc("MobileNetv2Basic":0:0), %arg99: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_749"} loc("MobileNetv2Basic":0:0), %arg100: tensor<1x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_749_fork_clone69"} loc("MobileNetv2Basic":0:0), %arg101: tensor<1x320x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_764"} loc("MobileNetv2Basic":0:0), %arg102: tensor<1x320x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_764_fork_clone44"} loc("MobileNetv2Basic":0:0), %arg103: tensor<1x1280x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_778"} loc("MobileNetv2Basic":0:0), %arg104: tensor<1x1280x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_778_fork_clone26"} loc("MobileNetv2Basic":0:0), %arg105: tensor<32x3x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg106: tensor<32x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.1.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg107: tensor<16x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.1.conv.1.weight"} loc("MobileNetv2Basic":0:0), %arg108: tensor<96x16x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.2.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg109: tensor<96x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.2.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg110: tensor<24x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.2.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg111: tensor<144x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.3.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg112: tensor<144x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.3.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg113: tensor<24x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.3.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg114: tensor<144x24x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.4.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg115: tensor<144x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.4.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg116: tensor<32x144x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.4.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg117: tensor<192x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.5.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg118: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.5.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg119: tensor<32x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.5.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg120: tensor<192x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.6.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg121: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.6.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg122: tensor<32x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.6.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg123: tensor<192x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.7.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg124: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.7.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg125: tensor<64x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.7.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg126: tensor<384x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.8.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg127: tensor<384x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.8.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg128: tensor<64x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.8.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg129: tensor<384x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.9.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg130: tensor<384x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.9.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg131: tensor<64x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.9.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg132: tensor<384x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.10.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg133: tensor<384x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.10.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg134: tensor<64x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.10.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg135: tensor<384x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.11.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg136: tensor<384x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.11.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg137: tensor<96x384x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.11.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg138: tensor<576x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.12.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg139: tensor<576x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.12.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg140: tensor<96x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.12.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg141: tensor<576x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.13.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg142: tensor<576x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.13.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg143: tensor<96x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.13.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg144: tensor<576x96x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.14.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg145: tensor<576x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.14.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg146: tensor<160x576x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.14.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg147: tensor<960x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.15.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg148: tensor<960x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.15.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg149: tensor<160x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.15.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg150: tensor<960x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.16.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg151: tensor<960x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.16.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg152: tensor<160x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.16.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg153: tensor<960x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.17.conv.0.0.weight"} loc("MobileNetv2Basic":0:0), %arg154: tensor<960x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.17.conv.1.0.weight"} loc("MobileNetv2Basic":0:0), %arg155: tensor<320x960x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.17.conv.2.weight"} loc("MobileNetv2Basic":0:0), %arg156: tensor<1280x320x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "features.18.0.weight"} loc("MobileNetv2Basic":0:0), %arg157: tensor<1280x1000xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "classifier.1.weight"} loc("MobileNetv2Basic":0:0), %arg158: tensor<1000xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "classifier.1.bias"} loc("MobileNetv2Basic":0:0)) -> (tensor<8x1000xbf16> {ttir.name = "MobileNetv2Basic.output_add_797"}) {
    %0 = ttir.empty() : tensor<8x224x3x224xbf16> loc(#loc169)
    %1 = "ttir.transpose"(%arg0, %0) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x3x224x224xbf16>, tensor<8x224x3x224xbf16>) -> tensor<8x224x3x224xbf16> loc(#loc169)
    %2 = ttir.empty() : tensor<8x224x224x3xbf16> loc(#loc170)
    %3 = "ttir.transpose"(%1, %2) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x224x3x224xbf16>, tensor<8x224x224x3xbf16>) -> tensor<8x224x224x3xbf16> loc(#loc170)
    %4 = ttir.empty() : tensor<8x112x112x32xbf16> loc(#loc171)
    %5 = "ttir.conv2d"(%3, %arg105, %4) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x224x224x3xbf16>, tensor<32x3x3x3xbf16>, tensor<8x112x112x32xbf16>) -> tensor<8x112x112x32xbf16> loc(#loc171)
    %6 = ttir.empty() : tensor<8x112x32x112xbf16> loc(#loc172)
    %7 = "ttir.transpose"(%5, %6) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x32xbf16>, tensor<8x112x32x112xbf16>) -> tensor<8x112x32x112xbf16> loc(#loc172)
    %8 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc173)
    %9 = "ttir.transpose"(%7, %8) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x32x112xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc173)
    %10 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc2)
    %11 = "ttir.multiply"(%9, %arg1, %10) : (tensor<8x32x112x112xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc2)
    %12 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc3)
    %13 = "ttir.add"(%11, %arg2, %12) : (tensor<8x32x112x112xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc3)
    %14 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc174)
    %15 = "ttir.clamp_scalar"(%13, %14) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x32x112x112xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc174)
    %16 = ttir.empty() : tensor<8x112x32x112xbf16> loc(#loc382)
    %17 = "ttir.transpose"(%15, %16) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x32x112x112xbf16>, tensor<8x112x32x112xbf16>) -> tensor<8x112x32x112xbf16> loc(#loc382)
    %18 = ttir.empty() : tensor<8x112x112x32xbf16> loc(#loc383)
    %19 = "ttir.transpose"(%17, %18) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x32x112xbf16>, tensor<8x112x112x32xbf16>) -> tensor<8x112x112x32xbf16> loc(#loc383)
    %20 = ttir.empty() : tensor<8x112x112x32xbf16> loc(#loc384)
    %21 = "ttir.conv2d"(%19, %arg106, %20) <{dilation = array<i32: 1, 1>, groups = 32 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x112x112x32xbf16>, tensor<32x1x3x3xbf16>, tensor<8x112x112x32xbf16>) -> tensor<8x112x112x32xbf16> loc(#loc384)
    %22 = ttir.empty() : tensor<8x112x32x112xbf16> loc(#loc385)
    %23 = "ttir.transpose"(%21, %22) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x32xbf16>, tensor<8x112x32x112xbf16>) -> tensor<8x112x32x112xbf16> loc(#loc385)
    %24 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc386)
    %25 = "ttir.transpose"(%23, %24) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x32x112xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc386)
    %26 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc4)
    %27 = "ttir.multiply"(%25, %arg3, %26) : (tensor<8x32x112x112xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc4)
    %28 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc5)
    %29 = "ttir.add"(%27, %arg4, %28) : (tensor<8x32x112x112xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc5)
    %30 = ttir.empty() : tensor<8x32x112x112xbf16> loc(#loc387)
    %31 = "ttir.clamp_scalar"(%29, %30) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x32x112x112xbf16>, tensor<8x32x112x112xbf16>) -> tensor<8x32x112x112xbf16> loc(#loc387)
    %32 = ttir.empty() : tensor<8x112x32x112xbf16> loc(#loc233)
    %33 = "ttir.transpose"(%31, %32) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x32x112x112xbf16>, tensor<8x112x32x112xbf16>) -> tensor<8x112x32x112xbf16> loc(#loc233)
    %34 = ttir.empty() : tensor<8x112x112x32xbf16> loc(#loc234)
    %35 = "ttir.transpose"(%33, %34) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x32x112xbf16>, tensor<8x112x112x32xbf16>) -> tensor<8x112x112x32xbf16> loc(#loc234)
    %36 = ttir.empty() : tensor<8x112x112x16xbf16> loc(#loc235)
    %37 = "ttir.conv2d"(%35, %arg107, %36) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x112x112x32xbf16>, tensor<16x32x1x1xbf16>, tensor<8x112x112x16xbf16>) -> tensor<8x112x112x16xbf16> loc(#loc235)
    %38 = ttir.empty() : tensor<8x112x16x112xbf16> loc(#loc236)
    %39 = "ttir.transpose"(%37, %38) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x16xbf16>, tensor<8x112x16x112xbf16>) -> tensor<8x112x16x112xbf16> loc(#loc236)
    %40 = ttir.empty() : tensor<8x16x112x112xbf16> loc(#loc237)
    %41 = "ttir.transpose"(%39, %40) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x16x112xbf16>, tensor<8x16x112x112xbf16>) -> tensor<8x16x112x112xbf16> loc(#loc237)
    %42 = ttir.empty() : tensor<8x16x112x112xbf16> loc(#loc6)
    %43 = "ttir.multiply"(%41, %arg5, %42) : (tensor<8x16x112x112xbf16>, tensor<1x16x1x1xbf16>, tensor<8x16x112x112xbf16>) -> tensor<8x16x112x112xbf16> loc(#loc6)
    %44 = ttir.empty() : tensor<8x16x112x112xbf16> loc(#loc7)
    %45 = "ttir.add"(%43, %arg6, %44) : (tensor<8x16x112x112xbf16>, tensor<1x16x1x1xbf16>, tensor<8x16x112x112xbf16>) -> tensor<8x16x112x112xbf16> loc(#loc7)
    %46 = ttir.empty() : tensor<8x112x16x112xbf16> loc(#loc388)
    %47 = "ttir.transpose"(%45, %46) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x16x112x112xbf16>, tensor<8x112x16x112xbf16>) -> tensor<8x112x16x112xbf16> loc(#loc388)
    %48 = ttir.empty() : tensor<8x112x112x16xbf16> loc(#loc389)
    %49 = "ttir.transpose"(%47, %48) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x16x112xbf16>, tensor<8x112x112x16xbf16>) -> tensor<8x112x112x16xbf16> loc(#loc389)
    %50 = ttir.empty() : tensor<8x112x112x96xbf16> loc(#loc390)
    %51 = "ttir.conv2d"(%49, %arg108, %50) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x112x112x16xbf16>, tensor<96x16x1x1xbf16>, tensor<8x112x112x96xbf16>) -> tensor<8x112x112x96xbf16> loc(#loc390)
    %52 = ttir.empty() : tensor<8x112x96x112xbf16> loc(#loc391)
    %53 = "ttir.transpose"(%51, %52) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x96xbf16>, tensor<8x112x96x112xbf16>) -> tensor<8x112x96x112xbf16> loc(#loc391)
    %54 = ttir.empty() : tensor<8x96x112x112xbf16> loc(#loc392)
    %55 = "ttir.transpose"(%53, %54) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x96x112xbf16>, tensor<8x96x112x112xbf16>) -> tensor<8x96x112x112xbf16> loc(#loc392)
    %56 = ttir.empty() : tensor<8x96x112x112xbf16> loc(#loc8)
    %57 = "ttir.multiply"(%55, %arg7, %56) : (tensor<8x96x112x112xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x112x112xbf16>) -> tensor<8x96x112x112xbf16> loc(#loc8)
    %58 = ttir.empty() : tensor<8x96x112x112xbf16> loc(#loc9)
    %59 = "ttir.add"(%57, %arg8, %58) : (tensor<8x96x112x112xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x112x112xbf16>) -> tensor<8x96x112x112xbf16> loc(#loc9)
    %60 = ttir.empty() : tensor<8x96x112x112xbf16> loc(#loc393)
    %61 = "ttir.clamp_scalar"(%59, %60) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x96x112x112xbf16>, tensor<8x96x112x112xbf16>) -> tensor<8x96x112x112xbf16> loc(#loc393)
    %62 = ttir.empty() : tensor<8x112x96x112xbf16> loc(#loc394)
    %63 = "ttir.transpose"(%61, %62) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x96x112x112xbf16>, tensor<8x112x96x112xbf16>) -> tensor<8x112x96x112xbf16> loc(#loc394)
    %64 = ttir.empty() : tensor<8x112x112x96xbf16> loc(#loc395)
    %65 = "ttir.transpose"(%63, %64) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x96x112xbf16>, tensor<8x112x112x96xbf16>) -> tensor<8x112x112x96xbf16> loc(#loc395)
    %66 = ttir.empty() : tensor<8x56x56x96xbf16> loc(#loc396)
    %67 = "ttir.conv2d"(%65, %arg109, %66) <{dilation = array<i32: 1, 1>, groups = 96 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x112x112x96xbf16>, tensor<96x1x3x3xbf16>, tensor<8x56x56x96xbf16>) -> tensor<8x56x56x96xbf16> loc(#loc396)
    %68 = ttir.empty() : tensor<8x56x96x56xbf16> loc(#loc397)
    %69 = "ttir.transpose"(%67, %68) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x96xbf16>, tensor<8x56x96x56xbf16>) -> tensor<8x56x96x56xbf16> loc(#loc397)
    %70 = ttir.empty() : tensor<8x96x56x56xbf16> loc(#loc398)
    %71 = "ttir.transpose"(%69, %70) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x96x56xbf16>, tensor<8x96x56x56xbf16>) -> tensor<8x96x56x56xbf16> loc(#loc398)
    %72 = ttir.empty() : tensor<8x96x56x56xbf16> loc(#loc10)
    %73 = "ttir.multiply"(%71, %arg9, %72) : (tensor<8x96x56x56xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x56x56xbf16>) -> tensor<8x96x56x56xbf16> loc(#loc10)
    %74 = ttir.empty() : tensor<8x96x56x56xbf16> loc(#loc11)
    %75 = "ttir.add"(%73, %arg10, %74) : (tensor<8x96x56x56xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x56x56xbf16>) -> tensor<8x96x56x56xbf16> loc(#loc11)
    %76 = ttir.empty() : tensor<8x96x56x56xbf16> loc(#loc399)
    %77 = "ttir.clamp_scalar"(%75, %76) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x96x56x56xbf16>, tensor<8x96x56x56xbf16>) -> tensor<8x96x56x56xbf16> loc(#loc399)
    %78 = ttir.empty() : tensor<8x56x96x56xbf16> loc(#loc242)
    %79 = "ttir.transpose"(%77, %78) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x96x56x56xbf16>, tensor<8x56x96x56xbf16>) -> tensor<8x56x96x56xbf16> loc(#loc242)
    %80 = ttir.empty() : tensor<8x56x56x96xbf16> loc(#loc243)
    %81 = "ttir.transpose"(%79, %80) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x96x56xbf16>, tensor<8x56x56x96xbf16>) -> tensor<8x56x56x96xbf16> loc(#loc243)
    %82 = ttir.empty() : tensor<8x56x56x24xbf16> loc(#loc244)
    %83 = "ttir.conv2d"(%81, %arg110, %82) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x96xbf16>, tensor<24x96x1x1xbf16>, tensor<8x56x56x24xbf16>) -> tensor<8x56x56x24xbf16> loc(#loc244)
    %84 = ttir.empty() : tensor<8x56x24x56xbf16> loc(#loc245)
    %85 = "ttir.transpose"(%83, %84) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x24xbf16>, tensor<8x56x24x56xbf16>) -> tensor<8x56x24x56xbf16> loc(#loc245)
    %86 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc246)
    %87 = "ttir.transpose"(%85, %86) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x24x56xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc246)
    %88 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc12)
    %89 = "ttir.multiply"(%87, %arg11, %88) : (tensor<8x24x56x56xbf16>, tensor<1x24x1x1xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc12)
    %90 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc13)
    %91 = "ttir.add"(%89, %arg12, %90) : (tensor<8x24x56x56xbf16>, tensor<1x24x1x1xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc13)
    %92 = ttir.empty() : tensor<8x56x24x56xbf16> loc(#loc400)
    %93 = "ttir.transpose"(%91, %92) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x24x56x56xbf16>, tensor<8x56x24x56xbf16>) -> tensor<8x56x24x56xbf16> loc(#loc400)
    %94 = ttir.empty() : tensor<8x56x56x24xbf16> loc(#loc401)
    %95 = "ttir.transpose"(%93, %94) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x24x56xbf16>, tensor<8x56x56x24xbf16>) -> tensor<8x56x56x24xbf16> loc(#loc401)
    %96 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc402)
    %97 = "ttir.conv2d"(%95, %arg111, %96) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x24xbf16>, tensor<144x24x1x1xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc402)
    %98 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc403)
    %99 = "ttir.transpose"(%97, %98) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x144xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc403)
    %100 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc404)
    %101 = "ttir.transpose"(%99, %100) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc404)
    %102 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc14)
    %103 = "ttir.multiply"(%101, %arg13, %102) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc14)
    %104 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc15)
    %105 = "ttir.add"(%103, %arg14, %104) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc15)
    %106 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc405)
    %107 = "ttir.clamp_scalar"(%105, %106) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x144x56x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc405)
    %108 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc406)
    %109 = "ttir.transpose"(%107, %108) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x144x56x56xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc406)
    %110 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc407)
    %111 = "ttir.transpose"(%109, %110) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc407)
    %112 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc408)
    %113 = "ttir.conv2d"(%111, %arg112, %112) <{dilation = array<i32: 1, 1>, groups = 144 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x144xbf16>, tensor<144x1x3x3xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc408)
    %114 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc409)
    %115 = "ttir.transpose"(%113, %114) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x144xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc409)
    %116 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc410)
    %117 = "ttir.transpose"(%115, %116) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc410)
    %118 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc16)
    %119 = "ttir.multiply"(%117, %arg15, %118) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc16)
    %120 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc17)
    %121 = "ttir.add"(%119, %arg16, %120) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc17)
    %122 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc411)
    %123 = "ttir.clamp_scalar"(%121, %122) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x144x56x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc411)
    %124 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc251)
    %125 = "ttir.transpose"(%123, %124) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x144x56x56xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc251)
    %126 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc252)
    %127 = "ttir.transpose"(%125, %126) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc252)
    %128 = ttir.empty() : tensor<8x56x56x24xbf16> loc(#loc253)
    %129 = "ttir.conv2d"(%127, %arg113, %128) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x144xbf16>, tensor<24x144x1x1xbf16>, tensor<8x56x56x24xbf16>) -> tensor<8x56x56x24xbf16> loc(#loc253)
    %130 = ttir.empty() : tensor<8x56x24x56xbf16> loc(#loc254)
    %131 = "ttir.transpose"(%129, %130) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x24xbf16>, tensor<8x56x24x56xbf16>) -> tensor<8x56x24x56xbf16> loc(#loc254)
    %132 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc255)
    %133 = "ttir.transpose"(%131, %132) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x24x56xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc255)
    %134 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc18)
    %135 = "ttir.multiply"(%133, %arg17, %134) : (tensor<8x24x56x56xbf16>, tensor<1x24x1x1xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc18)
    %136 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc19)
    %137 = "ttir.add"(%135, %arg18, %136) : (tensor<8x24x56x56xbf16>, tensor<1x24x1x1xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc19)
    %138 = ttir.empty() : tensor<8x24x56x56xbf16> loc(#loc142)
    %139 = "ttir.add"(%91, %137, %138) : (tensor<8x24x56x56xbf16>, tensor<8x24x56x56xbf16>, tensor<8x24x56x56xbf16>) -> tensor<8x24x56x56xbf16> loc(#loc142)
    %140 = ttir.empty() : tensor<8x56x24x56xbf16> loc(#loc412)
    %141 = "ttir.transpose"(%139, %140) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x24x56x56xbf16>, tensor<8x56x24x56xbf16>) -> tensor<8x56x24x56xbf16> loc(#loc412)
    %142 = ttir.empty() : tensor<8x56x56x24xbf16> loc(#loc413)
    %143 = "ttir.transpose"(%141, %142) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x24x56xbf16>, tensor<8x56x56x24xbf16>) -> tensor<8x56x56x24xbf16> loc(#loc413)
    %144 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc414)
    %145 = "ttir.conv2d"(%143, %arg114, %144) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x24xbf16>, tensor<144x24x1x1xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc414)
    %146 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc415)
    %147 = "ttir.transpose"(%145, %146) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x144xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc415)
    %148 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc416)
    %149 = "ttir.transpose"(%147, %148) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc416)
    %150 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc20)
    %151 = "ttir.multiply"(%149, %arg19, %150) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc20)
    %152 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc21)
    %153 = "ttir.add"(%151, %arg20, %152) : (tensor<8x144x56x56xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc21)
    %154 = ttir.empty() : tensor<8x144x56x56xbf16> loc(#loc417)
    %155 = "ttir.clamp_scalar"(%153, %154) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x144x56x56xbf16>, tensor<8x144x56x56xbf16>) -> tensor<8x144x56x56xbf16> loc(#loc417)
    %156 = ttir.empty() : tensor<8x56x144x56xbf16> loc(#loc418)
    %157 = "ttir.transpose"(%155, %156) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x144x56x56xbf16>, tensor<8x56x144x56xbf16>) -> tensor<8x56x144x56xbf16> loc(#loc418)
    %158 = ttir.empty() : tensor<8x56x56x144xbf16> loc(#loc419)
    %159 = "ttir.transpose"(%157, %158) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x144x56xbf16>, tensor<8x56x56x144xbf16>) -> tensor<8x56x56x144xbf16> loc(#loc419)
    %160 = ttir.empty() : tensor<8x28x28x144xbf16> loc(#loc420)
    %161 = "ttir.conv2d"(%159, %arg115, %160) <{dilation = array<i32: 1, 1>, groups = 144 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x56x56x144xbf16>, tensor<144x1x3x3xbf16>, tensor<8x28x28x144xbf16>) -> tensor<8x28x28x144xbf16> loc(#loc420)
    %162 = ttir.empty() : tensor<8x28x144x28xbf16> loc(#loc421)
    %163 = "ttir.transpose"(%161, %162) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x144xbf16>, tensor<8x28x144x28xbf16>) -> tensor<8x28x144x28xbf16> loc(#loc421)
    %164 = ttir.empty() : tensor<8x144x28x28xbf16> loc(#loc422)
    %165 = "ttir.transpose"(%163, %164) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x144x28xbf16>, tensor<8x144x28x28xbf16>) -> tensor<8x144x28x28xbf16> loc(#loc422)
    %166 = ttir.empty() : tensor<8x144x28x28xbf16> loc(#loc22)
    %167 = "ttir.multiply"(%165, %arg21, %166) : (tensor<8x144x28x28xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x28x28xbf16>) -> tensor<8x144x28x28xbf16> loc(#loc22)
    %168 = ttir.empty() : tensor<8x144x28x28xbf16> loc(#loc23)
    %169 = "ttir.add"(%167, %arg22, %168) : (tensor<8x144x28x28xbf16>, tensor<1x144x1x1xbf16>, tensor<8x144x28x28xbf16>) -> tensor<8x144x28x28xbf16> loc(#loc23)
    %170 = ttir.empty() : tensor<8x144x28x28xbf16> loc(#loc423)
    %171 = "ttir.clamp_scalar"(%169, %170) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x144x28x28xbf16>, tensor<8x144x28x28xbf16>) -> tensor<8x144x28x28xbf16> loc(#loc423)
    %172 = ttir.empty() : tensor<8x28x144x28xbf16> loc(#loc260)
    %173 = "ttir.transpose"(%171, %172) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x144x28x28xbf16>, tensor<8x28x144x28xbf16>) -> tensor<8x28x144x28xbf16> loc(#loc260)
    %174 = ttir.empty() : tensor<8x28x28x144xbf16> loc(#loc261)
    %175 = "ttir.transpose"(%173, %174) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x144x28xbf16>, tensor<8x28x28x144xbf16>) -> tensor<8x28x28x144xbf16> loc(#loc261)
    %176 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc262)
    %177 = "ttir.conv2d"(%175, %arg116, %176) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x144xbf16>, tensor<32x144x1x1xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc262)
    %178 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc263)
    %179 = "ttir.transpose"(%177, %178) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x32xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc263)
    %180 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc264)
    %181 = "ttir.transpose"(%179, %180) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc264)
    %182 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc24)
    %183 = "ttir.multiply"(%181, %arg23, %182) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc24)
    %184 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc25)
    %185 = "ttir.add"(%183, %arg24, %184) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc25)
    %186 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc424)
    %187 = "ttir.transpose"(%185, %186) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x32x28x28xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc424)
    %188 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc425)
    %189 = "ttir.transpose"(%187, %188) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc425)
    %190 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc426)
    %191 = "ttir.conv2d"(%189, %arg117, %190) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x32xbf16>, tensor<192x32x1x1xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc426)
    %192 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc427)
    %193 = "ttir.transpose"(%191, %192) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x192xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc427)
    %194 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc428)
    %195 = "ttir.transpose"(%193, %194) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc428)
    %196 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc26)
    %197 = "ttir.multiply"(%195, %arg25, %196) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc26)
    %198 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc27)
    %199 = "ttir.add"(%197, %arg26, %198) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc27)
    %200 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc429)
    %201 = "ttir.clamp_scalar"(%199, %200) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x28x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc429)
    %202 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc430)
    %203 = "ttir.transpose"(%201, %202) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x28x28xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc430)
    %204 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc431)
    %205 = "ttir.transpose"(%203, %204) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc431)
    %206 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc432)
    %207 = "ttir.conv2d"(%205, %arg118, %206) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc432)
    %208 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc433)
    %209 = "ttir.transpose"(%207, %208) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x192xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc433)
    %210 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc434)
    %211 = "ttir.transpose"(%209, %210) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc434)
    %212 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc28)
    %213 = "ttir.multiply"(%211, %arg27, %212) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc28)
    %214 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc29)
    %215 = "ttir.add"(%213, %arg28, %214) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc29)
    %216 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc435)
    %217 = "ttir.clamp_scalar"(%215, %216) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x28x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc435)
    %218 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc269)
    %219 = "ttir.transpose"(%217, %218) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x28x28xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc269)
    %220 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc270)
    %221 = "ttir.transpose"(%219, %220) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc270)
    %222 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc271)
    %223 = "ttir.conv2d"(%221, %arg119, %222) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x192xbf16>, tensor<32x192x1x1xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc271)
    %224 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc272)
    %225 = "ttir.transpose"(%223, %224) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x32xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc272)
    %226 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc273)
    %227 = "ttir.transpose"(%225, %226) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc273)
    %228 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc30)
    %229 = "ttir.multiply"(%227, %arg29, %228) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc30)
    %230 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc31)
    %231 = "ttir.add"(%229, %arg30, %230) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc31)
    %232 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc145)
    %233 = "ttir.add"(%185, %231, %232) : (tensor<8x32x28x28xbf16>, tensor<8x32x28x28xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc145)
    %234 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc436)
    %235 = "ttir.transpose"(%233, %234) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x32x28x28xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc436)
    %236 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc437)
    %237 = "ttir.transpose"(%235, %236) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc437)
    %238 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc438)
    %239 = "ttir.conv2d"(%237, %arg120, %238) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x32xbf16>, tensor<192x32x1x1xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc438)
    %240 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc439)
    %241 = "ttir.transpose"(%239, %240) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x192xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc439)
    %242 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc440)
    %243 = "ttir.transpose"(%241, %242) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc440)
    %244 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc32)
    %245 = "ttir.multiply"(%243, %arg31, %244) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc32)
    %246 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc33)
    %247 = "ttir.add"(%245, %arg32, %246) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc33)
    %248 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc441)
    %249 = "ttir.clamp_scalar"(%247, %248) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x28x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc441)
    %250 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc442)
    %251 = "ttir.transpose"(%249, %250) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x28x28xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc442)
    %252 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc443)
    %253 = "ttir.transpose"(%251, %252) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc443)
    %254 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc444)
    %255 = "ttir.conv2d"(%253, %arg121, %254) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc444)
    %256 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc445)
    %257 = "ttir.transpose"(%255, %256) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x192xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc445)
    %258 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc446)
    %259 = "ttir.transpose"(%257, %258) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc446)
    %260 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc34)
    %261 = "ttir.multiply"(%259, %arg33, %260) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc34)
    %262 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc35)
    %263 = "ttir.add"(%261, %arg34, %262) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc35)
    %264 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc447)
    %265 = "ttir.clamp_scalar"(%263, %264) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x28x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc447)
    %266 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc278)
    %267 = "ttir.transpose"(%265, %266) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x28x28xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc278)
    %268 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc279)
    %269 = "ttir.transpose"(%267, %268) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc279)
    %270 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc280)
    %271 = "ttir.conv2d"(%269, %arg122, %270) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x192xbf16>, tensor<32x192x1x1xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc280)
    %272 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc281)
    %273 = "ttir.transpose"(%271, %272) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x32xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc281)
    %274 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc282)
    %275 = "ttir.transpose"(%273, %274) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc282)
    %276 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc36)
    %277 = "ttir.multiply"(%275, %arg35, %276) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc36)
    %278 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc37)
    %279 = "ttir.add"(%277, %arg36, %278) : (tensor<8x32x28x28xbf16>, tensor<1x32x1x1xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc37)
    %280 = ttir.empty() : tensor<8x32x28x28xbf16> loc(#loc147)
    %281 = "ttir.add"(%233, %279, %280) : (tensor<8x32x28x28xbf16>, tensor<8x32x28x28xbf16>, tensor<8x32x28x28xbf16>) -> tensor<8x32x28x28xbf16> loc(#loc147)
    %282 = ttir.empty() : tensor<8x28x32x28xbf16> loc(#loc448)
    %283 = "ttir.transpose"(%281, %282) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x32x28x28xbf16>, tensor<8x28x32x28xbf16>) -> tensor<8x28x32x28xbf16> loc(#loc448)
    %284 = ttir.empty() : tensor<8x28x28x32xbf16> loc(#loc449)
    %285 = "ttir.transpose"(%283, %284) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x32x28xbf16>, tensor<8x28x28x32xbf16>) -> tensor<8x28x28x32xbf16> loc(#loc449)
    %286 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc450)
    %287 = "ttir.conv2d"(%285, %arg123, %286) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x32xbf16>, tensor<192x32x1x1xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc450)
    %288 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc451)
    %289 = "ttir.transpose"(%287, %288) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x192xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc451)
    %290 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc452)
    %291 = "ttir.transpose"(%289, %290) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc452)
    %292 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc38)
    %293 = "ttir.multiply"(%291, %arg37, %292) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc38)
    %294 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc39)
    %295 = "ttir.add"(%293, %arg38, %294) : (tensor<8x192x28x28xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc39)
    %296 = ttir.empty() : tensor<8x192x28x28xbf16> loc(#loc453)
    %297 = "ttir.clamp_scalar"(%295, %296) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x28x28xbf16>, tensor<8x192x28x28xbf16>) -> tensor<8x192x28x28xbf16> loc(#loc453)
    %298 = ttir.empty() : tensor<8x28x192x28xbf16> loc(#loc454)
    %299 = "ttir.transpose"(%297, %298) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x28x28xbf16>, tensor<8x28x192x28xbf16>) -> tensor<8x28x192x28xbf16> loc(#loc454)
    %300 = ttir.empty() : tensor<8x28x28x192xbf16> loc(#loc455)
    %301 = "ttir.transpose"(%299, %300) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x192x28xbf16>, tensor<8x28x28x192xbf16>) -> tensor<8x28x28x192xbf16> loc(#loc455)
    %302 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc456)
    %303 = "ttir.conv2d"(%301, %arg124, %302) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x28x28x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc456)
    %304 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc457)
    %305 = "ttir.transpose"(%303, %304) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc457)
    %306 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc458)
    %307 = "ttir.transpose"(%305, %306) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc458)
    %308 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc40)
    %309 = "ttir.multiply"(%307, %arg39, %308) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc40)
    %310 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc41)
    %311 = "ttir.add"(%309, %arg40, %310) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc41)
    %312 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc459)
    %313 = "ttir.clamp_scalar"(%311, %312) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc459)
    %314 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc287)
    %315 = "ttir.transpose"(%313, %314) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc287)
    %316 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc288)
    %317 = "ttir.transpose"(%315, %316) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc288)
    %318 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc289)
    %319 = "ttir.conv2d"(%317, %arg125, %318) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<64x192x1x1xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc289)
    %320 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc290)
    %321 = "ttir.transpose"(%319, %320) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x64xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc290)
    %322 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc291)
    %323 = "ttir.transpose"(%321, %322) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc291)
    %324 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc42)
    %325 = "ttir.multiply"(%323, %arg41, %324) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc42)
    %326 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc43)
    %327 = "ttir.add"(%325, %arg42, %326) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc43)
    %328 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc460)
    %329 = "ttir.transpose"(%327, %328) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x14x14xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc460)
    %330 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc461)
    %331 = "ttir.transpose"(%329, %330) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc461)
    %332 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc462)
    %333 = "ttir.conv2d"(%331, %arg126, %332) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x64xbf16>, tensor<384x64x1x1xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc462)
    %334 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc463)
    %335 = "ttir.transpose"(%333, %334) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc463)
    %336 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc464)
    %337 = "ttir.transpose"(%335, %336) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc464)
    %338 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc44)
    %339 = "ttir.multiply"(%337, %arg43, %338) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc44)
    %340 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc45)
    %341 = "ttir.add"(%339, %arg44, %340) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc45)
    %342 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc465)
    %343 = "ttir.clamp_scalar"(%341, %342) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc465)
    %344 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc466)
    %345 = "ttir.transpose"(%343, %344) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc466)
    %346 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc467)
    %347 = "ttir.transpose"(%345, %346) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc467)
    %348 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc468)
    %349 = "ttir.conv2d"(%347, %arg127, %348) <{dilation = array<i32: 1, 1>, groups = 384 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<384x1x3x3xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc468)
    %350 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc469)
    %351 = "ttir.transpose"(%349, %350) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc469)
    %352 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc470)
    %353 = "ttir.transpose"(%351, %352) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc470)
    %354 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc46)
    %355 = "ttir.multiply"(%353, %arg45, %354) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc46)
    %356 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc47)
    %357 = "ttir.add"(%355, %arg46, %356) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc47)
    %358 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc471)
    %359 = "ttir.clamp_scalar"(%357, %358) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc471)
    %360 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc296)
    %361 = "ttir.transpose"(%359, %360) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc296)
    %362 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc297)
    %363 = "ttir.transpose"(%361, %362) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc297)
    %364 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc298)
    %365 = "ttir.conv2d"(%363, %arg128, %364) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<64x384x1x1xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc298)
    %366 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc299)
    %367 = "ttir.transpose"(%365, %366) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x64xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc299)
    %368 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc300)
    %369 = "ttir.transpose"(%367, %368) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc300)
    %370 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc48)
    %371 = "ttir.multiply"(%369, %arg47, %370) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc48)
    %372 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc49)
    %373 = "ttir.add"(%371, %arg48, %372) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc49)
    %374 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc150)
    %375 = "ttir.add"(%327, %373, %374) : (tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc150)
    %376 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc472)
    %377 = "ttir.transpose"(%375, %376) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x14x14xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc472)
    %378 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc473)
    %379 = "ttir.transpose"(%377, %378) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc473)
    %380 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc474)
    %381 = "ttir.conv2d"(%379, %arg129, %380) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x64xbf16>, tensor<384x64x1x1xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc474)
    %382 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc475)
    %383 = "ttir.transpose"(%381, %382) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc475)
    %384 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc476)
    %385 = "ttir.transpose"(%383, %384) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc476)
    %386 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc50)
    %387 = "ttir.multiply"(%385, %arg49, %386) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc50)
    %388 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc51)
    %389 = "ttir.add"(%387, %arg50, %388) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc51)
    %390 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc477)
    %391 = "ttir.clamp_scalar"(%389, %390) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc477)
    %392 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc478)
    %393 = "ttir.transpose"(%391, %392) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc478)
    %394 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc479)
    %395 = "ttir.transpose"(%393, %394) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc479)
    %396 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc480)
    %397 = "ttir.conv2d"(%395, %arg130, %396) <{dilation = array<i32: 1, 1>, groups = 384 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<384x1x3x3xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc480)
    %398 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc481)
    %399 = "ttir.transpose"(%397, %398) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc481)
    %400 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc482)
    %401 = "ttir.transpose"(%399, %400) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc482)
    %402 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc52)
    %403 = "ttir.multiply"(%401, %arg51, %402) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc52)
    %404 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc53)
    %405 = "ttir.add"(%403, %arg52, %404) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc53)
    %406 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc483)
    %407 = "ttir.clamp_scalar"(%405, %406) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc483)
    %408 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc305)
    %409 = "ttir.transpose"(%407, %408) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc305)
    %410 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc306)
    %411 = "ttir.transpose"(%409, %410) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc306)
    %412 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc307)
    %413 = "ttir.conv2d"(%411, %arg131, %412) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<64x384x1x1xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc307)
    %414 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc308)
    %415 = "ttir.transpose"(%413, %414) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x64xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc308)
    %416 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc309)
    %417 = "ttir.transpose"(%415, %416) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc309)
    %418 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc54)
    %419 = "ttir.multiply"(%417, %arg53, %418) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc54)
    %420 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc55)
    %421 = "ttir.add"(%419, %arg54, %420) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc55)
    %422 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc152)
    %423 = "ttir.add"(%375, %421, %422) : (tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc152)
    %424 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc484)
    %425 = "ttir.transpose"(%423, %424) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x14x14xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc484)
    %426 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc485)
    %427 = "ttir.transpose"(%425, %426) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc485)
    %428 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc486)
    %429 = "ttir.conv2d"(%427, %arg132, %428) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x64xbf16>, tensor<384x64x1x1xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc486)
    %430 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc487)
    %431 = "ttir.transpose"(%429, %430) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc487)
    %432 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc488)
    %433 = "ttir.transpose"(%431, %432) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc488)
    %434 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc56)
    %435 = "ttir.multiply"(%433, %arg55, %434) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc56)
    %436 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc57)
    %437 = "ttir.add"(%435, %arg56, %436) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc57)
    %438 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc489)
    %439 = "ttir.clamp_scalar"(%437, %438) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc489)
    %440 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc490)
    %441 = "ttir.transpose"(%439, %440) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc490)
    %442 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc491)
    %443 = "ttir.transpose"(%441, %442) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc491)
    %444 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc492)
    %445 = "ttir.conv2d"(%443, %arg133, %444) <{dilation = array<i32: 1, 1>, groups = 384 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<384x1x3x3xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc492)
    %446 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc493)
    %447 = "ttir.transpose"(%445, %446) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc493)
    %448 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc494)
    %449 = "ttir.transpose"(%447, %448) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc494)
    %450 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc58)
    %451 = "ttir.multiply"(%449, %arg57, %450) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc58)
    %452 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc59)
    %453 = "ttir.add"(%451, %arg58, %452) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc59)
    %454 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc495)
    %455 = "ttir.clamp_scalar"(%453, %454) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc495)
    %456 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc314)
    %457 = "ttir.transpose"(%455, %456) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc314)
    %458 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc315)
    %459 = "ttir.transpose"(%457, %458) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc315)
    %460 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc316)
    %461 = "ttir.conv2d"(%459, %arg134, %460) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<64x384x1x1xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc316)
    %462 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc317)
    %463 = "ttir.transpose"(%461, %462) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x64xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc317)
    %464 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc318)
    %465 = "ttir.transpose"(%463, %464) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc318)
    %466 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc60)
    %467 = "ttir.multiply"(%465, %arg59, %466) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc60)
    %468 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc61)
    %469 = "ttir.add"(%467, %arg60, %468) : (tensor<8x64x14x14xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc61)
    %470 = ttir.empty() : tensor<8x64x14x14xbf16> loc(#loc154)
    %471 = "ttir.add"(%423, %469, %470) : (tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>, tensor<8x64x14x14xbf16>) -> tensor<8x64x14x14xbf16> loc(#loc154)
    %472 = ttir.empty() : tensor<8x14x64x14xbf16> loc(#loc496)
    %473 = "ttir.transpose"(%471, %472) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x14x14xbf16>, tensor<8x14x64x14xbf16>) -> tensor<8x14x64x14xbf16> loc(#loc496)
    %474 = ttir.empty() : tensor<8x14x14x64xbf16> loc(#loc497)
    %475 = "ttir.transpose"(%473, %474) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x64x14xbf16>, tensor<8x14x14x64xbf16>) -> tensor<8x14x14x64xbf16> loc(#loc497)
    %476 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc498)
    %477 = "ttir.conv2d"(%475, %arg135, %476) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x64xbf16>, tensor<384x64x1x1xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc498)
    %478 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc499)
    %479 = "ttir.transpose"(%477, %478) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc499)
    %480 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc500)
    %481 = "ttir.transpose"(%479, %480) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc500)
    %482 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc62)
    %483 = "ttir.multiply"(%481, %arg61, %482) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc62)
    %484 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc63)
    %485 = "ttir.add"(%483, %arg62, %484) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc63)
    %486 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc501)
    %487 = "ttir.clamp_scalar"(%485, %486) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc501)
    %488 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc502)
    %489 = "ttir.transpose"(%487, %488) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc502)
    %490 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc503)
    %491 = "ttir.transpose"(%489, %490) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc503)
    %492 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc504)
    %493 = "ttir.conv2d"(%491, %arg136, %492) <{dilation = array<i32: 1, 1>, groups = 384 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<384x1x3x3xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc504)
    %494 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc505)
    %495 = "ttir.transpose"(%493, %494) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x384xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc505)
    %496 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc506)
    %497 = "ttir.transpose"(%495, %496) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc506)
    %498 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc64)
    %499 = "ttir.multiply"(%497, %arg63, %498) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc64)
    %500 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc65)
    %501 = "ttir.add"(%499, %arg64, %500) : (tensor<8x384x14x14xbf16>, tensor<1x384x1x1xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc65)
    %502 = ttir.empty() : tensor<8x384x14x14xbf16> loc(#loc507)
    %503 = "ttir.clamp_scalar"(%501, %502) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x384x14x14xbf16>, tensor<8x384x14x14xbf16>) -> tensor<8x384x14x14xbf16> loc(#loc507)
    %504 = ttir.empty() : tensor<8x14x384x14xbf16> loc(#loc323)
    %505 = "ttir.transpose"(%503, %504) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x384x14x14xbf16>, tensor<8x14x384x14xbf16>) -> tensor<8x14x384x14xbf16> loc(#loc323)
    %506 = ttir.empty() : tensor<8x14x14x384xbf16> loc(#loc324)
    %507 = "ttir.transpose"(%505, %506) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x384x14xbf16>, tensor<8x14x14x384xbf16>) -> tensor<8x14x14x384xbf16> loc(#loc324)
    %508 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc325)
    %509 = "ttir.conv2d"(%507, %arg137, %508) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x384xbf16>, tensor<96x384x1x1xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc325)
    %510 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc326)
    %511 = "ttir.transpose"(%509, %510) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x96xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc326)
    %512 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc327)
    %513 = "ttir.transpose"(%511, %512) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc327)
    %514 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc66)
    %515 = "ttir.multiply"(%513, %arg65, %514) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc66)
    %516 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc67)
    %517 = "ttir.add"(%515, %arg66, %516) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc67)
    %518 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc508)
    %519 = "ttir.transpose"(%517, %518) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x96x14x14xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc508)
    %520 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc509)
    %521 = "ttir.transpose"(%519, %520) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc509)
    %522 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc510)
    %523 = "ttir.conv2d"(%521, %arg138, %522) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x96xbf16>, tensor<576x96x1x1xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc510)
    %524 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc511)
    %525 = "ttir.transpose"(%523, %524) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x576xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc511)
    %526 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc512)
    %527 = "ttir.transpose"(%525, %526) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc512)
    %528 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc68)
    %529 = "ttir.multiply"(%527, %arg67, %528) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc68)
    %530 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc69)
    %531 = "ttir.add"(%529, %arg68, %530) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc69)
    %532 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc513)
    %533 = "ttir.clamp_scalar"(%531, %532) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x14x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc513)
    %534 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc514)
    %535 = "ttir.transpose"(%533, %534) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x14x14xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc514)
    %536 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc515)
    %537 = "ttir.transpose"(%535, %536) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc515)
    %538 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc516)
    %539 = "ttir.conv2d"(%537, %arg139, %538) <{dilation = array<i32: 1, 1>, groups = 576 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x576xbf16>, tensor<576x1x3x3xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc516)
    %540 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc517)
    %541 = "ttir.transpose"(%539, %540) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x576xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc517)
    %542 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc518)
    %543 = "ttir.transpose"(%541, %542) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc518)
    %544 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc70)
    %545 = "ttir.multiply"(%543, %arg69, %544) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc70)
    %546 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc71)
    %547 = "ttir.add"(%545, %arg70, %546) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc71)
    %548 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc519)
    %549 = "ttir.clamp_scalar"(%547, %548) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x14x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc519)
    %550 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc332)
    %551 = "ttir.transpose"(%549, %550) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x14x14xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc332)
    %552 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc333)
    %553 = "ttir.transpose"(%551, %552) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc333)
    %554 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc334)
    %555 = "ttir.conv2d"(%553, %arg140, %554) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x576xbf16>, tensor<96x576x1x1xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc334)
    %556 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc335)
    %557 = "ttir.transpose"(%555, %556) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x96xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc335)
    %558 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc336)
    %559 = "ttir.transpose"(%557, %558) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc336)
    %560 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc72)
    %561 = "ttir.multiply"(%559, %arg71, %560) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc72)
    %562 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc73)
    %563 = "ttir.add"(%561, %arg72, %562) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc73)
    %564 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc157)
    %565 = "ttir.add"(%517, %563, %564) : (tensor<8x96x14x14xbf16>, tensor<8x96x14x14xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc157)
    %566 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc520)
    %567 = "ttir.transpose"(%565, %566) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x96x14x14xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc520)
    %568 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc521)
    %569 = "ttir.transpose"(%567, %568) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc521)
    %570 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc522)
    %571 = "ttir.conv2d"(%569, %arg141, %570) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x96xbf16>, tensor<576x96x1x1xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc522)
    %572 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc523)
    %573 = "ttir.transpose"(%571, %572) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x576xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc523)
    %574 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc524)
    %575 = "ttir.transpose"(%573, %574) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc524)
    %576 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc74)
    %577 = "ttir.multiply"(%575, %arg73, %576) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc74)
    %578 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc75)
    %579 = "ttir.add"(%577, %arg74, %578) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc75)
    %580 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc525)
    %581 = "ttir.clamp_scalar"(%579, %580) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x14x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc525)
    %582 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc526)
    %583 = "ttir.transpose"(%581, %582) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x14x14xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc526)
    %584 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc527)
    %585 = "ttir.transpose"(%583, %584) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc527)
    %586 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc528)
    %587 = "ttir.conv2d"(%585, %arg142, %586) <{dilation = array<i32: 1, 1>, groups = 576 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x576xbf16>, tensor<576x1x3x3xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc528)
    %588 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc529)
    %589 = "ttir.transpose"(%587, %588) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x576xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc529)
    %590 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc530)
    %591 = "ttir.transpose"(%589, %590) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc530)
    %592 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc76)
    %593 = "ttir.multiply"(%591, %arg75, %592) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc76)
    %594 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc77)
    %595 = "ttir.add"(%593, %arg76, %594) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc77)
    %596 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc531)
    %597 = "ttir.clamp_scalar"(%595, %596) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x14x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc531)
    %598 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc341)
    %599 = "ttir.transpose"(%597, %598) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x14x14xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc341)
    %600 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc342)
    %601 = "ttir.transpose"(%599, %600) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc342)
    %602 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc343)
    %603 = "ttir.conv2d"(%601, %arg143, %602) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x576xbf16>, tensor<96x576x1x1xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc343)
    %604 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc344)
    %605 = "ttir.transpose"(%603, %604) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x96xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc344)
    %606 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc345)
    %607 = "ttir.transpose"(%605, %606) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc345)
    %608 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc78)
    %609 = "ttir.multiply"(%607, %arg77, %608) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc78)
    %610 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc79)
    %611 = "ttir.add"(%609, %arg78, %610) : (tensor<8x96x14x14xbf16>, tensor<1x96x1x1xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc79)
    %612 = ttir.empty() : tensor<8x96x14x14xbf16> loc(#loc159)
    %613 = "ttir.add"(%565, %611, %612) : (tensor<8x96x14x14xbf16>, tensor<8x96x14x14xbf16>, tensor<8x96x14x14xbf16>) -> tensor<8x96x14x14xbf16> loc(#loc159)
    %614 = ttir.empty() : tensor<8x14x96x14xbf16> loc(#loc532)
    %615 = "ttir.transpose"(%613, %614) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x96x14x14xbf16>, tensor<8x14x96x14xbf16>) -> tensor<8x14x96x14xbf16> loc(#loc532)
    %616 = ttir.empty() : tensor<8x14x14x96xbf16> loc(#loc533)
    %617 = "ttir.transpose"(%615, %616) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x96x14xbf16>, tensor<8x14x14x96xbf16>) -> tensor<8x14x14x96xbf16> loc(#loc533)
    %618 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc534)
    %619 = "ttir.conv2d"(%617, %arg144, %618) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x96xbf16>, tensor<576x96x1x1xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc534)
    %620 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc535)
    %621 = "ttir.transpose"(%619, %620) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x576xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc535)
    %622 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc536)
    %623 = "ttir.transpose"(%621, %622) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc536)
    %624 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc80)
    %625 = "ttir.multiply"(%623, %arg79, %624) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc80)
    %626 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc81)
    %627 = "ttir.add"(%625, %arg80, %626) : (tensor<8x576x14x14xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc81)
    %628 = ttir.empty() : tensor<8x576x14x14xbf16> loc(#loc537)
    %629 = "ttir.clamp_scalar"(%627, %628) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x14x14xbf16>, tensor<8x576x14x14xbf16>) -> tensor<8x576x14x14xbf16> loc(#loc537)
    %630 = ttir.empty() : tensor<8x14x576x14xbf16> loc(#loc538)
    %631 = "ttir.transpose"(%629, %630) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x14x14xbf16>, tensor<8x14x576x14xbf16>) -> tensor<8x14x576x14xbf16> loc(#loc538)
    %632 = ttir.empty() : tensor<8x14x14x576xbf16> loc(#loc539)
    %633 = "ttir.transpose"(%631, %632) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x576x14xbf16>, tensor<8x14x14x576xbf16>) -> tensor<8x14x14x576xbf16> loc(#loc539)
    %634 = ttir.empty() : tensor<8x7x7x576xbf16> loc(#loc540)
    %635 = "ttir.conv2d"(%633, %arg145, %634) <{dilation = array<i32: 1, 1>, groups = 576 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x14x14x576xbf16>, tensor<576x1x3x3xbf16>, tensor<8x7x7x576xbf16>) -> tensor<8x7x7x576xbf16> loc(#loc540)
    %636 = ttir.empty() : tensor<8x7x576x7xbf16> loc(#loc541)
    %637 = "ttir.transpose"(%635, %636) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x576xbf16>, tensor<8x7x576x7xbf16>) -> tensor<8x7x576x7xbf16> loc(#loc541)
    %638 = ttir.empty() : tensor<8x576x7x7xbf16> loc(#loc542)
    %639 = "ttir.transpose"(%637, %638) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x576x7xbf16>, tensor<8x576x7x7xbf16>) -> tensor<8x576x7x7xbf16> loc(#loc542)
    %640 = ttir.empty() : tensor<8x576x7x7xbf16> loc(#loc82)
    %641 = "ttir.multiply"(%639, %arg81, %640) : (tensor<8x576x7x7xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x7x7xbf16>) -> tensor<8x576x7x7xbf16> loc(#loc82)
    %642 = ttir.empty() : tensor<8x576x7x7xbf16> loc(#loc83)
    %643 = "ttir.add"(%641, %arg82, %642) : (tensor<8x576x7x7xbf16>, tensor<1x576x1x1xbf16>, tensor<8x576x7x7xbf16>) -> tensor<8x576x7x7xbf16> loc(#loc83)
    %644 = ttir.empty() : tensor<8x576x7x7xbf16> loc(#loc543)
    %645 = "ttir.clamp_scalar"(%643, %644) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x576x7x7xbf16>, tensor<8x576x7x7xbf16>) -> tensor<8x576x7x7xbf16> loc(#loc543)
    %646 = ttir.empty() : tensor<8x7x576x7xbf16> loc(#loc350)
    %647 = "ttir.transpose"(%645, %646) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x576x7x7xbf16>, tensor<8x7x576x7xbf16>) -> tensor<8x7x576x7xbf16> loc(#loc350)
    %648 = ttir.empty() : tensor<8x7x7x576xbf16> loc(#loc351)
    %649 = "ttir.transpose"(%647, %648) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x576x7xbf16>, tensor<8x7x7x576xbf16>) -> tensor<8x7x7x576xbf16> loc(#loc351)
    %650 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc352)
    %651 = "ttir.conv2d"(%649, %arg146, %650) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x576xbf16>, tensor<160x576x1x1xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc352)
    %652 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc353)
    %653 = "ttir.transpose"(%651, %652) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x160xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc353)
    %654 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc354)
    %655 = "ttir.transpose"(%653, %654) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc354)
    %656 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc84)
    %657 = "ttir.multiply"(%655, %arg83, %656) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc84)
    %658 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc85)
    %659 = "ttir.add"(%657, %arg84, %658) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc85)
    %660 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc544)
    %661 = "ttir.transpose"(%659, %660) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x7x7xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc544)
    %662 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc545)
    %663 = "ttir.transpose"(%661, %662) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc545)
    %664 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc546)
    %665 = "ttir.conv2d"(%663, %arg147, %664) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x160xbf16>, tensor<960x160x1x1xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc546)
    %666 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc547)
    %667 = "ttir.transpose"(%665, %666) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc547)
    %668 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc548)
    %669 = "ttir.transpose"(%667, %668) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc548)
    %670 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc86)
    %671 = "ttir.multiply"(%669, %arg85, %670) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc86)
    %672 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc87)
    %673 = "ttir.add"(%671, %arg86, %672) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc87)
    %674 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc549)
    %675 = "ttir.clamp_scalar"(%673, %674) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc549)
    %676 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc550)
    %677 = "ttir.transpose"(%675, %676) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc550)
    %678 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc551)
    %679 = "ttir.transpose"(%677, %678) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc551)
    %680 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc552)
    %681 = "ttir.conv2d"(%679, %arg148, %680) <{dilation = array<i32: 1, 1>, groups = 960 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<960x1x3x3xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc552)
    %682 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc553)
    %683 = "ttir.transpose"(%681, %682) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc553)
    %684 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc554)
    %685 = "ttir.transpose"(%683, %684) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc554)
    %686 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc88)
    %687 = "ttir.multiply"(%685, %arg87, %686) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc88)
    %688 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc89)
    %689 = "ttir.add"(%687, %arg88, %688) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc89)
    %690 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc555)
    %691 = "ttir.clamp_scalar"(%689, %690) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc555)
    %692 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc359)
    %693 = "ttir.transpose"(%691, %692) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc359)
    %694 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc360)
    %695 = "ttir.transpose"(%693, %694) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc360)
    %696 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc361)
    %697 = "ttir.conv2d"(%695, %arg149, %696) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<160x960x1x1xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc361)
    %698 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc362)
    %699 = "ttir.transpose"(%697, %698) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x160xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc362)
    %700 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc363)
    %701 = "ttir.transpose"(%699, %700) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc363)
    %702 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc90)
    %703 = "ttir.multiply"(%701, %arg89, %702) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc90)
    %704 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc91)
    %705 = "ttir.add"(%703, %arg90, %704) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc91)
    %706 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc162)
    %707 = "ttir.add"(%659, %705, %706) : (tensor<8x160x7x7xbf16>, tensor<8x160x7x7xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc162)
    %708 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc556)
    %709 = "ttir.transpose"(%707, %708) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x7x7xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc556)
    %710 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc557)
    %711 = "ttir.transpose"(%709, %710) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc557)
    %712 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc558)
    %713 = "ttir.conv2d"(%711, %arg150, %712) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x160xbf16>, tensor<960x160x1x1xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc558)
    %714 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc559)
    %715 = "ttir.transpose"(%713, %714) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc559)
    %716 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc560)
    %717 = "ttir.transpose"(%715, %716) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc560)
    %718 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc92)
    %719 = "ttir.multiply"(%717, %arg91, %718) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc92)
    %720 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc93)
    %721 = "ttir.add"(%719, %arg92, %720) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc93)
    %722 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc561)
    %723 = "ttir.clamp_scalar"(%721, %722) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc561)
    %724 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc562)
    %725 = "ttir.transpose"(%723, %724) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc562)
    %726 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc563)
    %727 = "ttir.transpose"(%725, %726) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc563)
    %728 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc564)
    %729 = "ttir.conv2d"(%727, %arg151, %728) <{dilation = array<i32: 1, 1>, groups = 960 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<960x1x3x3xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc564)
    %730 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc565)
    %731 = "ttir.transpose"(%729, %730) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc565)
    %732 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc566)
    %733 = "ttir.transpose"(%731, %732) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc566)
    %734 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc94)
    %735 = "ttir.multiply"(%733, %arg93, %734) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc94)
    %736 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc95)
    %737 = "ttir.add"(%735, %arg94, %736) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc95)
    %738 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc567)
    %739 = "ttir.clamp_scalar"(%737, %738) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc567)
    %740 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc368)
    %741 = "ttir.transpose"(%739, %740) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc368)
    %742 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc369)
    %743 = "ttir.transpose"(%741, %742) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc369)
    %744 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc370)
    %745 = "ttir.conv2d"(%743, %arg152, %744) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<160x960x1x1xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc370)
    %746 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc371)
    %747 = "ttir.transpose"(%745, %746) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x160xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc371)
    %748 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc372)
    %749 = "ttir.transpose"(%747, %748) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc372)
    %750 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc96)
    %751 = "ttir.multiply"(%749, %arg95, %750) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc96)
    %752 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc97)
    %753 = "ttir.add"(%751, %arg96, %752) : (tensor<8x160x7x7xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc97)
    %754 = ttir.empty() : tensor<8x160x7x7xbf16> loc(#loc164)
    %755 = "ttir.add"(%707, %753, %754) : (tensor<8x160x7x7xbf16>, tensor<8x160x7x7xbf16>, tensor<8x160x7x7xbf16>) -> tensor<8x160x7x7xbf16> loc(#loc164)
    %756 = ttir.empty() : tensor<8x7x160x7xbf16> loc(#loc568)
    %757 = "ttir.transpose"(%755, %756) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x7x7xbf16>, tensor<8x7x160x7xbf16>) -> tensor<8x7x160x7xbf16> loc(#loc568)
    %758 = ttir.empty() : tensor<8x7x7x160xbf16> loc(#loc569)
    %759 = "ttir.transpose"(%757, %758) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x160x7xbf16>, tensor<8x7x7x160xbf16>) -> tensor<8x7x7x160xbf16> loc(#loc569)
    %760 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc570)
    %761 = "ttir.conv2d"(%759, %arg153, %760) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x160xbf16>, tensor<960x160x1x1xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc570)
    %762 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc571)
    %763 = "ttir.transpose"(%761, %762) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc571)
    %764 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc572)
    %765 = "ttir.transpose"(%763, %764) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc572)
    %766 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc98)
    %767 = "ttir.multiply"(%765, %arg97, %766) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc98)
    %768 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc99)
    %769 = "ttir.add"(%767, %arg98, %768) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc99)
    %770 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc573)
    %771 = "ttir.clamp_scalar"(%769, %770) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc573)
    %772 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc574)
    %773 = "ttir.transpose"(%771, %772) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc574)
    %774 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc575)
    %775 = "ttir.transpose"(%773, %774) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc575)
    %776 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc576)
    %777 = "ttir.conv2d"(%775, %arg154, %776) <{dilation = array<i32: 1, 1>, groups = 960 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<960x1x3x3xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc576)
    %778 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc577)
    %779 = "ttir.transpose"(%777, %778) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x960xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc577)
    %780 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc578)
    %781 = "ttir.transpose"(%779, %780) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc578)
    %782 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc100)
    %783 = "ttir.multiply"(%781, %arg99, %782) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc100)
    %784 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc101)
    %785 = "ttir.add"(%783, %arg100, %784) : (tensor<8x960x7x7xbf16>, tensor<1x960x1x1xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc101)
    %786 = ttir.empty() : tensor<8x960x7x7xbf16> loc(#loc579)
    %787 = "ttir.clamp_scalar"(%785, %786) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x960x7x7xbf16>, tensor<8x960x7x7xbf16>) -> tensor<8x960x7x7xbf16> loc(#loc579)
    %788 = ttir.empty() : tensor<8x7x960x7xbf16> loc(#loc377)
    %789 = "ttir.transpose"(%787, %788) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x960x7x7xbf16>, tensor<8x7x960x7xbf16>) -> tensor<8x7x960x7xbf16> loc(#loc377)
    %790 = ttir.empty() : tensor<8x7x7x960xbf16> loc(#loc378)
    %791 = "ttir.transpose"(%789, %790) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x960x7xbf16>, tensor<8x7x7x960xbf16>) -> tensor<8x7x7x960xbf16> loc(#loc378)
    %792 = ttir.empty() : tensor<8x7x7x320xbf16> loc(#loc379)
    %793 = "ttir.conv2d"(%791, %arg155, %792) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x960xbf16>, tensor<320x960x1x1xbf16>, tensor<8x7x7x320xbf16>) -> tensor<8x7x7x320xbf16> loc(#loc379)
    %794 = ttir.empty() : tensor<8x7x320x7xbf16> loc(#loc380)
    %795 = "ttir.transpose"(%793, %794) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x320xbf16>, tensor<8x7x320x7xbf16>) -> tensor<8x7x320x7xbf16> loc(#loc380)
    %796 = ttir.empty() : tensor<8x320x7x7xbf16> loc(#loc381)
    %797 = "ttir.transpose"(%795, %796) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x320x7xbf16>, tensor<8x320x7x7xbf16>) -> tensor<8x320x7x7xbf16> loc(#loc381)
    %798 = ttir.empty() : tensor<8x320x7x7xbf16> loc(#loc102)
    %799 = "ttir.multiply"(%797, %arg101, %798) : (tensor<8x320x7x7xbf16>, tensor<1x320x1x1xbf16>, tensor<8x320x7x7xbf16>) -> tensor<8x320x7x7xbf16> loc(#loc102)
    %800 = ttir.empty() : tensor<8x320x7x7xbf16> loc(#loc103)
    %801 = "ttir.add"(%799, %arg102, %800) : (tensor<8x320x7x7xbf16>, tensor<1x320x1x1xbf16>, tensor<8x320x7x7xbf16>) -> tensor<8x320x7x7xbf16> loc(#loc103)
    %802 = ttir.empty() : tensor<8x7x320x7xbf16> loc(#loc225)
    %803 = "ttir.transpose"(%801, %802) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x320x7x7xbf16>, tensor<8x7x320x7xbf16>) -> tensor<8x7x320x7xbf16> loc(#loc225)
    %804 = ttir.empty() : tensor<8x7x7x320xbf16> loc(#loc226)
    %805 = "ttir.transpose"(%803, %804) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x320x7xbf16>, tensor<8x7x7x320xbf16>) -> tensor<8x7x7x320xbf16> loc(#loc226)
    %806 = ttir.empty() : tensor<8x7x7x1280xbf16> loc(#loc227)
    %807 = "ttir.conv2d"(%805, %arg156, %806) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x320xbf16>, tensor<1280x320x1x1xbf16>, tensor<8x7x7x1280xbf16>) -> tensor<8x7x7x1280xbf16> loc(#loc227)
    %808 = ttir.empty() : tensor<8x7x1280x7xbf16> loc(#loc228)
    %809 = "ttir.transpose"(%807, %808) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x1280xbf16>, tensor<8x7x1280x7xbf16>) -> tensor<8x7x1280x7xbf16> loc(#loc228)
    %810 = ttir.empty() : tensor<8x1280x7x7xbf16> loc(#loc229)
    %811 = "ttir.transpose"(%809, %810) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x1280x7xbf16>, tensor<8x1280x7x7xbf16>) -> tensor<8x1280x7x7xbf16> loc(#loc229)
    %812 = ttir.empty() : tensor<8x1280x7x7xbf16> loc(#loc104)
    %813 = "ttir.multiply"(%811, %arg103, %812) : (tensor<8x1280x7x7xbf16>, tensor<1x1280x1x1xbf16>, tensor<8x1280x7x7xbf16>) -> tensor<8x1280x7x7xbf16> loc(#loc104)
    %814 = ttir.empty() : tensor<8x1280x7x7xbf16> loc(#loc105)
    %815 = "ttir.add"(%813, %arg104, %814) : (tensor<8x1280x7x7xbf16>, tensor<1x1280x1x1xbf16>, tensor<8x1280x7x7xbf16>) -> tensor<8x1280x7x7xbf16> loc(#loc105)
    %816 = ttir.empty() : tensor<8x1280x7x7xbf16> loc(#loc230)
    %817 = "ttir.clamp_scalar"(%815, %816) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x1280x7x7xbf16>, tensor<8x1280x7x7xbf16>) -> tensor<8x1280x7x7xbf16> loc(#loc230)
    %818 = ttir.empty() : tensor<8x1x1280x49xbf16> loc(#loc110)
    %819 = "ttir.reshape"(%817, %818) <{shape = [8 : i32, 1 : i32, 1280 : i32, 49 : i32]}> : (tensor<8x1280x7x7xbf16>, tensor<8x1x1280x49xbf16>) -> tensor<8x1x1280x49xbf16> loc(#loc110)
    %820 = ttir.empty() : tensor<8x1x49x1280xbf16> loc(#loc111)
    %821 = "ttir.transpose"(%819, %820) <{dim0 = 2 : si32, dim1 = 3 : si32}> : (tensor<8x1x1280x49xbf16>, tensor<8x1x49x1280xbf16>) -> tensor<8x1x49x1280xbf16> loc(#loc111)
    %822 = ttir.empty() : tensor<8x1x1x1280xbf16> loc(#loc112)
    %823 = "ttir.mean"(%821, %822) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x1x49x1280xbf16>, tensor<8x1x1x1280xbf16>) -> tensor<8x1x1x1280xbf16> loc(#loc112)
    %824 = ttir.empty() : tensor<8x1x1280x1xbf16> loc(#loc113)
    %825 = "ttir.transpose"(%823, %824) <{dim0 = 2 : si32, dim1 = 3 : si32}> : (tensor<8x1x1x1280xbf16>, tensor<8x1x1280x1xbf16>) -> tensor<8x1x1280x1xbf16> loc(#loc113)
    %826 = ttir.empty() : tensor<8x1280x1x1xbf16> loc(#loc114)
    %827 = "ttir.reshape"(%825, %826) <{shape = [8 : i32, 1280 : i32, 1 : i32, 1 : i32]}> : (tensor<8x1x1280x1xbf16>, tensor<8x1280x1x1xbf16>) -> tensor<8x1280x1x1xbf16> loc(#loc114)
    %828 = ttir.empty() : tensor<8x1280x1xbf16> loc(#loc106)
    %829 = "ttir.squeeze"(%827, %828) <{dim = -2 : si32}> : (tensor<8x1280x1x1xbf16>, tensor<8x1280x1xbf16>) -> tensor<8x1280x1xbf16> loc(#loc106)
    %830 = ttir.empty() : tensor<8x1280xbf16> loc(#loc115)
    %831 = "ttir.squeeze"(%829, %830) <{dim = -1 : si32}> : (tensor<8x1280x1xbf16>, tensor<8x1280xbf16>) -> tensor<8x1280xbf16> loc(#loc115)
    %832 = ttir.empty() : tensor<8x1000xbf16> loc(#loc168)
    %833 = "ttir.matmul"(%831, %arg157, %832) <{transpose_a = false, transpose_b = false}> : (tensor<8x1280xbf16>, tensor<1280x1000xbf16>, tensor<8x1000xbf16>) -> tensor<8x1000xbf16> loc(#loc168)
    %834 = ttir.empty() : tensor<8x1000xbf16> loc(#loc107)
    %835 = "ttir.add"(%833, %arg158, %834) : (tensor<8x1000xbf16>, tensor<1000xbf16>, tensor<8x1000xbf16>) -> tensor<8x1000xbf16> loc(#loc107)
    return %835 : tensor<8x1000xbf16> loc(#loc108)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("torchvision.models.mobilenetv2.MobileNetV2::")
#loc2 = loc("multiply_7")
#loc3 = loc("add_13")
#loc4 = loc("multiply_23")
#loc5 = loc("add_29")
#loc6 = loc("multiply_38")
#loc7 = loc("add_44")
#loc8 = loc("multiply_52")
#loc9 = loc("add_58")
#loc10 = loc("multiply_68")
#loc11 = loc("add_74")
#loc12 = loc("multiply_83")
#loc13 = loc("add_89")
#loc14 = loc("multiply_97")
#loc15 = loc("add_103")
#loc16 = loc("multiply_113")
#loc17 = loc("add_119")
#loc18 = loc("multiply_128")
#loc19 = loc("add_134")
#loc20 = loc("multiply_143")
#loc21 = loc("add_149")
#loc22 = loc("multiply_159")
#loc23 = loc("add_165")
#loc24 = loc("multiply_174")
#loc25 = loc("add_180")
#loc26 = loc("multiply_188")
#loc27 = loc("add_194")
#loc28 = loc("multiply_204")
#loc29 = loc("add_210")
#loc30 = loc("multiply_219")
#loc31 = loc("add_225")
#loc32 = loc("multiply_234")
#loc33 = loc("add_240")
#loc34 = loc("multiply_250")
#loc35 = loc("add_256")
#loc36 = loc("multiply_265")
#loc37 = loc("add_271")
#loc38 = loc("multiply_280")
#loc39 = loc("add_286")
#loc40 = loc("multiply_296")
#loc41 = loc("add_302")
#loc42 = loc("multiply_311")
#loc43 = loc("add_317")
#loc44 = loc("multiply_325")
#loc45 = loc("add_331")
#loc46 = loc("multiply_341")
#loc47 = loc("add_347")
#loc48 = loc("multiply_356")
#loc49 = loc("add_362")
#loc50 = loc("multiply_371")
#loc51 = loc("add_377")
#loc52 = loc("multiply_387")
#loc53 = loc("add_393")
#loc54 = loc("multiply_402")
#loc55 = loc("add_408")
#loc56 = loc("multiply_417")
#loc57 = loc("add_423")
#loc58 = loc("multiply_433")
#loc59 = loc("add_439")
#loc60 = loc("multiply_448")
#loc61 = loc("add_454")
#loc62 = loc("multiply_463")
#loc63 = loc("add_469")
#loc64 = loc("multiply_479")
#loc65 = loc("add_485")
#loc66 = loc("multiply_494")
#loc67 = loc("add_500")
#loc68 = loc("multiply_508")
#loc69 = loc("add_514")
#loc70 = loc("multiply_524")
#loc71 = loc("add_530")
#loc72 = loc("multiply_539")
#loc73 = loc("add_545")
#loc74 = loc("multiply_554")
#loc75 = loc("add_560")
#loc76 = loc("multiply_570")
#loc77 = loc("add_576")
#loc78 = loc("multiply_585")
#loc79 = loc("add_591")
#loc80 = loc("multiply_600")
#loc81 = loc("add_606")
#loc82 = loc("multiply_616")
#loc83 = loc("add_622")
#loc84 = loc("multiply_631")
#loc85 = loc("add_637")
#loc86 = loc("multiply_645")
#loc87 = loc("add_651")
#loc88 = loc("multiply_661")
#loc89 = loc("add_667")
#loc90 = loc("multiply_676")
#loc91 = loc("add_682")
#loc92 = loc("multiply_691")
#loc93 = loc("add_697")
#loc94 = loc("multiply_707")
#loc95 = loc("add_713")
#loc96 = loc("multiply_722")
#loc97 = loc("add_728")
#loc98 = loc("multiply_737")
#loc99 = loc("add_743")
#loc100 = loc("multiply_753")
#loc101 = loc("add_759")
#loc102 = loc("multiply_768")
#loc103 = loc("add_774")
#loc104 = loc("multiply_782")
#loc105 = loc("add_788")
#loc106 = loc("squeeze_792")
#loc107 = loc("add_797")
#loc108 = loc(unknown)
#loc109 = loc("torch.nn.modules.container.Sequential::features"(#loc1))
#loc110 = loc("avg_pool2d_790.dc.reshape.0"(#loc1))
#loc111 = loc("avg_pool2d_790.dc.transpose.1"(#loc1))
#loc112 = loc("avg_pool2d_790.dc.reduce_avg.2"(#loc1))
#loc113 = loc("avg_pool2d_790.dc.transpose.3"(#loc1))
#loc114 = loc("avg_pool2d_790.dc.reshape.4"(#loc1))
#loc115 = loc("squeeze_793"(#loc1))
#loc116 = loc("torch.nn.modules.container.Sequential::classifier"(#loc1))
#loc117 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc109))
#loc118 = loc("torchvision.models.mobilenetv2.InvertedResidual::1"(#loc109))
#loc119 = loc("torchvision.models.mobilenetv2.InvertedResidual::2"(#loc109))
#loc120 = loc("torchvision.models.mobilenetv2.InvertedResidual::3"(#loc109))
#loc121 = loc("torchvision.models.mobilenetv2.InvertedResidual::4"(#loc109))
#loc122 = loc("torchvision.models.mobilenetv2.InvertedResidual::5"(#loc109))
#loc123 = loc("torchvision.models.mobilenetv2.InvertedResidual::6"(#loc109))
#loc124 = loc("torchvision.models.mobilenetv2.InvertedResidual::7"(#loc109))
#loc125 = loc("torchvision.models.mobilenetv2.InvertedResidual::8"(#loc109))
#loc126 = loc("torchvision.models.mobilenetv2.InvertedResidual::9"(#loc109))
#loc127 = loc("torchvision.models.mobilenetv2.InvertedResidual::10"(#loc109))
#loc128 = loc("torchvision.models.mobilenetv2.InvertedResidual::11"(#loc109))
#loc129 = loc("torchvision.models.mobilenetv2.InvertedResidual::12"(#loc109))
#loc130 = loc("torchvision.models.mobilenetv2.InvertedResidual::13"(#loc109))
#loc131 = loc("torchvision.models.mobilenetv2.InvertedResidual::14"(#loc109))
#loc132 = loc("torchvision.models.mobilenetv2.InvertedResidual::15"(#loc109))
#loc133 = loc("torchvision.models.mobilenetv2.InvertedResidual::16"(#loc109))
#loc134 = loc("torchvision.models.mobilenetv2.InvertedResidual::17"(#loc109))
#loc135 = loc("torchvision.ops.misc.Conv2dNormActivation::18"(#loc109))
#loc136 = loc("torch.nn.modules.linear.Linear::1"(#loc116))
#loc137 = loc("torch.nn.modules.conv.Conv2d::0"(#loc117))
#loc138 = loc("torch.nn.modules.activation.ReLU6::2"(#loc117))
#loc139 = loc("torch.nn.modules.container.Sequential::conv"(#loc118))
#loc140 = loc("torch.nn.modules.container.Sequential::conv"(#loc119))
#loc141 = loc("torch.nn.modules.container.Sequential::conv"(#loc120))
#loc142 = loc("add_135"(#loc120))
#loc143 = loc("torch.nn.modules.container.Sequential::conv"(#loc121))
#loc144 = loc("torch.nn.modules.container.Sequential::conv"(#loc122))
#loc145 = loc("add_226"(#loc122))
#loc146 = loc("torch.nn.modules.container.Sequential::conv"(#loc123))
#loc147 = loc("add_272"(#loc123))
#loc148 = loc("torch.nn.modules.container.Sequential::conv"(#loc124))
#loc149 = loc("torch.nn.modules.container.Sequential::conv"(#loc125))
#loc150 = loc("add_363"(#loc125))
#loc151 = loc("torch.nn.modules.container.Sequential::conv"(#loc126))
#loc152 = loc("add_409"(#loc126))
#loc153 = loc("torch.nn.modules.container.Sequential::conv"(#loc127))
#loc154 = loc("add_455"(#loc127))
#loc155 = loc("torch.nn.modules.container.Sequential::conv"(#loc128))
#loc156 = loc("torch.nn.modules.container.Sequential::conv"(#loc129))
#loc157 = loc("add_546"(#loc129))
#loc158 = loc("torch.nn.modules.container.Sequential::conv"(#loc130))
#loc159 = loc("add_592"(#loc130))
#loc160 = loc("torch.nn.modules.container.Sequential::conv"(#loc131))
#loc161 = loc("torch.nn.modules.container.Sequential::conv"(#loc132))
#loc162 = loc("add_683"(#loc132))
#loc163 = loc("torch.nn.modules.container.Sequential::conv"(#loc133))
#loc164 = loc("add_729"(#loc133))
#loc165 = loc("torch.nn.modules.container.Sequential::conv"(#loc134))
#loc166 = loc("torch.nn.modules.conv.Conv2d::0"(#loc135))
#loc167 = loc("torch.nn.modules.activation.ReLU6::2"(#loc135))
#loc168 = loc("matmul_796"(#loc136))
#loc169 = loc("conv2d_0.dc.transpose.0"(#loc137))
#loc170 = loc("conv2d_0.dc.transpose.1"(#loc137))
#loc171 = loc("conv2d_0.dc.conv2d.2"(#loc137))
#loc172 = loc("conv2d_0.dc.transpose.3"(#loc137))
#loc173 = loc("conv2d_0.dc.transpose.4"(#loc137))
#loc174 = loc("clip_14"(#loc138))
#loc175 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc139))
#loc176 = loc("torch.nn.modules.conv.Conv2d::1"(#loc139))
#loc177 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc140))
#loc178 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc140))
#loc179 = loc("torch.nn.modules.conv.Conv2d::2"(#loc140))
#loc180 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc141))
#loc181 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc141))
#loc182 = loc("torch.nn.modules.conv.Conv2d::2"(#loc141))
#loc183 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc143))
#loc184 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc143))
#loc185 = loc("torch.nn.modules.conv.Conv2d::2"(#loc143))
#loc186 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc144))
#loc187 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc144))
#loc188 = loc("torch.nn.modules.conv.Conv2d::2"(#loc144))
#loc189 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc146))
#loc190 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc146))
#loc191 = loc("torch.nn.modules.conv.Conv2d::2"(#loc146))
#loc192 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc148))
#loc193 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc148))
#loc194 = loc("torch.nn.modules.conv.Conv2d::2"(#loc148))
#loc195 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc149))
#loc196 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc149))
#loc197 = loc("torch.nn.modules.conv.Conv2d::2"(#loc149))
#loc198 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc151))
#loc199 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc151))
#loc200 = loc("torch.nn.modules.conv.Conv2d::2"(#loc151))
#loc201 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc153))
#loc202 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc153))
#loc203 = loc("torch.nn.modules.conv.Conv2d::2"(#loc153))
#loc204 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc155))
#loc205 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc155))
#loc206 = loc("torch.nn.modules.conv.Conv2d::2"(#loc155))
#loc207 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc156))
#loc208 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc156))
#loc209 = loc("torch.nn.modules.conv.Conv2d::2"(#loc156))
#loc210 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc158))
#loc211 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc158))
#loc212 = loc("torch.nn.modules.conv.Conv2d::2"(#loc158))
#loc213 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc160))
#loc214 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc160))
#loc215 = loc("torch.nn.modules.conv.Conv2d::2"(#loc160))
#loc216 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc161))
#loc217 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc161))
#loc218 = loc("torch.nn.modules.conv.Conv2d::2"(#loc161))
#loc219 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc163))
#loc220 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc163))
#loc221 = loc("torch.nn.modules.conv.Conv2d::2"(#loc163))
#loc222 = loc("torchvision.ops.misc.Conv2dNormActivation::0"(#loc165))
#loc223 = loc("torchvision.ops.misc.Conv2dNormActivation::1"(#loc165))
#loc224 = loc("torch.nn.modules.conv.Conv2d::2"(#loc165))
#loc225 = loc("conv2d_775.dc.transpose.0"(#loc166))
#loc226 = loc("conv2d_775.dc.transpose.1"(#loc166))
#loc227 = loc("conv2d_775.dc.conv2d.2"(#loc166))
#loc228 = loc("conv2d_775.dc.transpose.3"(#loc166))
#loc229 = loc("conv2d_775.dc.transpose.4"(#loc166))
#loc230 = loc("clip_789"(#loc167))
#loc231 = loc("torch.nn.modules.conv.Conv2d::0"(#loc175))
#loc232 = loc("torch.nn.modules.activation.ReLU6::2"(#loc175))
#loc233 = loc("conv2d_31.dc.transpose.0"(#loc176))
#loc234 = loc("conv2d_31.dc.transpose.1"(#loc176))
#loc235 = loc("conv2d_31.dc.conv2d.2"(#loc176))
#loc236 = loc("conv2d_31.dc.transpose.3"(#loc176))
#loc237 = loc("conv2d_31.dc.transpose.4"(#loc176))
#loc238 = loc("torch.nn.modules.conv.Conv2d::0"(#loc177))
#loc239 = loc("torch.nn.modules.activation.ReLU6::2"(#loc177))
#loc240 = loc("torch.nn.modules.conv.Conv2d::0"(#loc178))
#loc241 = loc("torch.nn.modules.activation.ReLU6::2"(#loc178))
#loc242 = loc("conv2d_76.dc.transpose.0"(#loc179))
#loc243 = loc("conv2d_76.dc.transpose.1"(#loc179))
#loc244 = loc("conv2d_76.dc.conv2d.2"(#loc179))
#loc245 = loc("conv2d_76.dc.transpose.3"(#loc179))
#loc246 = loc("conv2d_76.dc.transpose.4"(#loc179))
#loc247 = loc("torch.nn.modules.conv.Conv2d::0"(#loc180))
#loc248 = loc("torch.nn.modules.activation.ReLU6::2"(#loc180))
#loc249 = loc("torch.nn.modules.conv.Conv2d::0"(#loc181))
#loc250 = loc("torch.nn.modules.activation.ReLU6::2"(#loc181))
#loc251 = loc("conv2d_121.dc.transpose.0"(#loc182))
#loc252 = loc("conv2d_121.dc.transpose.1"(#loc182))
#loc253 = loc("conv2d_121.dc.conv2d.2"(#loc182))
#loc254 = loc("conv2d_121.dc.transpose.3"(#loc182))
#loc255 = loc("conv2d_121.dc.transpose.4"(#loc182))
#loc256 = loc("torch.nn.modules.conv.Conv2d::0"(#loc183))
#loc257 = loc("torch.nn.modules.activation.ReLU6::2"(#loc183))
#loc258 = loc("torch.nn.modules.conv.Conv2d::0"(#loc184))
#loc259 = loc("torch.nn.modules.activation.ReLU6::2"(#loc184))
#loc260 = loc("conv2d_167.dc.transpose.0"(#loc185))
#loc261 = loc("conv2d_167.dc.transpose.1"(#loc185))
#loc262 = loc("conv2d_167.dc.conv2d.2"(#loc185))
#loc263 = loc("conv2d_167.dc.transpose.3"(#loc185))
#loc264 = loc("conv2d_167.dc.transpose.4"(#loc185))
#loc265 = loc("torch.nn.modules.conv.Conv2d::0"(#loc186))
#loc266 = loc("torch.nn.modules.activation.ReLU6::2"(#loc186))
#loc267 = loc("torch.nn.modules.conv.Conv2d::0"(#loc187))
#loc268 = loc("torch.nn.modules.activation.ReLU6::2"(#loc187))
#loc269 = loc("conv2d_212.dc.transpose.0"(#loc188))
#loc270 = loc("conv2d_212.dc.transpose.1"(#loc188))
#loc271 = loc("conv2d_212.dc.conv2d.2"(#loc188))
#loc272 = loc("conv2d_212.dc.transpose.3"(#loc188))
#loc273 = loc("conv2d_212.dc.transpose.4"(#loc188))
#loc274 = loc("torch.nn.modules.conv.Conv2d::0"(#loc189))
#loc275 = loc("torch.nn.modules.activation.ReLU6::2"(#loc189))
#loc276 = loc("torch.nn.modules.conv.Conv2d::0"(#loc190))
#loc277 = loc("torch.nn.modules.activation.ReLU6::2"(#loc190))
#loc278 = loc("conv2d_258.dc.transpose.0"(#loc191))
#loc279 = loc("conv2d_258.dc.transpose.1"(#loc191))
#loc280 = loc("conv2d_258.dc.conv2d.2"(#loc191))
#loc281 = loc("conv2d_258.dc.transpose.3"(#loc191))
#loc282 = loc("conv2d_258.dc.transpose.4"(#loc191))
#loc283 = loc("torch.nn.modules.conv.Conv2d::0"(#loc192))
#loc284 = loc("torch.nn.modules.activation.ReLU6::2"(#loc192))
#loc285 = loc("torch.nn.modules.conv.Conv2d::0"(#loc193))
#loc286 = loc("torch.nn.modules.activation.ReLU6::2"(#loc193))
#loc287 = loc("conv2d_304.dc.transpose.0"(#loc194))
#loc288 = loc("conv2d_304.dc.transpose.1"(#loc194))
#loc289 = loc("conv2d_304.dc.conv2d.2"(#loc194))
#loc290 = loc("conv2d_304.dc.transpose.3"(#loc194))
#loc291 = loc("conv2d_304.dc.transpose.4"(#loc194))
#loc292 = loc("torch.nn.modules.conv.Conv2d::0"(#loc195))
#loc293 = loc("torch.nn.modules.activation.ReLU6::2"(#loc195))
#loc294 = loc("torch.nn.modules.conv.Conv2d::0"(#loc196))
#loc295 = loc("torch.nn.modules.activation.ReLU6::2"(#loc196))
#loc296 = loc("conv2d_349.dc.transpose.0"(#loc197))
#loc297 = loc("conv2d_349.dc.transpose.1"(#loc197))
#loc298 = loc("conv2d_349.dc.conv2d.2"(#loc197))
#loc299 = loc("conv2d_349.dc.transpose.3"(#loc197))
#loc300 = loc("conv2d_349.dc.transpose.4"(#loc197))
#loc301 = loc("torch.nn.modules.conv.Conv2d::0"(#loc198))
#loc302 = loc("torch.nn.modules.activation.ReLU6::2"(#loc198))
#loc303 = loc("torch.nn.modules.conv.Conv2d::0"(#loc199))
#loc304 = loc("torch.nn.modules.activation.ReLU6::2"(#loc199))
#loc305 = loc("conv2d_395.dc.transpose.0"(#loc200))
#loc306 = loc("conv2d_395.dc.transpose.1"(#loc200))
#loc307 = loc("conv2d_395.dc.conv2d.2"(#loc200))
#loc308 = loc("conv2d_395.dc.transpose.3"(#loc200))
#loc309 = loc("conv2d_395.dc.transpose.4"(#loc200))
#loc310 = loc("torch.nn.modules.conv.Conv2d::0"(#loc201))
#loc311 = loc("torch.nn.modules.activation.ReLU6::2"(#loc201))
#loc312 = loc("torch.nn.modules.conv.Conv2d::0"(#loc202))
#loc313 = loc("torch.nn.modules.activation.ReLU6::2"(#loc202))
#loc314 = loc("conv2d_441.dc.transpose.0"(#loc203))
#loc315 = loc("conv2d_441.dc.transpose.1"(#loc203))
#loc316 = loc("conv2d_441.dc.conv2d.2"(#loc203))
#loc317 = loc("conv2d_441.dc.transpose.3"(#loc203))
#loc318 = loc("conv2d_441.dc.transpose.4"(#loc203))
#loc319 = loc("torch.nn.modules.conv.Conv2d::0"(#loc204))
#loc320 = loc("torch.nn.modules.activation.ReLU6::2"(#loc204))
#loc321 = loc("torch.nn.modules.conv.Conv2d::0"(#loc205))
#loc322 = loc("torch.nn.modules.activation.ReLU6::2"(#loc205))
#loc323 = loc("conv2d_487.dc.transpose.0"(#loc206))
#loc324 = loc("conv2d_487.dc.transpose.1"(#loc206))
#loc325 = loc("conv2d_487.dc.conv2d.2"(#loc206))
#loc326 = loc("conv2d_487.dc.transpose.3"(#loc206))
#loc327 = loc("conv2d_487.dc.transpose.4"(#loc206))
#loc328 = loc("torch.nn.modules.conv.Conv2d::0"(#loc207))
#loc329 = loc("torch.nn.modules.activation.ReLU6::2"(#loc207))
#loc330 = loc("torch.nn.modules.conv.Conv2d::0"(#loc208))
#loc331 = loc("torch.nn.modules.activation.ReLU6::2"(#loc208))
#loc332 = loc("conv2d_532.dc.transpose.0"(#loc209))
#loc333 = loc("conv2d_532.dc.transpose.1"(#loc209))
#loc334 = loc("conv2d_532.dc.conv2d.2"(#loc209))
#loc335 = loc("conv2d_532.dc.transpose.3"(#loc209))
#loc336 = loc("conv2d_532.dc.transpose.4"(#loc209))
#loc337 = loc("torch.nn.modules.conv.Conv2d::0"(#loc210))
#loc338 = loc("torch.nn.modules.activation.ReLU6::2"(#loc210))
#loc339 = loc("torch.nn.modules.conv.Conv2d::0"(#loc211))
#loc340 = loc("torch.nn.modules.activation.ReLU6::2"(#loc211))
#loc341 = loc("conv2d_578.dc.transpose.0"(#loc212))
#loc342 = loc("conv2d_578.dc.transpose.1"(#loc212))
#loc343 = loc("conv2d_578.dc.conv2d.2"(#loc212))
#loc344 = loc("conv2d_578.dc.transpose.3"(#loc212))
#loc345 = loc("conv2d_578.dc.transpose.4"(#loc212))
#loc346 = loc("torch.nn.modules.conv.Conv2d::0"(#loc213))
#loc347 = loc("torch.nn.modules.activation.ReLU6::2"(#loc213))
#loc348 = loc("torch.nn.modules.conv.Conv2d::0"(#loc214))
#loc349 = loc("torch.nn.modules.activation.ReLU6::2"(#loc214))
#loc350 = loc("conv2d_624.dc.transpose.0"(#loc215))
#loc351 = loc("conv2d_624.dc.transpose.1"(#loc215))
#loc352 = loc("conv2d_624.dc.conv2d.2"(#loc215))
#loc353 = loc("conv2d_624.dc.transpose.3"(#loc215))
#loc354 = loc("conv2d_624.dc.transpose.4"(#loc215))
#loc355 = loc("torch.nn.modules.conv.Conv2d::0"(#loc216))
#loc356 = loc("torch.nn.modules.activation.ReLU6::2"(#loc216))
#loc357 = loc("torch.nn.modules.conv.Conv2d::0"(#loc217))
#loc358 = loc("torch.nn.modules.activation.ReLU6::2"(#loc217))
#loc359 = loc("conv2d_669.dc.transpose.0"(#loc218))
#loc360 = loc("conv2d_669.dc.transpose.1"(#loc218))
#loc361 = loc("conv2d_669.dc.conv2d.2"(#loc218))
#loc362 = loc("conv2d_669.dc.transpose.3"(#loc218))
#loc363 = loc("conv2d_669.dc.transpose.4"(#loc218))
#loc364 = loc("torch.nn.modules.conv.Conv2d::0"(#loc219))
#loc365 = loc("torch.nn.modules.activation.ReLU6::2"(#loc219))
#loc366 = loc("torch.nn.modules.conv.Conv2d::0"(#loc220))
#loc367 = loc("torch.nn.modules.activation.ReLU6::2"(#loc220))
#loc368 = loc("conv2d_715.dc.transpose.0"(#loc221))
#loc369 = loc("conv2d_715.dc.transpose.1"(#loc221))
#loc370 = loc("conv2d_715.dc.conv2d.2"(#loc221))
#loc371 = loc("conv2d_715.dc.transpose.3"(#loc221))
#loc372 = loc("conv2d_715.dc.transpose.4"(#loc221))
#loc373 = loc("torch.nn.modules.conv.Conv2d::0"(#loc222))
#loc374 = loc("torch.nn.modules.activation.ReLU6::2"(#loc222))
#loc375 = loc("torch.nn.modules.conv.Conv2d::0"(#loc223))
#loc376 = loc("torch.nn.modules.activation.ReLU6::2"(#loc223))
#loc377 = loc("conv2d_761.dc.transpose.0"(#loc224))
#loc378 = loc("conv2d_761.dc.transpose.1"(#loc224))
#loc379 = loc("conv2d_761.dc.conv2d.2"(#loc224))
#loc380 = loc("conv2d_761.dc.transpose.3"(#loc224))
#loc381 = loc("conv2d_761.dc.transpose.4"(#loc224))
#loc382 = loc("conv2d_16.dc.transpose.0"(#loc231))
#loc383 = loc("conv2d_16.dc.transpose.1"(#loc231))
#loc384 = loc("conv2d_16.dc.conv2d.2"(#loc231))
#loc385 = loc("conv2d_16.dc.transpose.3"(#loc231))
#loc386 = loc("conv2d_16.dc.transpose.4"(#loc231))
#loc387 = loc("clip_30"(#loc232))
#loc388 = loc("conv2d_45.dc.transpose.0"(#loc238))
#loc389 = loc("conv2d_45.dc.transpose.1"(#loc238))
#loc390 = loc("conv2d_45.dc.conv2d.2"(#loc238))
#loc391 = loc("conv2d_45.dc.transpose.3"(#loc238))
#loc392 = loc("conv2d_45.dc.transpose.4"(#loc238))
#loc393 = loc("clip_59"(#loc239))
#loc394 = loc("conv2d_61.dc.transpose.0"(#loc240))
#loc395 = loc("conv2d_61.dc.transpose.1"(#loc240))
#loc396 = loc("conv2d_61.dc.conv2d.2"(#loc240))
#loc397 = loc("conv2d_61.dc.transpose.3"(#loc240))
#loc398 = loc("conv2d_61.dc.transpose.4"(#loc240))
#loc399 = loc("clip_75"(#loc241))
#loc400 = loc("conv2d_90.dc.transpose.0"(#loc247))
#loc401 = loc("conv2d_90.dc.transpose.1"(#loc247))
#loc402 = loc("conv2d_90.dc.conv2d.2"(#loc247))
#loc403 = loc("conv2d_90.dc.transpose.3"(#loc247))
#loc404 = loc("conv2d_90.dc.transpose.4"(#loc247))
#loc405 = loc("clip_104"(#loc248))
#loc406 = loc("conv2d_106.dc.transpose.0"(#loc249))
#loc407 = loc("conv2d_106.dc.transpose.1"(#loc249))
#loc408 = loc("conv2d_106.dc.conv2d.2"(#loc249))
#loc409 = loc("conv2d_106.dc.transpose.3"(#loc249))
#loc410 = loc("conv2d_106.dc.transpose.4"(#loc249))
#loc411 = loc("clip_120"(#loc250))
#loc412 = loc("conv2d_136.dc.transpose.0"(#loc256))
#loc413 = loc("conv2d_136.dc.transpose.1"(#loc256))
#loc414 = loc("conv2d_136.dc.conv2d.2"(#loc256))
#loc415 = loc("conv2d_136.dc.transpose.3"(#loc256))
#loc416 = loc("conv2d_136.dc.transpose.4"(#loc256))
#loc417 = loc("clip_150"(#loc257))
#loc418 = loc("conv2d_152.dc.transpose.0"(#loc258))
#loc419 = loc("conv2d_152.dc.transpose.1"(#loc258))
#loc420 = loc("conv2d_152.dc.conv2d.2"(#loc258))
#loc421 = loc("conv2d_152.dc.transpose.3"(#loc258))
#loc422 = loc("conv2d_152.dc.transpose.4"(#loc258))
#loc423 = loc("clip_166"(#loc259))
#loc424 = loc("conv2d_181.dc.transpose.0"(#loc265))
#loc425 = loc("conv2d_181.dc.transpose.1"(#loc265))
#loc426 = loc("conv2d_181.dc.conv2d.2"(#loc265))
#loc427 = loc("conv2d_181.dc.transpose.3"(#loc265))
#loc428 = loc("conv2d_181.dc.transpose.4"(#loc265))
#loc429 = loc("clip_195"(#loc266))
#loc430 = loc("conv2d_197.dc.transpose.0"(#loc267))
#loc431 = loc("conv2d_197.dc.transpose.1"(#loc267))
#loc432 = loc("conv2d_197.dc.conv2d.2"(#loc267))
#loc433 = loc("conv2d_197.dc.transpose.3"(#loc267))
#loc434 = loc("conv2d_197.dc.transpose.4"(#loc267))
#loc435 = loc("clip_211"(#loc268))
#loc436 = loc("conv2d_227.dc.transpose.0"(#loc274))
#loc437 = loc("conv2d_227.dc.transpose.1"(#loc274))
#loc438 = loc("conv2d_227.dc.conv2d.2"(#loc274))
#loc439 = loc("conv2d_227.dc.transpose.3"(#loc274))
#loc440 = loc("conv2d_227.dc.transpose.4"(#loc274))
#loc441 = loc("clip_241"(#loc275))
#loc442 = loc("conv2d_243.dc.transpose.0"(#loc276))
#loc443 = loc("conv2d_243.dc.transpose.1"(#loc276))
#loc444 = loc("conv2d_243.dc.conv2d.2"(#loc276))
#loc445 = loc("conv2d_243.dc.transpose.3"(#loc276))
#loc446 = loc("conv2d_243.dc.transpose.4"(#loc276))
#loc447 = loc("clip_257"(#loc277))
#loc448 = loc("conv2d_273.dc.transpose.0"(#loc283))
#loc449 = loc("conv2d_273.dc.transpose.1"(#loc283))
#loc450 = loc("conv2d_273.dc.conv2d.2"(#loc283))
#loc451 = loc("conv2d_273.dc.transpose.3"(#loc283))
#loc452 = loc("conv2d_273.dc.transpose.4"(#loc283))
#loc453 = loc("clip_287"(#loc284))
#loc454 = loc("conv2d_289.dc.transpose.0"(#loc285))
#loc455 = loc("conv2d_289.dc.transpose.1"(#loc285))
#loc456 = loc("conv2d_289.dc.conv2d.2"(#loc285))
#loc457 = loc("conv2d_289.dc.transpose.3"(#loc285))
#loc458 = loc("conv2d_289.dc.transpose.4"(#loc285))
#loc459 = loc("clip_303"(#loc286))
#loc460 = loc("conv2d_318.dc.transpose.0"(#loc292))
#loc461 = loc("conv2d_318.dc.transpose.1"(#loc292))
#loc462 = loc("conv2d_318.dc.conv2d.2"(#loc292))
#loc463 = loc("conv2d_318.dc.transpose.3"(#loc292))
#loc464 = loc("conv2d_318.dc.transpose.4"(#loc292))
#loc465 = loc("clip_332"(#loc293))
#loc466 = loc("conv2d_334.dc.transpose.0"(#loc294))
#loc467 = loc("conv2d_334.dc.transpose.1"(#loc294))
#loc468 = loc("conv2d_334.dc.conv2d.2"(#loc294))
#loc469 = loc("conv2d_334.dc.transpose.3"(#loc294))
#loc470 = loc("conv2d_334.dc.transpose.4"(#loc294))
#loc471 = loc("clip_348"(#loc295))
#loc472 = loc("conv2d_364.dc.transpose.0"(#loc301))
#loc473 = loc("conv2d_364.dc.transpose.1"(#loc301))
#loc474 = loc("conv2d_364.dc.conv2d.2"(#loc301))
#loc475 = loc("conv2d_364.dc.transpose.3"(#loc301))
#loc476 = loc("conv2d_364.dc.transpose.4"(#loc301))
#loc477 = loc("clip_378"(#loc302))
#loc478 = loc("conv2d_380.dc.transpose.0"(#loc303))
#loc479 = loc("conv2d_380.dc.transpose.1"(#loc303))
#loc480 = loc("conv2d_380.dc.conv2d.2"(#loc303))
#loc481 = loc("conv2d_380.dc.transpose.3"(#loc303))
#loc482 = loc("conv2d_380.dc.transpose.4"(#loc303))
#loc483 = loc("clip_394"(#loc304))
#loc484 = loc("conv2d_410.dc.transpose.0"(#loc310))
#loc485 = loc("conv2d_410.dc.transpose.1"(#loc310))
#loc486 = loc("conv2d_410.dc.conv2d.2"(#loc310))
#loc487 = loc("conv2d_410.dc.transpose.3"(#loc310))
#loc488 = loc("conv2d_410.dc.transpose.4"(#loc310))
#loc489 = loc("clip_424"(#loc311))
#loc490 = loc("conv2d_426.dc.transpose.0"(#loc312))
#loc491 = loc("conv2d_426.dc.transpose.1"(#loc312))
#loc492 = loc("conv2d_426.dc.conv2d.2"(#loc312))
#loc493 = loc("conv2d_426.dc.transpose.3"(#loc312))
#loc494 = loc("conv2d_426.dc.transpose.4"(#loc312))
#loc495 = loc("clip_440"(#loc313))
#loc496 = loc("conv2d_456.dc.transpose.0"(#loc319))
#loc497 = loc("conv2d_456.dc.transpose.1"(#loc319))
#loc498 = loc("conv2d_456.dc.conv2d.2"(#loc319))
#loc499 = loc("conv2d_456.dc.transpose.3"(#loc319))
#loc500 = loc("conv2d_456.dc.transpose.4"(#loc319))
#loc501 = loc("clip_470"(#loc320))
#loc502 = loc("conv2d_472.dc.transpose.0"(#loc321))
#loc503 = loc("conv2d_472.dc.transpose.1"(#loc321))
#loc504 = loc("conv2d_472.dc.conv2d.2"(#loc321))
#loc505 = loc("conv2d_472.dc.transpose.3"(#loc321))
#loc506 = loc("conv2d_472.dc.transpose.4"(#loc321))
#loc507 = loc("clip_486"(#loc322))
#loc508 = loc("conv2d_501.dc.transpose.0"(#loc328))
#loc509 = loc("conv2d_501.dc.transpose.1"(#loc328))
#loc510 = loc("conv2d_501.dc.conv2d.2"(#loc328))
#loc511 = loc("conv2d_501.dc.transpose.3"(#loc328))
#loc512 = loc("conv2d_501.dc.transpose.4"(#loc328))
#loc513 = loc("clip_515"(#loc329))
#loc514 = loc("conv2d_517.dc.transpose.0"(#loc330))
#loc515 = loc("conv2d_517.dc.transpose.1"(#loc330))
#loc516 = loc("conv2d_517.dc.conv2d.2"(#loc330))
#loc517 = loc("conv2d_517.dc.transpose.3"(#loc330))
#loc518 = loc("conv2d_517.dc.transpose.4"(#loc330))
#loc519 = loc("clip_531"(#loc331))
#loc520 = loc("conv2d_547.dc.transpose.0"(#loc337))
#loc521 = loc("conv2d_547.dc.transpose.1"(#loc337))
#loc522 = loc("conv2d_547.dc.conv2d.2"(#loc337))
#loc523 = loc("conv2d_547.dc.transpose.3"(#loc337))
#loc524 = loc("conv2d_547.dc.transpose.4"(#loc337))
#loc525 = loc("clip_561"(#loc338))
#loc526 = loc("conv2d_563.dc.transpose.0"(#loc339))
#loc527 = loc("conv2d_563.dc.transpose.1"(#loc339))
#loc528 = loc("conv2d_563.dc.conv2d.2"(#loc339))
#loc529 = loc("conv2d_563.dc.transpose.3"(#loc339))
#loc530 = loc("conv2d_563.dc.transpose.4"(#loc339))
#loc531 = loc("clip_577"(#loc340))
#loc532 = loc("conv2d_593.dc.transpose.0"(#loc346))
#loc533 = loc("conv2d_593.dc.transpose.1"(#loc346))
#loc534 = loc("conv2d_593.dc.conv2d.2"(#loc346))
#loc535 = loc("conv2d_593.dc.transpose.3"(#loc346))
#loc536 = loc("conv2d_593.dc.transpose.4"(#loc346))
#loc537 = loc("clip_607"(#loc347))
#loc538 = loc("conv2d_609.dc.transpose.0"(#loc348))
#loc539 = loc("conv2d_609.dc.transpose.1"(#loc348))
#loc540 = loc("conv2d_609.dc.conv2d.2"(#loc348))
#loc541 = loc("conv2d_609.dc.transpose.3"(#loc348))
#loc542 = loc("conv2d_609.dc.transpose.4"(#loc348))
#loc543 = loc("clip_623"(#loc349))
#loc544 = loc("conv2d_638.dc.transpose.0"(#loc355))
#loc545 = loc("conv2d_638.dc.transpose.1"(#loc355))
#loc546 = loc("conv2d_638.dc.conv2d.2"(#loc355))
#loc547 = loc("conv2d_638.dc.transpose.3"(#loc355))
#loc548 = loc("conv2d_638.dc.transpose.4"(#loc355))
#loc549 = loc("clip_652"(#loc356))
#loc550 = loc("conv2d_654.dc.transpose.0"(#loc357))
#loc551 = loc("conv2d_654.dc.transpose.1"(#loc357))
#loc552 = loc("conv2d_654.dc.conv2d.2"(#loc357))
#loc553 = loc("conv2d_654.dc.transpose.3"(#loc357))
#loc554 = loc("conv2d_654.dc.transpose.4"(#loc357))
#loc555 = loc("clip_668"(#loc358))
#loc556 = loc("conv2d_684.dc.transpose.0"(#loc364))
#loc557 = loc("conv2d_684.dc.transpose.1"(#loc364))
#loc558 = loc("conv2d_684.dc.conv2d.2"(#loc364))
#loc559 = loc("conv2d_684.dc.transpose.3"(#loc364))
#loc560 = loc("conv2d_684.dc.transpose.4"(#loc364))
#loc561 = loc("clip_698"(#loc365))
#loc562 = loc("conv2d_700.dc.transpose.0"(#loc366))
#loc563 = loc("conv2d_700.dc.transpose.1"(#loc366))
#loc564 = loc("conv2d_700.dc.conv2d.2"(#loc366))
#loc565 = loc("conv2d_700.dc.transpose.3"(#loc366))
#loc566 = loc("conv2d_700.dc.transpose.4"(#loc366))
#loc567 = loc("clip_714"(#loc367))
#loc568 = loc("conv2d_730.dc.transpose.0"(#loc373))
#loc569 = loc("conv2d_730.dc.transpose.1"(#loc373))
#loc570 = loc("conv2d_730.dc.conv2d.2"(#loc373))
#loc571 = loc("conv2d_730.dc.transpose.3"(#loc373))
#loc572 = loc("conv2d_730.dc.transpose.4"(#loc373))
#loc573 = loc("clip_744"(#loc374))
#loc574 = loc("conv2d_746.dc.transpose.0"(#loc375))
#loc575 = loc("conv2d_746.dc.transpose.1"(#loc375))
#loc576 = loc("conv2d_746.dc.conv2d.2"(#loc375))
#loc577 = loc("conv2d_746.dc.transpose.3"(#loc375))
#loc578 = loc("conv2d_746.dc.transpose.4"(#loc375))
#loc579 = loc("clip_760"(#loc376))
