// REQUIRES: opmodel, regression
// RUN: ttmlir-opt --ttir-to-ttnn-backend-pipeline="system-desc-path=%system_desc_path% enable-optimizer=true memory-layout-analysis-enabled=false enable-fusing-pass=true" -o yolo_v4_ttnn.mlir %s
// RUN: ttmlir-translate --ttnn-to-flatbuffer yolo_v4_ttnn.mlir > %t.ttnn
#loc = loc("YOLOv4":0:0)
module @YOLOv4 {
  func.func @forward(%arg0: tensor<1x3x480x640xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "input_1"} loc("YOLOv4":0:0), %arg1: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3"} loc("YOLOv4":0:0), %arg2: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3_fork_clone2965"} loc("YOLOv4":0:0), %arg3: tensor<1x32x480x640xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_14"} loc("YOLOv4":0:0), %arg4: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_17"} loc("YOLOv4":0:0), %arg5: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_25"} loc("YOLOv4":0:0), %arg6: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_25_fork_clone2574"} loc("YOLOv4":0:0), %arg7: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_36"} loc("YOLOv4":0:0), %arg8: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_39"} loc("YOLOv4":0:0), %arg9: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_47"} loc("YOLOv4":0:0), %arg10: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_47_fork_clone2676"} loc("YOLOv4":0:0), %arg11: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_58"} loc("YOLOv4":0:0), %arg12: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_61"} loc("YOLOv4":0:0), %arg13: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_69"} loc("YOLOv4":0:0), %arg14: tensor<1x32x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_69_fork_clone3025"} loc("YOLOv4":0:0), %arg15: tensor<1x32x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_80"} loc("YOLOv4":0:0), %arg16: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_83"} loc("YOLOv4":0:0), %arg17: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_91"} loc("YOLOv4":0:0), %arg18: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_91_fork_clone2670"} loc("YOLOv4":0:0), %arg19: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_102"} loc("YOLOv4":0:0), %arg20: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_105"} loc("YOLOv4":0:0), %arg21: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_114"} loc("YOLOv4":0:0), %arg22: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_114_fork_clone2203"} loc("YOLOv4":0:0), %arg23: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_125"} loc("YOLOv4":0:0), %arg24: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_128"} loc("YOLOv4":0:0), %arg25: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_136"} loc("YOLOv4":0:0), %arg26: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_136_fork_clone2211"} loc("YOLOv4":0:0), %arg27: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_147"} loc("YOLOv4":0:0), %arg28: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_150"} loc("YOLOv4":0:0), %arg29: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_159"} loc("YOLOv4":0:0), %arg30: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_159_fork_clone1916"} loc("YOLOv4":0:0), %arg31: tensor<1x64x240x320xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_170"} loc("YOLOv4":0:0), %arg32: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_173"} loc("YOLOv4":0:0), %arg33: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_181"} loc("YOLOv4":0:0), %arg34: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_181_fork_clone1710"} loc("YOLOv4":0:0), %arg35: tensor<1x128x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_192"} loc("YOLOv4":0:0), %arg36: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_195"} loc("YOLOv4":0:0), %arg37: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_203"} loc("YOLOv4":0:0), %arg38: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_203_fork_clone1789"} loc("YOLOv4":0:0), %arg39: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_214"} loc("YOLOv4":0:0), %arg40: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_217"} loc("YOLOv4":0:0), %arg41: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_225"} loc("YOLOv4":0:0), %arg42: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_225_fork_clone2006"} loc("YOLOv4":0:0), %arg43: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_236"} loc("YOLOv4":0:0), %arg44: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_239"} loc("YOLOv4":0:0), %arg45: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_247"} loc("YOLOv4":0:0), %arg46: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_247_fork_clone1797"} loc("YOLOv4":0:0), %arg47: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_258"} loc("YOLOv4":0:0), %arg48: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_261"} loc("YOLOv4":0:0), %arg49: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_270"} loc("YOLOv4":0:0), %arg50: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_270_fork_clone1963"} loc("YOLOv4":0:0), %arg51: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_281"} loc("YOLOv4":0:0), %arg52: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_284"} loc("YOLOv4":0:0), %arg53: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_292"} loc("YOLOv4":0:0), %arg54: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_292_fork_clone1754"} loc("YOLOv4":0:0), %arg55: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_303"} loc("YOLOv4":0:0), %arg56: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_306"} loc("YOLOv4":0:0), %arg57: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_315"} loc("YOLOv4":0:0), %arg58: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_315_fork_clone1457"} loc("YOLOv4":0:0), %arg59: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_326"} loc("YOLOv4":0:0), %arg60: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_329"} loc("YOLOv4":0:0), %arg61: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_337"} loc("YOLOv4":0:0), %arg62: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_337_fork_clone1465"} loc("YOLOv4":0:0), %arg63: tensor<1x64x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_348"} loc("YOLOv4":0:0), %arg64: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_351"} loc("YOLOv4":0:0), %arg65: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_360"} loc("YOLOv4":0:0), %arg66: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_360_fork_clone1082"} loc("YOLOv4":0:0), %arg67: tensor<1x128x120x160xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_371"} loc("YOLOv4":0:0), %arg68: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_374"} loc("YOLOv4":0:0), %arg69: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_382"} loc("YOLOv4":0:0), %arg70: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_382_fork_clone859"} loc("YOLOv4":0:0), %arg71: tensor<1x256x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_393"} loc("YOLOv4":0:0), %arg72: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_396"} loc("YOLOv4":0:0), %arg73: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_404"} loc("YOLOv4":0:0), %arg74: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_404_fork_clone1333"} loc("YOLOv4":0:0), %arg75: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_415"} loc("YOLOv4":0:0), %arg76: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_418"} loc("YOLOv4":0:0), %arg77: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_426"} loc("YOLOv4":0:0), %arg78: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_426_fork_clone1622"} loc("YOLOv4":0:0), %arg79: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_437"} loc("YOLOv4":0:0), %arg80: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_440"} loc("YOLOv4":0:0), %arg81: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_448"} loc("YOLOv4":0:0), %arg82: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_448_fork_clone1341"} loc("YOLOv4":0:0), %arg83: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_459"} loc("YOLOv4":0:0), %arg84: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_462"} loc("YOLOv4":0:0), %arg85: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_471"} loc("YOLOv4":0:0), %arg86: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_471_fork_clone1564"} loc("YOLOv4":0:0), %arg87: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_482"} loc("YOLOv4":0:0), %arg88: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_485"} loc("YOLOv4":0:0), %arg89: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_493"} loc("YOLOv4":0:0), %arg90: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_493_fork_clone1266"} loc("YOLOv4":0:0), %arg91: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_504"} loc("YOLOv4":0:0), %arg92: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_507"} loc("YOLOv4":0:0), %arg93: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_516"} loc("YOLOv4":0:0), %arg94: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_516_fork_clone1505"} loc("YOLOv4":0:0), %arg95: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_527"} loc("YOLOv4":0:0), %arg96: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_530"} loc("YOLOv4":0:0), %arg97: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_538"} loc("YOLOv4":0:0), %arg98: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_538_fork_clone1192"} loc("YOLOv4":0:0), %arg99: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_549"} loc("YOLOv4":0:0), %arg100: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_552"} loc("YOLOv4":0:0), %arg101: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_561"} loc("YOLOv4":0:0), %arg102: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_561_fork_clone1437"} loc("YOLOv4":0:0), %arg103: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_572"} loc("YOLOv4":0:0), %arg104: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_575"} loc("YOLOv4":0:0), %arg105: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_583"} loc("YOLOv4":0:0), %arg106: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_583_fork_clone1120"} loc("YOLOv4":0:0), %arg107: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_594"} loc("YOLOv4":0:0), %arg108: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_597"} loc("YOLOv4":0:0), %arg109: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_606"} loc("YOLOv4":0:0), %arg110: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_606_fork_clone1368"} loc("YOLOv4":0:0), %arg111: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_617"} loc("YOLOv4":0:0), %arg112: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_620"} loc("YOLOv4":0:0), %arg113: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_628"} loc("YOLOv4":0:0), %arg114: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_628_fork_clone1053"} loc("YOLOv4":0:0), %arg115: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_639"} loc("YOLOv4":0:0), %arg116: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_642"} loc("YOLOv4":0:0), %arg117: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_651"} loc("YOLOv4":0:0), %arg118: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_651_fork_clone1293"} loc("YOLOv4":0:0), %arg119: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_662"} loc("YOLOv4":0:0), %arg120: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_665"} loc("YOLOv4":0:0), %arg121: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_673"} loc("YOLOv4":0:0), %arg122: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_673_fork_clone993"} loc("YOLOv4":0:0), %arg123: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_684"} loc("YOLOv4":0:0), %arg124: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_687"} loc("YOLOv4":0:0), %arg125: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_696"} loc("YOLOv4":0:0), %arg126: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_696_fork_clone1219"} loc("YOLOv4":0:0), %arg127: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_707"} loc("YOLOv4":0:0), %arg128: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_710"} loc("YOLOv4":0:0), %arg129: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_718"} loc("YOLOv4":0:0), %arg130: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_718_fork_clone940"} loc("YOLOv4":0:0), %arg131: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_729"} loc("YOLOv4":0:0), %arg132: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_732"} loc("YOLOv4":0:0), %arg133: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_741"} loc("YOLOv4":0:0), %arg134: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_741_fork_clone1147"} loc("YOLOv4":0:0), %arg135: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_752"} loc("YOLOv4":0:0), %arg136: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_755"} loc("YOLOv4":0:0), %arg137: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_763"} loc("YOLOv4":0:0), %arg138: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_763_fork_clone896"} loc("YOLOv4":0:0), %arg139: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_774"} loc("YOLOv4":0:0), %arg140: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_777"} loc("YOLOv4":0:0), %arg141: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_786"} loc("YOLOv4":0:0), %arg142: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_786_fork_clone727"} loc("YOLOv4":0:0), %arg143: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_797"} loc("YOLOv4":0:0), %arg144: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_800"} loc("YOLOv4":0:0), %arg145: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_808"} loc("YOLOv4":0:0), %arg146: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_808_fork_clone735"} loc("YOLOv4":0:0), %arg147: tensor<1x128x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_819"} loc("YOLOv4":0:0), %arg148: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_822"} loc("YOLOv4":0:0), %arg149: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_831"} loc("YOLOv4":0:0), %arg150: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_831_fork_clone607"} loc("YOLOv4":0:0), %arg151: tensor<1x256x60x80xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_842"} loc("YOLOv4":0:0), %arg152: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_845"} loc("YOLOv4":0:0), %arg153: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_853"} loc("YOLOv4":0:0), %arg154: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_853_fork_clone503"} loc("YOLOv4":0:0), %arg155: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_868"} loc("YOLOv4":0:0), %arg156: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_868_fork_clone2162"} loc("YOLOv4":0:0), %arg157: tensor<1x512x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_879"} loc("YOLOv4":0:0), %arg158: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_882"} loc("YOLOv4":0:0), %arg159: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_890"} loc("YOLOv4":0:0), %arg160: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_890_fork_clone2889"} loc("YOLOv4":0:0), %arg161: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_901"} loc("YOLOv4":0:0), %arg162: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_904"} loc("YOLOv4":0:0), %arg163: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_912"} loc("YOLOv4":0:0), %arg164: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_912_fork_clone3124"} loc("YOLOv4":0:0), %arg165: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_923"} loc("YOLOv4":0:0), %arg166: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_926"} loc("YOLOv4":0:0), %arg167: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_934"} loc("YOLOv4":0:0), %arg168: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_934_fork_clone2897"} loc("YOLOv4":0:0), %arg169: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_945"} loc("YOLOv4":0:0), %arg170: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_948"} loc("YOLOv4":0:0), %arg171: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_957"} loc("YOLOv4":0:0), %arg172: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_957_fork_clone3096"} loc("YOLOv4":0:0), %arg173: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_968"} loc("YOLOv4":0:0), %arg174: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_971"} loc("YOLOv4":0:0), %arg175: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_979"} loc("YOLOv4":0:0), %arg176: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_979_fork_clone2805"} loc("YOLOv4":0:0), %arg177: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_990"} loc("YOLOv4":0:0), %arg178: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_993"} loc("YOLOv4":0:0), %arg179: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1002"} loc("YOLOv4":0:0), %arg180: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1002_fork_clone3057"} loc("YOLOv4":0:0), %arg181: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1013"} loc("YOLOv4":0:0), %arg182: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1016"} loc("YOLOv4":0:0), %arg183: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1024"} loc("YOLOv4":0:0), %arg184: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1024_fork_clone2706"} loc("YOLOv4":0:0), %arg185: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1035"} loc("YOLOv4":0:0), %arg186: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1038"} loc("YOLOv4":0:0), %arg187: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1047"} loc("YOLOv4":0:0), %arg188: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1047_fork_clone2997"} loc("YOLOv4":0:0), %arg189: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1058"} loc("YOLOv4":0:0), %arg190: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1061"} loc("YOLOv4":0:0), %arg191: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1069"} loc("YOLOv4":0:0), %arg192: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1069_fork_clone2601"} loc("YOLOv4":0:0), %arg193: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1080"} loc("YOLOv4":0:0), %arg194: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1083"} loc("YOLOv4":0:0), %arg195: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1092"} loc("YOLOv4":0:0), %arg196: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1092_fork_clone2924"} loc("YOLOv4":0:0), %arg197: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1103"} loc("YOLOv4":0:0), %arg198: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1106"} loc("YOLOv4":0:0), %arg199: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1114"} loc("YOLOv4":0:0), %arg200: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1114_fork_clone2493"} loc("YOLOv4":0:0), %arg201: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1125"} loc("YOLOv4":0:0), %arg202: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1128"} loc("YOLOv4":0:0), %arg203: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1137"} loc("YOLOv4":0:0), %arg204: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1137_fork_clone2832"} loc("YOLOv4":0:0), %arg205: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1148"} loc("YOLOv4":0:0), %arg206: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1151"} loc("YOLOv4":0:0), %arg207: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1159"} loc("YOLOv4":0:0), %arg208: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1159_fork_clone2398"} loc("YOLOv4":0:0), %arg209: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1170"} loc("YOLOv4":0:0), %arg210: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1173"} loc("YOLOv4":0:0), %arg211: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1182"} loc("YOLOv4":0:0), %arg212: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1182_fork_clone2733"} loc("YOLOv4":0:0), %arg213: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1193"} loc("YOLOv4":0:0), %arg214: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1196"} loc("YOLOv4":0:0), %arg215: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1204"} loc("YOLOv4":0:0), %arg216: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1204_fork_clone2309"} loc("YOLOv4":0:0), %arg217: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1215"} loc("YOLOv4":0:0), %arg218: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1218"} loc("YOLOv4":0:0), %arg219: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1227"} loc("YOLOv4":0:0), %arg220: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1227_fork_clone2628"} loc("YOLOv4":0:0), %arg221: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1238"} loc("YOLOv4":0:0), %arg222: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1241"} loc("YOLOv4":0:0), %arg223: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1249"} loc("YOLOv4":0:0), %arg224: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1249_fork_clone2237"} loc("YOLOv4":0:0), %arg225: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1260"} loc("YOLOv4":0:0), %arg226: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1263"} loc("YOLOv4":0:0), %arg227: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1272"} loc("YOLOv4":0:0), %arg228: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1272_fork_clone1926"} loc("YOLOv4":0:0), %arg229: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1283"} loc("YOLOv4":0:0), %arg230: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1286"} loc("YOLOv4":0:0), %arg231: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1294"} loc("YOLOv4":0:0), %arg232: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1294_fork_clone1934"} loc("YOLOv4":0:0), %arg233: tensor<1x256x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1305"} loc("YOLOv4":0:0), %arg234: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1308"} loc("YOLOv4":0:0), %arg235: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1317"} loc("YOLOv4":0:0), %arg236: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1317_fork_clone1661"} loc("YOLOv4":0:0), %arg237: tensor<1x512x30x40xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1328"} loc("YOLOv4":0:0), %arg238: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1331"} loc("YOLOv4":0:0), %arg239: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1339"} loc("YOLOv4":0:0), %arg240: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1339_fork_clone1400"} loc("YOLOv4":0:0), %arg241: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1354"} loc("YOLOv4":0:0), %arg242: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1354_fork_clone2190"} loc("YOLOv4":0:0), %arg243: tensor<1x1024x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1365"} loc("YOLOv4":0:0), %arg244: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1368"} loc("YOLOv4":0:0), %arg245: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1376"} loc("YOLOv4":0:0), %arg246: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1376_fork_clone2522"} loc("YOLOv4":0:0), %arg247: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1387"} loc("YOLOv4":0:0), %arg248: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1390"} loc("YOLOv4":0:0), %arg249: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1398"} loc("YOLOv4":0:0), %arg250: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1398_fork_clone2942"} loc("YOLOv4":0:0), %arg251: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1409"} loc("YOLOv4":0:0), %arg252: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1412"} loc("YOLOv4":0:0), %arg253: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1420"} loc("YOLOv4":0:0), %arg254: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1420_fork_clone2530"} loc("YOLOv4":0:0), %arg255: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1431"} loc("YOLOv4":0:0), %arg256: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1434"} loc("YOLOv4":0:0), %arg257: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1443"} loc("YOLOv4":0:0), %arg258: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1443_fork_clone2854"} loc("YOLOv4":0:0), %arg259: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1454"} loc("YOLOv4":0:0), %arg260: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1457"} loc("YOLOv4":0:0), %arg261: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1465"} loc("YOLOv4":0:0), %arg262: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1465_fork_clone2433"} loc("YOLOv4":0:0), %arg263: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1476"} loc("YOLOv4":0:0), %arg264: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1479"} loc("YOLOv4":0:0), %arg265: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1488"} loc("YOLOv4":0:0), %arg266: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1488_fork_clone2763"} loc("YOLOv4":0:0), %arg267: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1499"} loc("YOLOv4":0:0), %arg268: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1502"} loc("YOLOv4":0:0), %arg269: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1510"} loc("YOLOv4":0:0), %arg270: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1510_fork_clone2343"} loc("YOLOv4":0:0), %arg271: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1521"} loc("YOLOv4":0:0), %arg272: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1524"} loc("YOLOv4":0:0), %arg273: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1533"} loc("YOLOv4":0:0), %arg274: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1533_fork_clone2660"} loc("YOLOv4":0:0), %arg275: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1544"} loc("YOLOv4":0:0), %arg276: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1547"} loc("YOLOv4":0:0), %arg277: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1555"} loc("YOLOv4":0:0), %arg278: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1555_fork_clone2265"} loc("YOLOv4":0:0), %arg279: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1566"} loc("YOLOv4":0:0), %arg280: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1569"} loc("YOLOv4":0:0), %arg281: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1578"} loc("YOLOv4":0:0), %arg282: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1578_fork_clone1942"} loc("YOLOv4":0:0), %arg283: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1589"} loc("YOLOv4":0:0), %arg284: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1592"} loc("YOLOv4":0:0), %arg285: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1600"} loc("YOLOv4":0:0), %arg286: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1600_fork_clone1950"} loc("YOLOv4":0:0), %arg287: tensor<1x512x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1611"} loc("YOLOv4":0:0), %arg288: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1614"} loc("YOLOv4":0:0), %arg289: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1623"} loc("YOLOv4":0:0), %arg290: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1623_fork_clone1672"} loc("YOLOv4":0:0), %arg291: tensor<1x1024x15x20xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_greater_1634"} loc("YOLOv4":0:0), %arg292: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_1637"} loc("YOLOv4":0:0), %arg293: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1645"} loc("YOLOv4":0:0), %arg294: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1645_fork_clone1408"} loc("YOLOv4":0:0), %arg295: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1660"} loc("YOLOv4":0:0), %arg296: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1660_fork_clone1096"} loc("YOLOv4":0:0), %arg297: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1675"} loc("YOLOv4":0:0), %arg298: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1675_fork_clone873"} loc("YOLOv4":0:0), %arg299: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1694"} loc("YOLOv4":0:0), %arg300: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1694_fork_clone720"} loc("YOLOv4":0:0), %arg301: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1709"} loc("YOLOv4":0:0), %arg302: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1709_fork_clone627"} loc("YOLOv4":0:0), %arg303: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1724"} loc("YOLOv4":0:0), %arg304: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1724_fork_clone520"} loc("YOLOv4":0:0), %arg305: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1739"} loc("YOLOv4":0:0), %arg306: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1739_fork_clone1477"} loc("YOLOv4":0:0), %arg307: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1756"} loc("YOLOv4":0:0), %arg308: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1756_fork_clone1023"} loc("YOLOv4":0:0), %arg309: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1771"} loc("YOLOv4":0:0), %arg310: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1771_fork_clone826"} loc("YOLOv4":0:0), %arg311: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1786"} loc("YOLOv4":0:0), %arg312: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1786_fork_clone711"} loc("YOLOv4":0:0), %arg313: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1801"} loc("YOLOv4":0:0), %arg314: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1801_fork_clone619"} loc("YOLOv4":0:0), %arg315: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1816"} loc("YOLOv4":0:0), %arg316: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1816_fork_clone513"} loc("YOLOv4":0:0), %arg317: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1831"} loc("YOLOv4":0:0), %arg318: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1831_fork_clone529"} loc("YOLOv4":0:0), %arg319: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1848"} loc("YOLOv4":0:0), %arg320: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1848_fork_clone397"} loc("YOLOv4":0:0), %arg321: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1863"} loc("YOLOv4":0:0), %arg322: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1863_fork_clone327"} loc("YOLOv4":0:0), %arg323: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1878"} loc("YOLOv4":0:0), %arg324: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1878_fork_clone258"} loc("YOLOv4":0:0), %arg325: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1893"} loc("YOLOv4":0:0), %arg326: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1893_fork_clone189"} loc("YOLOv4":0:0), %arg327: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1908"} loc("YOLOv4":0:0), %arg328: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1908_fork_clone120"} loc("YOLOv4":0:0), %arg329: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1923"} loc("YOLOv4":0:0), %arg330: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1923_fork_clone57"} loc("YOLOv4":0:0), %arg331: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1942"} loc("YOLOv4":0:0), %arg332: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1942_fork_clone509"} loc("YOLOv4":0:0), %arg333: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1958"} loc("YOLOv4":0:0), %arg334: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1958_fork_clone404"} loc("YOLOv4":0:0), %arg335: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1973"} loc("YOLOv4":0:0), %arg336: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1973_fork_clone333"} loc("YOLOv4":0:0), %arg337: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1988"} loc("YOLOv4":0:0), %arg338: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_1988_fork_clone264"} loc("YOLOv4":0:0), %arg339: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2003"} loc("YOLOv4":0:0), %arg340: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2003_fork_clone195"} loc("YOLOv4":0:0), %arg341: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2018"} loc("YOLOv4":0:0), %arg342: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2018_fork_clone126"} loc("YOLOv4":0:0), %arg343: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2033"} loc("YOLOv4":0:0), %arg344: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2033_fork_clone61"} loc("YOLOv4":0:0), %arg345: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2052"} loc("YOLOv4":0:0), %arg346: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2052_fork_clone516"} loc("YOLOv4":0:0), %arg347: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2068"} loc("YOLOv4":0:0), %arg348: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2068_fork_clone411"} loc("YOLOv4":0:0), %arg349: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2083"} loc("YOLOv4":0:0), %arg350: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2083_fork_clone339"} loc("YOLOv4":0:0), %arg351: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2098"} loc("YOLOv4":0:0), %arg352: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2098_fork_clone270"} loc("YOLOv4":0:0), %arg353: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2113"} loc("YOLOv4":0:0), %arg354: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2113_fork_clone201"} loc("YOLOv4":0:0), %arg355: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2128"} loc("YOLOv4":0:0), %arg356: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2128_fork_clone132"} loc("YOLOv4":0:0), %arg357: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2143"} loc("YOLOv4":0:0), %arg358: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_2143_fork_clone65"} loc("YOLOv4":0:0), %arg359: tensor<32x3x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c1.weight"} loc("YOLOv4":0:0), %arg360: tensor<64x32x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c2.weight"} loc("YOLOv4":0:0), %arg361: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c4.weight"} loc("YOLOv4":0:0), %arg362: tensor<32x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c5.weight"} loc("YOLOv4":0:0), %arg363: tensor<64x32x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c6.weight"} loc("YOLOv4":0:0), %arg364: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c7.weight"} loc("YOLOv4":0:0), %arg365: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c3.weight"} loc("YOLOv4":0:0), %arg366: tensor<64x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample1.c8.weight"} loc("YOLOv4":0:0), %arg367: tensor<128x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.c1.weight"} loc("YOLOv4":0:0), %arg368: tensor<64x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.c3.weight"} loc("YOLOv4":0:0), %arg369: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.res.module_list.0.0.weight"} loc("YOLOv4":0:0), %arg370: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.res.module_list.0.3.weight"} loc("YOLOv4":0:0), %arg371: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.res.module_list.1.0.weight"} loc("YOLOv4":0:0), %arg372: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.res.module_list.1.3.weight"} loc("YOLOv4":0:0), %arg373: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.c4.weight"} loc("YOLOv4":0:0), %arg374: tensor<64x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.c2.weight"} loc("YOLOv4":0:0), %arg375: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample2.c5.weight"} loc("YOLOv4":0:0), %arg376: tensor<256x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.c1.weight"} loc("YOLOv4":0:0), %arg377: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.c3.weight"} loc("YOLOv4":0:0), %arg378: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.0.0.weight"} loc("YOLOv4":0:0), %arg379: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.0.3.weight"} loc("YOLOv4":0:0), %arg380: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.1.0.weight"} loc("YOLOv4":0:0), %arg381: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.1.3.weight"} loc("YOLOv4":0:0), %arg382: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.2.0.weight"} loc("YOLOv4":0:0), %arg383: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.2.3.weight"} loc("YOLOv4":0:0), %arg384: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.3.0.weight"} loc("YOLOv4":0:0), %arg385: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.3.3.weight"} loc("YOLOv4":0:0), %arg386: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.4.0.weight"} loc("YOLOv4":0:0), %arg387: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.4.3.weight"} loc("YOLOv4":0:0), %arg388: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.5.0.weight"} loc("YOLOv4":0:0), %arg389: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.5.3.weight"} loc("YOLOv4":0:0), %arg390: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.6.0.weight"} loc("YOLOv4":0:0), %arg391: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.6.3.weight"} loc("YOLOv4":0:0), %arg392: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.7.0.weight"} loc("YOLOv4":0:0), %arg393: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.res.module_list.7.3.weight"} loc("YOLOv4":0:0), %arg394: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.c4.weight"} loc("YOLOv4":0:0), %arg395: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.c2.weight"} loc("YOLOv4":0:0), %arg396: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample3.c5.weight"} loc("YOLOv4":0:0), %arg397: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c9_2.weight"} loc("YOLOv4":0:0), %arg398: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.c1.weight"} loc("YOLOv4":0:0), %arg399: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.c3.weight"} loc("YOLOv4":0:0), %arg400: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.0.0.weight"} loc("YOLOv4":0:0), %arg401: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.0.3.weight"} loc("YOLOv4":0:0), %arg402: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.1.0.weight"} loc("YOLOv4":0:0), %arg403: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.1.3.weight"} loc("YOLOv4":0:0), %arg404: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.2.0.weight"} loc("YOLOv4":0:0), %arg405: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.2.3.weight"} loc("YOLOv4":0:0), %arg406: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.3.0.weight"} loc("YOLOv4":0:0), %arg407: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.3.3.weight"} loc("YOLOv4":0:0), %arg408: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.4.0.weight"} loc("YOLOv4":0:0), %arg409: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.4.3.weight"} loc("YOLOv4":0:0), %arg410: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.5.0.weight"} loc("YOLOv4":0:0), %arg411: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.5.3.weight"} loc("YOLOv4":0:0), %arg412: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.6.0.weight"} loc("YOLOv4":0:0), %arg413: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.6.3.weight"} loc("YOLOv4":0:0), %arg414: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.7.0.weight"} loc("YOLOv4":0:0), %arg415: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.res.module_list.7.3.weight"} loc("YOLOv4":0:0), %arg416: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.c4.weight"} loc("YOLOv4":0:0), %arg417: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.c2.weight"} loc("YOLOv4":0:0), %arg418: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample4.c5.weight"} loc("YOLOv4":0:0), %arg419: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c7_2.weight"} loc("YOLOv4":0:0), %arg420: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.c1.weight"} loc("YOLOv4":0:0), %arg421: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.c3.weight"} loc("YOLOv4":0:0), %arg422: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.0.0.weight"} loc("YOLOv4":0:0), %arg423: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.0.3.weight"} loc("YOLOv4":0:0), %arg424: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.1.0.weight"} loc("YOLOv4":0:0), %arg425: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.1.3.weight"} loc("YOLOv4":0:0), %arg426: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.2.0.weight"} loc("YOLOv4":0:0), %arg427: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.2.3.weight"} loc("YOLOv4":0:0), %arg428: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.3.0.weight"} loc("YOLOv4":0:0), %arg429: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.res.module_list.3.3.weight"} loc("YOLOv4":0:0), %arg430: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.c4.weight"} loc("YOLOv4":0:0), %arg431: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.c2.weight"} loc("YOLOv4":0:0), %arg432: tensor<1024x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.downsample5.c5.weight"} loc("YOLOv4":0:0), %arg433: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c1.weight"} loc("YOLOv4":0:0), %arg434: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c2.weight"} loc("YOLOv4":0:0), %arg435: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c3.weight"} loc("YOLOv4":0:0), %arg436: tensor<512x2048x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c4.weight"} loc("YOLOv4":0:0), %arg437: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c5.weight"} loc("YOLOv4":0:0), %arg438: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c6.weight"} loc("YOLOv4":0:0), %arg439: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c7.weight"} loc("YOLOv4":0:0), %arg440: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c7_3.weight"} loc("YOLOv4":0:0), %arg441: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c8.weight"} loc("YOLOv4":0:0), %arg442: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c7_4.weight"} loc("YOLOv4":0:0), %arg443: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c8_2.weight"} loc("YOLOv4":0:0), %arg444: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c7_5.weight"} loc("YOLOv4":0:0), %arg445: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c9.weight"} loc("YOLOv4":0:0), %arg446: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c9_3.weight"} loc("YOLOv4":0:0), %arg447: tensor<256x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c10.weight"} loc("YOLOv4":0:0), %arg448: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c9_4.weight"} loc("YOLOv4":0:0), %arg449: tensor<256x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c10_2.weight"} loc("YOLOv4":0:0), %arg450: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.neck.c9_5.weight"} loc("YOLOv4":0:0), %arg451: tensor<256x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c1.weight"} loc("YOLOv4":0:0), %arg452: tensor<255x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c2.weight"} loc("YOLOv4":0:0), %arg453: tensor<1x1x1x255xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c2.bias"} loc("YOLOv4":0:0), %arg454: tensor<256x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c3.weight"} loc("YOLOv4":0:0), %arg455: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c4.weight"} loc("YOLOv4":0:0), %arg456: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c5.weight"} loc("YOLOv4":0:0), %arg457: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c6.weight"} loc("YOLOv4":0:0), %arg458: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c7.weight"} loc("YOLOv4":0:0), %arg459: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c8.weight"} loc("YOLOv4":0:0), %arg460: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c9.weight"} loc("YOLOv4":0:0), %arg461: tensor<255x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c10.weight"} loc("YOLOv4":0:0), %arg462: tensor<1x1x1x255xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c10.bias"} loc("YOLOv4":0:0), %arg463: tensor<512x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c11.weight"} loc("YOLOv4":0:0), %arg464: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c12.weight"} loc("YOLOv4":0:0), %arg465: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c13.weight"} loc("YOLOv4":0:0), %arg466: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c14.weight"} loc("YOLOv4":0:0), %arg467: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c15.weight"} loc("YOLOv4":0:0), %arg468: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c16.weight"} loc("YOLOv4":0:0), %arg469: tensor<1024x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c17.weight"} loc("YOLOv4":0:0), %arg470: tensor<255x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c18.weight"} loc("YOLOv4":0:0), %arg471: tensor<1x1x1x255xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "model.head.c18.bias"} loc("YOLOv4":0:0)) -> (tensor<1x255x60x80xbf16> {ttir.name = "YOLOv4.output_add_1938"}, tensor<1x255x30x40xbf16> {ttir.name = "YOLOv4.output_add_2048"}, tensor<1x255x15x20xbf16> {ttir.name = "YOLOv4.output_add_2158"}) {
    %0 = ttir.empty() : tensor<1x480x3x640xbf16> loc(#loc539)
    %1 = "ttir.transpose"(%arg0, %0) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x3x480x640xbf16>, tensor<1x480x3x640xbf16>) -> tensor<1x480x3x640xbf16> loc(#loc539)
    %2 = ttir.empty() : tensor<1x480x640x3xbf16> loc(#loc540)
    %3 = "ttir.transpose"(%1, %2) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x480x3x640xbf16>, tensor<1x480x640x3xbf16>) -> tensor<1x480x640x3xbf16> loc(#loc540)
    %4 = ttir.empty() : tensor<1x480x640x32xbf16> loc(#loc541)
    %5 = "ttir.conv2d"(%3, %arg359, %4) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x480x640x3xbf16>, tensor<32x3x3x3xbf16>, tensor<1x480x640x32xbf16>) -> tensor<1x480x640x32xbf16> loc(#loc541)
    %6 = ttir.empty() : tensor<1x480x32x640xbf16> loc(#loc542)
    %7 = "ttir.transpose"(%5, %6) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x480x640x32xbf16>, tensor<1x480x32x640xbf16>) -> tensor<1x480x32x640xbf16> loc(#loc542)
    %8 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc543)
    %9 = "ttir.transpose"(%7, %8) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x480x32x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc543)
    %10 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc2)
    %11 = "ttir.multiply"(%9, %arg1, %10) : (tensor<1x32x480x640xbf16>, tensor<1x32x1x1xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc2)
    %12 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc544)
    %13 = "ttir.add"(%11, %arg2, %12) : (tensor<1x32x480x640xbf16>, tensor<1x32x1x1xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc544)
    %14 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc545)
    %15 = "ttir.gt"(%13, %arg3, %14) : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc545)
    %16 = ttir.empty() : tensor<1x32x480x640xi32> loc(#loc3)
    %17 = "ttir.typecast"(%15, %16) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xi32>) -> tensor<1x32x480x640xi32> loc(#loc3)
    %18 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc546)
    %19 = "ttir.exp"(%13, %18) : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc546)
    %20 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc547)
    %21 = "ttir.add"(%19, %arg4, %20) : (tensor<1x32x480x640xbf16>, tensor<1xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc547)
    %22 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc548)
    %23 = "ttir.log"(%21, %22) : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc548)
    %24 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc549)
    %25 = "ttir.where"(%17, %13, %23, %24) : (tensor<1x32x480x640xi32>, tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc549)
    %26 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc550)
    %27 = "ttir.tanh"(%25, %26) : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc550)
    %28 = ttir.empty() : tensor<1x32x480x640xbf16> loc(#loc551)
    %29 = "ttir.multiply"(%13, %27, %28) : (tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>, tensor<1x32x480x640xbf16>) -> tensor<1x32x480x640xbf16> loc(#loc551)
    %30 = ttir.empty() : tensor<1x480x32x640xbf16> loc(#loc552)
    %31 = "ttir.transpose"(%29, %30) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x32x480x640xbf16>, tensor<1x480x32x640xbf16>) -> tensor<1x480x32x640xbf16> loc(#loc552)
    %32 = ttir.empty() : tensor<1x480x640x32xbf16> loc(#loc553)
    %33 = "ttir.transpose"(%31, %32) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x480x32x640xbf16>, tensor<1x480x640x32xbf16>) -> tensor<1x480x640x32xbf16> loc(#loc553)
    %34 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc554)
    %35 = "ttir.conv2d"(%33, %arg360, %34) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x480x640x32xbf16>, tensor<64x32x3x3xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc554)
    %36 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc555)
    %37 = "ttir.transpose"(%35, %36) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc555)
    %38 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc556)
    %39 = "ttir.transpose"(%37, %38) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc556)
    %40 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc4)
    %41 = "ttir.multiply"(%39, %arg5, %40) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc4)
    %42 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc228)
    %43 = "ttir.add"(%41, %arg6, %42) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc228)
    %44 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc229)
    %45 = "ttir.gt"(%43, %arg7, %44) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc229)
    %46 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc5)
    %47 = "ttir.typecast"(%45, %46) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc5)
    %48 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc230)
    %49 = "ttir.exp"(%43, %48) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc230)
    %50 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc231)
    %51 = "ttir.add"(%49, %arg8, %50) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc231)
    %52 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc232)
    %53 = "ttir.log"(%51, %52) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc232)
    %54 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc233)
    %55 = "ttir.where"(%47, %43, %53, %54) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc233)
    %56 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc234)
    %57 = "ttir.tanh"(%55, %56) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc234)
    %58 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc235)
    %59 = "ttir.multiply"(%43, %57, %58) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc235)
    %60 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc557)
    %61 = "ttir.transpose"(%59, %60) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc557)
    %62 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc558)
    %63 = "ttir.transpose"(%61, %62) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc558)
    %64 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc559)
    %65 = "ttir.conv2d"(%63, %arg361, %64) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc559)
    %66 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc560)
    %67 = "ttir.transpose"(%65, %66) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc560)
    %68 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc561)
    %69 = "ttir.transpose"(%67, %68) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc561)
    %70 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc6)
    %71 = "ttir.multiply"(%69, %arg9, %70) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc6)
    %72 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc237)
    %73 = "ttir.add"(%71, %arg10, %72) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc237)
    %74 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc238)
    %75 = "ttir.gt"(%73, %arg11, %74) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc238)
    %76 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc7)
    %77 = "ttir.typecast"(%75, %76) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc7)
    %78 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc239)
    %79 = "ttir.exp"(%73, %78) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc239)
    %80 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc240)
    %81 = "ttir.add"(%79, %arg12, %80) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc240)
    %82 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc241)
    %83 = "ttir.log"(%81, %82) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc241)
    %84 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc242)
    %85 = "ttir.where"(%77, %73, %83, %84) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc242)
    %86 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc243)
    %87 = "ttir.tanh"(%85, %86) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc243)
    %88 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc244)
    %89 = "ttir.multiply"(%73, %87, %88) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc244)
    %90 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc562)
    %91 = "ttir.transpose"(%89, %90) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc562)
    %92 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc563)
    %93 = "ttir.transpose"(%91, %92) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc563)
    %94 = ttir.empty() : tensor<1x240x320x32xbf16> loc(#loc564)
    %95 = "ttir.conv2d"(%93, %arg362, %94) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x64xbf16>, tensor<32x64x1x1xbf16>, tensor<1x240x320x32xbf16>) -> tensor<1x240x320x32xbf16> loc(#loc564)
    %96 = ttir.empty() : tensor<1x240x32x320xbf16> loc(#loc565)
    %97 = "ttir.transpose"(%95, %96) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x32xbf16>, tensor<1x240x32x320xbf16>) -> tensor<1x240x32x320xbf16> loc(#loc565)
    %98 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc566)
    %99 = "ttir.transpose"(%97, %98) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x32x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc566)
    %100 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc8)
    %101 = "ttir.multiply"(%99, %arg13, %100) : (tensor<1x32x240x320xbf16>, tensor<1x32x1x1xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc8)
    %102 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc246)
    %103 = "ttir.add"(%101, %arg14, %102) : (tensor<1x32x240x320xbf16>, tensor<1x32x1x1xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc246)
    %104 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc247)
    %105 = "ttir.gt"(%103, %arg15, %104) : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc247)
    %106 = ttir.empty() : tensor<1x32x240x320xi32> loc(#loc9)
    %107 = "ttir.typecast"(%105, %106) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xi32>) -> tensor<1x32x240x320xi32> loc(#loc9)
    %108 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc248)
    %109 = "ttir.exp"(%103, %108) : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc248)
    %110 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc249)
    %111 = "ttir.add"(%109, %arg16, %110) : (tensor<1x32x240x320xbf16>, tensor<1xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc249)
    %112 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc250)
    %113 = "ttir.log"(%111, %112) : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc250)
    %114 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc251)
    %115 = "ttir.where"(%107, %103, %113, %114) : (tensor<1x32x240x320xi32>, tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc251)
    %116 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc252)
    %117 = "ttir.tanh"(%115, %116) : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc252)
    %118 = ttir.empty() : tensor<1x32x240x320xbf16> loc(#loc253)
    %119 = "ttir.multiply"(%103, %117, %118) : (tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>, tensor<1x32x240x320xbf16>) -> tensor<1x32x240x320xbf16> loc(#loc253)
    %120 = ttir.empty() : tensor<1x240x32x320xbf16> loc(#loc567)
    %121 = "ttir.transpose"(%119, %120) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x32x240x320xbf16>, tensor<1x240x32x320xbf16>) -> tensor<1x240x32x320xbf16> loc(#loc567)
    %122 = ttir.empty() : tensor<1x240x320x32xbf16> loc(#loc568)
    %123 = "ttir.transpose"(%121, %122) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x32x320xbf16>, tensor<1x240x320x32xbf16>) -> tensor<1x240x320x32xbf16> loc(#loc568)
    %124 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc569)
    %125 = "ttir.conv2d"(%123, %arg363, %124) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x32xbf16>, tensor<64x32x3x3xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc569)
    %126 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc570)
    %127 = "ttir.transpose"(%125, %126) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc570)
    %128 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc571)
    %129 = "ttir.transpose"(%127, %128) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc571)
    %130 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc10)
    %131 = "ttir.multiply"(%129, %arg17, %130) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc10)
    %132 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc255)
    %133 = "ttir.add"(%131, %arg18, %132) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc255)
    %134 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc256)
    %135 = "ttir.gt"(%133, %arg19, %134) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc256)
    %136 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc11)
    %137 = "ttir.typecast"(%135, %136) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc11)
    %138 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc257)
    %139 = "ttir.exp"(%133, %138) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc257)
    %140 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc258)
    %141 = "ttir.add"(%139, %arg20, %140) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc258)
    %142 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc259)
    %143 = "ttir.log"(%141, %142) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc259)
    %144 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc260)
    %145 = "ttir.where"(%137, %133, %143, %144) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc260)
    %146 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc261)
    %147 = "ttir.tanh"(%145, %146) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc261)
    %148 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc262)
    %149 = "ttir.multiply"(%133, %147, %148) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc262)
    %150 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc263)
    %151 = "ttir.add"(%149, %89, %150) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc263)
    %152 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc572)
    %153 = "ttir.transpose"(%151, %152) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc572)
    %154 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc573)
    %155 = "ttir.transpose"(%153, %154) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc573)
    %156 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc574)
    %157 = "ttir.conv2d"(%155, %arg364, %156) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc574)
    %158 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc575)
    %159 = "ttir.transpose"(%157, %158) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc575)
    %160 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc576)
    %161 = "ttir.transpose"(%159, %160) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc576)
    %162 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc12)
    %163 = "ttir.multiply"(%161, %arg21, %162) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc12)
    %164 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc265)
    %165 = "ttir.add"(%163, %arg22, %164) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc265)
    %166 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc266)
    %167 = "ttir.gt"(%165, %arg23, %166) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc266)
    %168 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc13)
    %169 = "ttir.typecast"(%167, %168) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc13)
    %170 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc267)
    %171 = "ttir.exp"(%165, %170) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc267)
    %172 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc268)
    %173 = "ttir.add"(%171, %arg24, %172) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc268)
    %174 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc269)
    %175 = "ttir.log"(%173, %174) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc269)
    %176 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc270)
    %177 = "ttir.where"(%169, %165, %175, %176) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc270)
    %178 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc271)
    %179 = "ttir.tanh"(%177, %178) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc271)
    %180 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc272)
    %181 = "ttir.multiply"(%165, %179, %180) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc272)
    %182 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc577)
    %183 = "ttir.transpose"(%59, %182) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc577)
    %184 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc578)
    %185 = "ttir.transpose"(%183, %184) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc578)
    %186 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc579)
    %187 = "ttir.conv2d"(%185, %arg365, %186) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc579)
    %188 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc580)
    %189 = "ttir.transpose"(%187, %188) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc580)
    %190 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc581)
    %191 = "ttir.transpose"(%189, %190) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc581)
    %192 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc14)
    %193 = "ttir.multiply"(%191, %arg25, %192) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc14)
    %194 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc274)
    %195 = "ttir.add"(%193, %arg26, %194) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc274)
    %196 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc275)
    %197 = "ttir.gt"(%195, %arg27, %196) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc275)
    %198 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc15)
    %199 = "ttir.typecast"(%197, %198) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc15)
    %200 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc276)
    %201 = "ttir.exp"(%195, %200) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc276)
    %202 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc277)
    %203 = "ttir.add"(%201, %arg28, %202) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc277)
    %204 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc278)
    %205 = "ttir.log"(%203, %204) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc278)
    %206 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc279)
    %207 = "ttir.where"(%199, %195, %205, %206) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc279)
    %208 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc280)
    %209 = "ttir.tanh"(%207, %208) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc280)
    %210 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc281)
    %211 = "ttir.multiply"(%195, %209, %210) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc281)
    %212 = ttir.empty() : tensor<1x128x240x320xbf16> loc(#loc282)
    %213 = "ttir.concat"(%181, %211, %212) <{dim = -3 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x128x240x320xbf16>) -> tensor<1x128x240x320xbf16> loc(#loc282)
    %214 = ttir.empty() : tensor<1x240x128x320xbf16> loc(#loc582)
    %215 = "ttir.transpose"(%213, %214) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x240x320xbf16>, tensor<1x240x128x320xbf16>) -> tensor<1x240x128x320xbf16> loc(#loc582)
    %216 = ttir.empty() : tensor<1x240x320x128xbf16> loc(#loc583)
    %217 = "ttir.transpose"(%215, %216) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x128x320xbf16>, tensor<1x240x320x128xbf16>) -> tensor<1x240x320x128xbf16> loc(#loc583)
    %218 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc584)
    %219 = "ttir.conv2d"(%217, %arg366, %218) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x240x320x128xbf16>, tensor<64x128x1x1xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc584)
    %220 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc585)
    %221 = "ttir.transpose"(%219, %220) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x320x64xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc585)
    %222 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc586)
    %223 = "ttir.transpose"(%221, %222) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc586)
    %224 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc16)
    %225 = "ttir.multiply"(%223, %arg29, %224) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc16)
    %226 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc284)
    %227 = "ttir.add"(%225, %arg30, %226) : (tensor<1x64x240x320xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc284)
    %228 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc285)
    %229 = "ttir.gt"(%227, %arg31, %228) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc285)
    %230 = ttir.empty() : tensor<1x64x240x320xi32> loc(#loc17)
    %231 = "ttir.typecast"(%229, %230) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xi32>) -> tensor<1x64x240x320xi32> loc(#loc17)
    %232 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc286)
    %233 = "ttir.exp"(%227, %232) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc286)
    %234 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc287)
    %235 = "ttir.add"(%233, %arg32, %234) : (tensor<1x64x240x320xbf16>, tensor<1xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc287)
    %236 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc288)
    %237 = "ttir.log"(%235, %236) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc288)
    %238 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc289)
    %239 = "ttir.where"(%231, %227, %237, %238) : (tensor<1x64x240x320xi32>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc289)
    %240 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc290)
    %241 = "ttir.tanh"(%239, %240) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc290)
    %242 = ttir.empty() : tensor<1x64x240x320xbf16> loc(#loc291)
    %243 = "ttir.multiply"(%227, %241, %242) : (tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>, tensor<1x64x240x320xbf16>) -> tensor<1x64x240x320xbf16> loc(#loc291)
    %244 = ttir.empty() : tensor<1x240x64x320xbf16> loc(#loc587)
    %245 = "ttir.transpose"(%243, %244) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x240x320xbf16>, tensor<1x240x64x320xbf16>) -> tensor<1x240x64x320xbf16> loc(#loc587)
    %246 = ttir.empty() : tensor<1x240x320x64xbf16> loc(#loc588)
    %247 = "ttir.transpose"(%245, %246) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x240x64x320xbf16>, tensor<1x240x320x64xbf16>) -> tensor<1x240x320x64xbf16> loc(#loc588)
    %248 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc589)
    %249 = "ttir.conv2d"(%247, %arg367, %248) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x240x320x64xbf16>, tensor<128x64x3x3xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc589)
    %250 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc590)
    %251 = "ttir.transpose"(%249, %250) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x128xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc590)
    %252 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc591)
    %253 = "ttir.transpose"(%251, %252) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc591)
    %254 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc18)
    %255 = "ttir.multiply"(%253, %arg33, %254) : (tensor<1x128x120x160xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc18)
    %256 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc592)
    %257 = "ttir.add"(%255, %arg34, %256) : (tensor<1x128x120x160xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc592)
    %258 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc593)
    %259 = "ttir.gt"(%257, %arg35, %258) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc593)
    %260 = ttir.empty() : tensor<1x128x120x160xi32> loc(#loc19)
    %261 = "ttir.typecast"(%259, %260) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xi32>) -> tensor<1x128x120x160xi32> loc(#loc19)
    %262 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc594)
    %263 = "ttir.exp"(%257, %262) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc594)
    %264 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc595)
    %265 = "ttir.add"(%263, %arg36, %264) : (tensor<1x128x120x160xbf16>, tensor<1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc595)
    %266 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc596)
    %267 = "ttir.log"(%265, %266) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc596)
    %268 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc597)
    %269 = "ttir.where"(%261, %257, %267, %268) : (tensor<1x128x120x160xi32>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc597)
    %270 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc598)
    %271 = "ttir.tanh"(%269, %270) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc598)
    %272 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc599)
    %273 = "ttir.multiply"(%257, %271, %272) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc599)
    %274 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc600)
    %275 = "ttir.transpose"(%273, %274) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x120x160xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc600)
    %276 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc601)
    %277 = "ttir.transpose"(%275, %276) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc601)
    %278 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc602)
    %279 = "ttir.conv2d"(%277, %arg368, %278) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x128xbf16>, tensor<64x128x1x1xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc602)
    %280 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc603)
    %281 = "ttir.transpose"(%279, %280) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc603)
    %282 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc604)
    %283 = "ttir.transpose"(%281, %282) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc604)
    %284 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc20)
    %285 = "ttir.multiply"(%283, %arg37, %284) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc20)
    %286 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc295)
    %287 = "ttir.add"(%285, %arg38, %286) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc295)
    %288 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc296)
    %289 = "ttir.gt"(%287, %arg39, %288) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc296)
    %290 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc21)
    %291 = "ttir.typecast"(%289, %290) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc21)
    %292 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc297)
    %293 = "ttir.exp"(%287, %292) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc297)
    %294 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc298)
    %295 = "ttir.add"(%293, %arg40, %294) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc298)
    %296 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc299)
    %297 = "ttir.log"(%295, %296) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc299)
    %298 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc300)
    %299 = "ttir.where"(%291, %287, %297, %298) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc300)
    %300 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc301)
    %301 = "ttir.tanh"(%299, %300) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc301)
    %302 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc302)
    %303 = "ttir.multiply"(%287, %301, %302) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc302)
    %304 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1144)
    %305 = "ttir.transpose"(%303, %304) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1144)
    %306 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1145)
    %307 = "ttir.transpose"(%305, %306) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1145)
    %308 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1146)
    %309 = "ttir.conv2d"(%307, %arg369, %308) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1146)
    %310 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1147)
    %311 = "ttir.transpose"(%309, %310) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1147)
    %312 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1148)
    %313 = "ttir.transpose"(%311, %312) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1148)
    %314 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc22)
    %315 = "ttir.multiply"(%313, %arg41, %314) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc22)
    %316 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1149)
    %317 = "ttir.add"(%315, %arg42, %316) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1149)
    %318 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1150)
    %319 = "ttir.gt"(%317, %arg43, %318) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1150)
    %320 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc23)
    %321 = "ttir.typecast"(%319, %320) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc23)
    %322 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1151)
    %323 = "ttir.exp"(%317, %322) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1151)
    %324 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1152)
    %325 = "ttir.add"(%323, %arg44, %324) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1152)
    %326 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1153)
    %327 = "ttir.log"(%325, %326) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1153)
    %328 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1154)
    %329 = "ttir.where"(%321, %317, %327, %328) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1154)
    %330 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1155)
    %331 = "ttir.tanh"(%329, %330) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1155)
    %332 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1156)
    %333 = "ttir.multiply"(%317, %331, %332) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1156)
    %334 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1157)
    %335 = "ttir.transpose"(%333, %334) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1157)
    %336 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1158)
    %337 = "ttir.transpose"(%335, %336) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1158)
    %338 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1159)
    %339 = "ttir.conv2d"(%337, %arg370, %338) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x64xbf16>, tensor<64x64x3x3xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1159)
    %340 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1160)
    %341 = "ttir.transpose"(%339, %340) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1160)
    %342 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1161)
    %343 = "ttir.transpose"(%341, %342) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1161)
    %344 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc24)
    %345 = "ttir.multiply"(%343, %arg45, %344) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc24)
    %346 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc608)
    %347 = "ttir.add"(%345, %arg46, %346) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc608)
    %348 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc609)
    %349 = "ttir.gt"(%347, %arg47, %348) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc609)
    %350 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc25)
    %351 = "ttir.typecast"(%349, %350) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc25)
    %352 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc610)
    %353 = "ttir.exp"(%347, %352) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc610)
    %354 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc611)
    %355 = "ttir.add"(%353, %arg48, %354) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc611)
    %356 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc612)
    %357 = "ttir.log"(%355, %356) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc612)
    %358 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc613)
    %359 = "ttir.where"(%351, %347, %357, %358) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc613)
    %360 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc614)
    %361 = "ttir.tanh"(%359, %360) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc614)
    %362 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc615)
    %363 = "ttir.multiply"(%347, %361, %362) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc615)
    %364 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc616)
    %365 = "ttir.add"(%303, %363, %364) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc616)
    %366 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1162)
    %367 = "ttir.transpose"(%365, %366) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1162)
    %368 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1163)
    %369 = "ttir.transpose"(%367, %368) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1163)
    %370 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1164)
    %371 = "ttir.conv2d"(%369, %arg371, %370) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1164)
    %372 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1165)
    %373 = "ttir.transpose"(%371, %372) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1165)
    %374 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1166)
    %375 = "ttir.transpose"(%373, %374) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1166)
    %376 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc26)
    %377 = "ttir.multiply"(%375, %arg49, %376) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc26)
    %378 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1167)
    %379 = "ttir.add"(%377, %arg50, %378) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1167)
    %380 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1168)
    %381 = "ttir.gt"(%379, %arg51, %380) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1168)
    %382 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc27)
    %383 = "ttir.typecast"(%381, %382) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc27)
    %384 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1169)
    %385 = "ttir.exp"(%379, %384) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1169)
    %386 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1170)
    %387 = "ttir.add"(%385, %arg52, %386) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1170)
    %388 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1171)
    %389 = "ttir.log"(%387, %388) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1171)
    %390 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1172)
    %391 = "ttir.where"(%383, %379, %389, %390) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1172)
    %392 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1173)
    %393 = "ttir.tanh"(%391, %392) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1173)
    %394 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1174)
    %395 = "ttir.multiply"(%379, %393, %394) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1174)
    %396 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1175)
    %397 = "ttir.transpose"(%395, %396) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1175)
    %398 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1176)
    %399 = "ttir.transpose"(%397, %398) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1176)
    %400 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc1177)
    %401 = "ttir.conv2d"(%399, %arg372, %400) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x64xbf16>, tensor<64x64x3x3xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc1177)
    %402 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc1178)
    %403 = "ttir.transpose"(%401, %402) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc1178)
    %404 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc1179)
    %405 = "ttir.transpose"(%403, %404) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc1179)
    %406 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc28)
    %407 = "ttir.multiply"(%405, %arg53, %406) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc28)
    %408 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc620)
    %409 = "ttir.add"(%407, %arg54, %408) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc620)
    %410 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc621)
    %411 = "ttir.gt"(%409, %arg55, %410) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc621)
    %412 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc29)
    %413 = "ttir.typecast"(%411, %412) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc29)
    %414 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc622)
    %415 = "ttir.exp"(%409, %414) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc622)
    %416 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc623)
    %417 = "ttir.add"(%415, %arg56, %416) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc623)
    %418 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc624)
    %419 = "ttir.log"(%417, %418) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc624)
    %420 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc625)
    %421 = "ttir.where"(%413, %409, %419, %420) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc625)
    %422 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc626)
    %423 = "ttir.tanh"(%421, %422) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc626)
    %424 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc627)
    %425 = "ttir.multiply"(%409, %423, %424) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc627)
    %426 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc628)
    %427 = "ttir.add"(%365, %425, %426) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc628)
    %428 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc629)
    %429 = "ttir.transpose"(%427, %428) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc629)
    %430 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc630)
    %431 = "ttir.transpose"(%429, %430) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc630)
    %432 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc631)
    %433 = "ttir.conv2d"(%431, %arg373, %432) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x64xbf16>, tensor<64x64x1x1xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc631)
    %434 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc632)
    %435 = "ttir.transpose"(%433, %434) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc632)
    %436 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc633)
    %437 = "ttir.transpose"(%435, %436) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc633)
    %438 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc30)
    %439 = "ttir.multiply"(%437, %arg57, %438) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc30)
    %440 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc305)
    %441 = "ttir.add"(%439, %arg58, %440) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc305)
    %442 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc306)
    %443 = "ttir.gt"(%441, %arg59, %442) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc306)
    %444 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc31)
    %445 = "ttir.typecast"(%443, %444) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc31)
    %446 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc307)
    %447 = "ttir.exp"(%441, %446) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc307)
    %448 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc308)
    %449 = "ttir.add"(%447, %arg60, %448) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc308)
    %450 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc309)
    %451 = "ttir.log"(%449, %450) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc309)
    %452 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc310)
    %453 = "ttir.where"(%445, %441, %451, %452) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc310)
    %454 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc311)
    %455 = "ttir.tanh"(%453, %454) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc311)
    %456 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc312)
    %457 = "ttir.multiply"(%441, %455, %456) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc312)
    %458 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc634)
    %459 = "ttir.transpose"(%273, %458) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x120x160xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc634)
    %460 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc635)
    %461 = "ttir.transpose"(%459, %460) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc635)
    %462 = ttir.empty() : tensor<1x120x160x64xbf16> loc(#loc636)
    %463 = "ttir.conv2d"(%461, %arg374, %462) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x128xbf16>, tensor<64x128x1x1xbf16>, tensor<1x120x160x64xbf16>) -> tensor<1x120x160x64xbf16> loc(#loc636)
    %464 = ttir.empty() : tensor<1x120x64x160xbf16> loc(#loc637)
    %465 = "ttir.transpose"(%463, %464) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x64xbf16>, tensor<1x120x64x160xbf16>) -> tensor<1x120x64x160xbf16> loc(#loc637)
    %466 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc638)
    %467 = "ttir.transpose"(%465, %466) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x64x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc638)
    %468 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc32)
    %469 = "ttir.multiply"(%467, %arg61, %468) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc32)
    %470 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc314)
    %471 = "ttir.add"(%469, %arg62, %470) : (tensor<1x64x120x160xbf16>, tensor<1x64x1x1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc314)
    %472 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc315)
    %473 = "ttir.gt"(%471, %arg63, %472) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc315)
    %474 = ttir.empty() : tensor<1x64x120x160xi32> loc(#loc33)
    %475 = "ttir.typecast"(%473, %474) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xi32>) -> tensor<1x64x120x160xi32> loc(#loc33)
    %476 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc316)
    %477 = "ttir.exp"(%471, %476) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc316)
    %478 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc317)
    %479 = "ttir.add"(%477, %arg64, %478) : (tensor<1x64x120x160xbf16>, tensor<1xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc317)
    %480 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc318)
    %481 = "ttir.log"(%479, %480) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc318)
    %482 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc319)
    %483 = "ttir.where"(%475, %471, %481, %482) : (tensor<1x64x120x160xi32>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc319)
    %484 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc320)
    %485 = "ttir.tanh"(%483, %484) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc320)
    %486 = ttir.empty() : tensor<1x64x120x160xbf16> loc(#loc321)
    %487 = "ttir.multiply"(%471, %485, %486) : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>) -> tensor<1x64x120x160xbf16> loc(#loc321)
    %488 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc322)
    %489 = "ttir.concat"(%457, %487, %488) <{dim = -3 : si32}> : (tensor<1x64x120x160xbf16>, tensor<1x64x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc322)
    %490 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc639)
    %491 = "ttir.transpose"(%489, %490) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x120x160xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc639)
    %492 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc640)
    %493 = "ttir.transpose"(%491, %492) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc640)
    %494 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc641)
    %495 = "ttir.conv2d"(%493, %arg375, %494) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x120x160x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc641)
    %496 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc642)
    %497 = "ttir.transpose"(%495, %496) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x160x128xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc642)
    %498 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc643)
    %499 = "ttir.transpose"(%497, %498) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc643)
    %500 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc34)
    %501 = "ttir.multiply"(%499, %arg65, %500) : (tensor<1x128x120x160xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc34)
    %502 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc324)
    %503 = "ttir.add"(%501, %arg66, %502) : (tensor<1x128x120x160xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc324)
    %504 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc325)
    %505 = "ttir.gt"(%503, %arg67, %504) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc325)
    %506 = ttir.empty() : tensor<1x128x120x160xi32> loc(#loc35)
    %507 = "ttir.typecast"(%505, %506) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xi32>) -> tensor<1x128x120x160xi32> loc(#loc35)
    %508 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc326)
    %509 = "ttir.exp"(%503, %508) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc326)
    %510 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc327)
    %511 = "ttir.add"(%509, %arg68, %510) : (tensor<1x128x120x160xbf16>, tensor<1xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc327)
    %512 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc328)
    %513 = "ttir.log"(%511, %512) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc328)
    %514 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc329)
    %515 = "ttir.where"(%507, %503, %513, %514) : (tensor<1x128x120x160xi32>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc329)
    %516 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc330)
    %517 = "ttir.tanh"(%515, %516) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc330)
    %518 = ttir.empty() : tensor<1x128x120x160xbf16> loc(#loc331)
    %519 = "ttir.multiply"(%503, %517, %518) : (tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>, tensor<1x128x120x160xbf16>) -> tensor<1x128x120x160xbf16> loc(#loc331)
    %520 = ttir.empty() : tensor<1x120x128x160xbf16> loc(#loc644)
    %521 = "ttir.transpose"(%519, %520) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x120x160xbf16>, tensor<1x120x128x160xbf16>) -> tensor<1x120x128x160xbf16> loc(#loc644)
    %522 = ttir.empty() : tensor<1x120x160x128xbf16> loc(#loc645)
    %523 = "ttir.transpose"(%521, %522) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x120x128x160xbf16>, tensor<1x120x160x128xbf16>) -> tensor<1x120x160x128xbf16> loc(#loc645)
    %524 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc646)
    %525 = "ttir.conv2d"(%523, %arg376, %524) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x120x160x128xbf16>, tensor<256x128x3x3xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc646)
    %526 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc647)
    %527 = "ttir.transpose"(%525, %526) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x256xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc647)
    %528 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc648)
    %529 = "ttir.transpose"(%527, %528) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc648)
    %530 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc36)
    %531 = "ttir.multiply"(%529, %arg69, %530) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc36)
    %532 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc649)
    %533 = "ttir.add"(%531, %arg70, %532) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc649)
    %534 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc650)
    %535 = "ttir.gt"(%533, %arg71, %534) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc650)
    %536 = ttir.empty() : tensor<1x256x60x80xi32> loc(#loc37)
    %537 = "ttir.typecast"(%535, %536) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xi32>) -> tensor<1x256x60x80xi32> loc(#loc37)
    %538 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc651)
    %539 = "ttir.exp"(%533, %538) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc651)
    %540 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc652)
    %541 = "ttir.add"(%539, %arg72, %540) : (tensor<1x256x60x80xbf16>, tensor<1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc652)
    %542 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc653)
    %543 = "ttir.log"(%541, %542) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc653)
    %544 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc654)
    %545 = "ttir.where"(%537, %533, %543, %544) : (tensor<1x256x60x80xi32>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc654)
    %546 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc655)
    %547 = "ttir.tanh"(%545, %546) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc655)
    %548 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc656)
    %549 = "ttir.multiply"(%533, %547, %548) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc656)
    %550 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc657)
    %551 = "ttir.transpose"(%549, %550) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc657)
    %552 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc658)
    %553 = "ttir.transpose"(%551, %552) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc658)
    %554 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc659)
    %555 = "ttir.conv2d"(%553, %arg377, %554) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc659)
    %556 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc660)
    %557 = "ttir.transpose"(%555, %556) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc660)
    %558 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc661)
    %559 = "ttir.transpose"(%557, %558) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc661)
    %560 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc38)
    %561 = "ttir.multiply"(%559, %arg73, %560) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc38)
    %562 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc335)
    %563 = "ttir.add"(%561, %arg74, %562) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc335)
    %564 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc336)
    %565 = "ttir.gt"(%563, %arg75, %564) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc336)
    %566 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc39)
    %567 = "ttir.typecast"(%565, %566) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc39)
    %568 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc337)
    %569 = "ttir.exp"(%563, %568) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc337)
    %570 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc338)
    %571 = "ttir.add"(%569, %arg76, %570) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc338)
    %572 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc339)
    %573 = "ttir.log"(%571, %572) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc339)
    %574 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc340)
    %575 = "ttir.where"(%567, %563, %573, %574) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc340)
    %576 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc341)
    %577 = "ttir.tanh"(%575, %576) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc341)
    %578 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc342)
    %579 = "ttir.multiply"(%563, %577, %578) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc342)
    %580 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1180)
    %581 = "ttir.transpose"(%579, %580) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1180)
    %582 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1181)
    %583 = "ttir.transpose"(%581, %582) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1181)
    %584 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1182)
    %585 = "ttir.conv2d"(%583, %arg378, %584) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1182)
    %586 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1183)
    %587 = "ttir.transpose"(%585, %586) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1183)
    %588 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1184)
    %589 = "ttir.transpose"(%587, %588) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1184)
    %590 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc40)
    %591 = "ttir.multiply"(%589, %arg77, %590) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc40)
    %592 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1185)
    %593 = "ttir.add"(%591, %arg78, %592) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1185)
    %594 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1186)
    %595 = "ttir.gt"(%593, %arg79, %594) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1186)
    %596 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc41)
    %597 = "ttir.typecast"(%595, %596) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc41)
    %598 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1187)
    %599 = "ttir.exp"(%593, %598) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1187)
    %600 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1188)
    %601 = "ttir.add"(%599, %arg80, %600) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1188)
    %602 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1189)
    %603 = "ttir.log"(%601, %602) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1189)
    %604 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1190)
    %605 = "ttir.where"(%597, %593, %603, %604) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1190)
    %606 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1191)
    %607 = "ttir.tanh"(%605, %606) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1191)
    %608 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1192)
    %609 = "ttir.multiply"(%593, %607, %608) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1192)
    %610 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1193)
    %611 = "ttir.transpose"(%609, %610) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1193)
    %612 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1194)
    %613 = "ttir.transpose"(%611, %612) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1194)
    %614 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1195)
    %615 = "ttir.conv2d"(%613, %arg379, %614) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1195)
    %616 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1196)
    %617 = "ttir.transpose"(%615, %616) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1196)
    %618 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1197)
    %619 = "ttir.transpose"(%617, %618) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1197)
    %620 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc42)
    %621 = "ttir.multiply"(%619, %arg81, %620) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc42)
    %622 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc665)
    %623 = "ttir.add"(%621, %arg82, %622) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc665)
    %624 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc666)
    %625 = "ttir.gt"(%623, %arg83, %624) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc666)
    %626 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc43)
    %627 = "ttir.typecast"(%625, %626) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc43)
    %628 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc667)
    %629 = "ttir.exp"(%623, %628) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc667)
    %630 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc668)
    %631 = "ttir.add"(%629, %arg84, %630) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc668)
    %632 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc669)
    %633 = "ttir.log"(%631, %632) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc669)
    %634 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc670)
    %635 = "ttir.where"(%627, %623, %633, %634) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc670)
    %636 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc671)
    %637 = "ttir.tanh"(%635, %636) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc671)
    %638 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc672)
    %639 = "ttir.multiply"(%623, %637, %638) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc672)
    %640 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc673)
    %641 = "ttir.add"(%579, %639, %640) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc673)
    %642 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1198)
    %643 = "ttir.transpose"(%641, %642) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1198)
    %644 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1199)
    %645 = "ttir.transpose"(%643, %644) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1199)
    %646 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1200)
    %647 = "ttir.conv2d"(%645, %arg380, %646) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1200)
    %648 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1201)
    %649 = "ttir.transpose"(%647, %648) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1201)
    %650 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1202)
    %651 = "ttir.transpose"(%649, %650) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1202)
    %652 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc44)
    %653 = "ttir.multiply"(%651, %arg85, %652) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc44)
    %654 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1203)
    %655 = "ttir.add"(%653, %arg86, %654) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1203)
    %656 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1204)
    %657 = "ttir.gt"(%655, %arg87, %656) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1204)
    %658 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc45)
    %659 = "ttir.typecast"(%657, %658) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc45)
    %660 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1205)
    %661 = "ttir.exp"(%655, %660) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1205)
    %662 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1206)
    %663 = "ttir.add"(%661, %arg88, %662) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1206)
    %664 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1207)
    %665 = "ttir.log"(%663, %664) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1207)
    %666 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1208)
    %667 = "ttir.where"(%659, %655, %665, %666) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1208)
    %668 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1209)
    %669 = "ttir.tanh"(%667, %668) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1209)
    %670 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1210)
    %671 = "ttir.multiply"(%655, %669, %670) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1210)
    %672 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1211)
    %673 = "ttir.transpose"(%671, %672) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1211)
    %674 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1212)
    %675 = "ttir.transpose"(%673, %674) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1212)
    %676 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1213)
    %677 = "ttir.conv2d"(%675, %arg381, %676) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1213)
    %678 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1214)
    %679 = "ttir.transpose"(%677, %678) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1214)
    %680 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1215)
    %681 = "ttir.transpose"(%679, %680) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1215)
    %682 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc46)
    %683 = "ttir.multiply"(%681, %arg89, %682) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc46)
    %684 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc674)
    %685 = "ttir.add"(%683, %arg90, %684) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc674)
    %686 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc675)
    %687 = "ttir.gt"(%685, %arg91, %686) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc675)
    %688 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc47)
    %689 = "ttir.typecast"(%687, %688) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc47)
    %690 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc676)
    %691 = "ttir.exp"(%685, %690) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc676)
    %692 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc677)
    %693 = "ttir.add"(%691, %arg92, %692) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc677)
    %694 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc678)
    %695 = "ttir.log"(%693, %694) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc678)
    %696 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc679)
    %697 = "ttir.where"(%689, %685, %695, %696) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc679)
    %698 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc680)
    %699 = "ttir.tanh"(%697, %698) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc680)
    %700 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc681)
    %701 = "ttir.multiply"(%685, %699, %700) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc681)
    %702 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc682)
    %703 = "ttir.add"(%641, %701, %702) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc682)
    %704 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1216)
    %705 = "ttir.transpose"(%703, %704) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1216)
    %706 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1217)
    %707 = "ttir.transpose"(%705, %706) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1217)
    %708 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1218)
    %709 = "ttir.conv2d"(%707, %arg382, %708) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1218)
    %710 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1219)
    %711 = "ttir.transpose"(%709, %710) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1219)
    %712 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1220)
    %713 = "ttir.transpose"(%711, %712) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1220)
    %714 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc48)
    %715 = "ttir.multiply"(%713, %arg93, %714) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc48)
    %716 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1221)
    %717 = "ttir.add"(%715, %arg94, %716) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1221)
    %718 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1222)
    %719 = "ttir.gt"(%717, %arg95, %718) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1222)
    %720 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc49)
    %721 = "ttir.typecast"(%719, %720) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc49)
    %722 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1223)
    %723 = "ttir.exp"(%717, %722) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1223)
    %724 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1224)
    %725 = "ttir.add"(%723, %arg96, %724) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1224)
    %726 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1225)
    %727 = "ttir.log"(%725, %726) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1225)
    %728 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1226)
    %729 = "ttir.where"(%721, %717, %727, %728) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1226)
    %730 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1227)
    %731 = "ttir.tanh"(%729, %730) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1227)
    %732 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1228)
    %733 = "ttir.multiply"(%717, %731, %732) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1228)
    %734 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1229)
    %735 = "ttir.transpose"(%733, %734) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1229)
    %736 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1230)
    %737 = "ttir.transpose"(%735, %736) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1230)
    %738 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1231)
    %739 = "ttir.conv2d"(%737, %arg383, %738) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1231)
    %740 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1232)
    %741 = "ttir.transpose"(%739, %740) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1232)
    %742 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1233)
    %743 = "ttir.transpose"(%741, %742) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1233)
    %744 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc50)
    %745 = "ttir.multiply"(%743, %arg97, %744) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc50)
    %746 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc683)
    %747 = "ttir.add"(%745, %arg98, %746) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc683)
    %748 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc684)
    %749 = "ttir.gt"(%747, %arg99, %748) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc684)
    %750 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc51)
    %751 = "ttir.typecast"(%749, %750) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc51)
    %752 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc685)
    %753 = "ttir.exp"(%747, %752) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc685)
    %754 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc686)
    %755 = "ttir.add"(%753, %arg100, %754) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc686)
    %756 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc687)
    %757 = "ttir.log"(%755, %756) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc687)
    %758 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc688)
    %759 = "ttir.where"(%751, %747, %757, %758) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc688)
    %760 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc689)
    %761 = "ttir.tanh"(%759, %760) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc689)
    %762 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc690)
    %763 = "ttir.multiply"(%747, %761, %762) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc690)
    %764 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc691)
    %765 = "ttir.add"(%703, %763, %764) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc691)
    %766 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1234)
    %767 = "ttir.transpose"(%765, %766) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1234)
    %768 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1235)
    %769 = "ttir.transpose"(%767, %768) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1235)
    %770 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1236)
    %771 = "ttir.conv2d"(%769, %arg384, %770) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1236)
    %772 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1237)
    %773 = "ttir.transpose"(%771, %772) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1237)
    %774 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1238)
    %775 = "ttir.transpose"(%773, %774) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1238)
    %776 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc52)
    %777 = "ttir.multiply"(%775, %arg101, %776) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc52)
    %778 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1239)
    %779 = "ttir.add"(%777, %arg102, %778) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1239)
    %780 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1240)
    %781 = "ttir.gt"(%779, %arg103, %780) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1240)
    %782 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc53)
    %783 = "ttir.typecast"(%781, %782) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc53)
    %784 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1241)
    %785 = "ttir.exp"(%779, %784) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1241)
    %786 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1242)
    %787 = "ttir.add"(%785, %arg104, %786) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1242)
    %788 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1243)
    %789 = "ttir.log"(%787, %788) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1243)
    %790 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1244)
    %791 = "ttir.where"(%783, %779, %789, %790) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1244)
    %792 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1245)
    %793 = "ttir.tanh"(%791, %792) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1245)
    %794 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1246)
    %795 = "ttir.multiply"(%779, %793, %794) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1246)
    %796 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1247)
    %797 = "ttir.transpose"(%795, %796) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1247)
    %798 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1248)
    %799 = "ttir.transpose"(%797, %798) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1248)
    %800 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1249)
    %801 = "ttir.conv2d"(%799, %arg385, %800) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1249)
    %802 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1250)
    %803 = "ttir.transpose"(%801, %802) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1250)
    %804 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1251)
    %805 = "ttir.transpose"(%803, %804) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1251)
    %806 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc54)
    %807 = "ttir.multiply"(%805, %arg105, %806) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc54)
    %808 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc692)
    %809 = "ttir.add"(%807, %arg106, %808) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc692)
    %810 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc693)
    %811 = "ttir.gt"(%809, %arg107, %810) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc693)
    %812 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc55)
    %813 = "ttir.typecast"(%811, %812) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc55)
    %814 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc694)
    %815 = "ttir.exp"(%809, %814) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc694)
    %816 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc695)
    %817 = "ttir.add"(%815, %arg108, %816) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc695)
    %818 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc696)
    %819 = "ttir.log"(%817, %818) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc696)
    %820 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc697)
    %821 = "ttir.where"(%813, %809, %819, %820) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc697)
    %822 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc698)
    %823 = "ttir.tanh"(%821, %822) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc698)
    %824 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc699)
    %825 = "ttir.multiply"(%809, %823, %824) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc699)
    %826 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc700)
    %827 = "ttir.add"(%765, %825, %826) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc700)
    %828 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1252)
    %829 = "ttir.transpose"(%827, %828) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1252)
    %830 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1253)
    %831 = "ttir.transpose"(%829, %830) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1253)
    %832 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1254)
    %833 = "ttir.conv2d"(%831, %arg386, %832) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1254)
    %834 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1255)
    %835 = "ttir.transpose"(%833, %834) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1255)
    %836 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1256)
    %837 = "ttir.transpose"(%835, %836) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1256)
    %838 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc56)
    %839 = "ttir.multiply"(%837, %arg109, %838) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc56)
    %840 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1257)
    %841 = "ttir.add"(%839, %arg110, %840) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1257)
    %842 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1258)
    %843 = "ttir.gt"(%841, %arg111, %842) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1258)
    %844 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc57)
    %845 = "ttir.typecast"(%843, %844) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc57)
    %846 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1259)
    %847 = "ttir.exp"(%841, %846) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1259)
    %848 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1260)
    %849 = "ttir.add"(%847, %arg112, %848) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1260)
    %850 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1261)
    %851 = "ttir.log"(%849, %850) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1261)
    %852 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1262)
    %853 = "ttir.where"(%845, %841, %851, %852) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1262)
    %854 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1263)
    %855 = "ttir.tanh"(%853, %854) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1263)
    %856 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1264)
    %857 = "ttir.multiply"(%841, %855, %856) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1264)
    %858 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1265)
    %859 = "ttir.transpose"(%857, %858) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1265)
    %860 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1266)
    %861 = "ttir.transpose"(%859, %860) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1266)
    %862 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1267)
    %863 = "ttir.conv2d"(%861, %arg387, %862) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1267)
    %864 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1268)
    %865 = "ttir.transpose"(%863, %864) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1268)
    %866 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1269)
    %867 = "ttir.transpose"(%865, %866) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1269)
    %868 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc58)
    %869 = "ttir.multiply"(%867, %arg113, %868) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc58)
    %870 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc701)
    %871 = "ttir.add"(%869, %arg114, %870) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc701)
    %872 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc702)
    %873 = "ttir.gt"(%871, %arg115, %872) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc702)
    %874 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc59)
    %875 = "ttir.typecast"(%873, %874) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc59)
    %876 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc703)
    %877 = "ttir.exp"(%871, %876) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc703)
    %878 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc704)
    %879 = "ttir.add"(%877, %arg116, %878) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc704)
    %880 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc705)
    %881 = "ttir.log"(%879, %880) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc705)
    %882 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc706)
    %883 = "ttir.where"(%875, %871, %881, %882) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc706)
    %884 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc707)
    %885 = "ttir.tanh"(%883, %884) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc707)
    %886 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc708)
    %887 = "ttir.multiply"(%871, %885, %886) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc708)
    %888 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc709)
    %889 = "ttir.add"(%827, %887, %888) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc709)
    %890 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1270)
    %891 = "ttir.transpose"(%889, %890) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1270)
    %892 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1271)
    %893 = "ttir.transpose"(%891, %892) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1271)
    %894 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1272)
    %895 = "ttir.conv2d"(%893, %arg388, %894) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1272)
    %896 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1273)
    %897 = "ttir.transpose"(%895, %896) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1273)
    %898 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1274)
    %899 = "ttir.transpose"(%897, %898) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1274)
    %900 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc60)
    %901 = "ttir.multiply"(%899, %arg117, %900) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc60)
    %902 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1275)
    %903 = "ttir.add"(%901, %arg118, %902) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1275)
    %904 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1276)
    %905 = "ttir.gt"(%903, %arg119, %904) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1276)
    %906 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc61)
    %907 = "ttir.typecast"(%905, %906) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc61)
    %908 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1277)
    %909 = "ttir.exp"(%903, %908) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1277)
    %910 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1278)
    %911 = "ttir.add"(%909, %arg120, %910) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1278)
    %912 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1279)
    %913 = "ttir.log"(%911, %912) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1279)
    %914 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1280)
    %915 = "ttir.where"(%907, %903, %913, %914) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1280)
    %916 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1281)
    %917 = "ttir.tanh"(%915, %916) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1281)
    %918 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1282)
    %919 = "ttir.multiply"(%903, %917, %918) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1282)
    %920 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1283)
    %921 = "ttir.transpose"(%919, %920) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1283)
    %922 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1284)
    %923 = "ttir.transpose"(%921, %922) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1284)
    %924 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1285)
    %925 = "ttir.conv2d"(%923, %arg389, %924) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1285)
    %926 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1286)
    %927 = "ttir.transpose"(%925, %926) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1286)
    %928 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1287)
    %929 = "ttir.transpose"(%927, %928) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1287)
    %930 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc62)
    %931 = "ttir.multiply"(%929, %arg121, %930) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc62)
    %932 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc710)
    %933 = "ttir.add"(%931, %arg122, %932) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc710)
    %934 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc711)
    %935 = "ttir.gt"(%933, %arg123, %934) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc711)
    %936 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc63)
    %937 = "ttir.typecast"(%935, %936) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc63)
    %938 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc712)
    %939 = "ttir.exp"(%933, %938) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc712)
    %940 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc713)
    %941 = "ttir.add"(%939, %arg124, %940) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc713)
    %942 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc714)
    %943 = "ttir.log"(%941, %942) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc714)
    %944 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc715)
    %945 = "ttir.where"(%937, %933, %943, %944) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc715)
    %946 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc716)
    %947 = "ttir.tanh"(%945, %946) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc716)
    %948 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc717)
    %949 = "ttir.multiply"(%933, %947, %948) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc717)
    %950 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc718)
    %951 = "ttir.add"(%889, %949, %950) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc718)
    %952 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1288)
    %953 = "ttir.transpose"(%951, %952) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1288)
    %954 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1289)
    %955 = "ttir.transpose"(%953, %954) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1289)
    %956 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1290)
    %957 = "ttir.conv2d"(%955, %arg390, %956) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1290)
    %958 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1291)
    %959 = "ttir.transpose"(%957, %958) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1291)
    %960 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1292)
    %961 = "ttir.transpose"(%959, %960) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1292)
    %962 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc64)
    %963 = "ttir.multiply"(%961, %arg125, %962) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc64)
    %964 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1293)
    %965 = "ttir.add"(%963, %arg126, %964) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1293)
    %966 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1294)
    %967 = "ttir.gt"(%965, %arg127, %966) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1294)
    %968 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc65)
    %969 = "ttir.typecast"(%967, %968) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc65)
    %970 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1295)
    %971 = "ttir.exp"(%965, %970) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1295)
    %972 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1296)
    %973 = "ttir.add"(%971, %arg128, %972) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1296)
    %974 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1297)
    %975 = "ttir.log"(%973, %974) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1297)
    %976 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1298)
    %977 = "ttir.where"(%969, %965, %975, %976) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1298)
    %978 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1299)
    %979 = "ttir.tanh"(%977, %978) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1299)
    %980 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1300)
    %981 = "ttir.multiply"(%965, %979, %980) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1300)
    %982 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1301)
    %983 = "ttir.transpose"(%981, %982) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1301)
    %984 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1302)
    %985 = "ttir.transpose"(%983, %984) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1302)
    %986 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1303)
    %987 = "ttir.conv2d"(%985, %arg391, %986) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1303)
    %988 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1304)
    %989 = "ttir.transpose"(%987, %988) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1304)
    %990 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1305)
    %991 = "ttir.transpose"(%989, %990) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1305)
    %992 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc66)
    %993 = "ttir.multiply"(%991, %arg129, %992) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc66)
    %994 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc719)
    %995 = "ttir.add"(%993, %arg130, %994) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc719)
    %996 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc720)
    %997 = "ttir.gt"(%995, %arg131, %996) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc720)
    %998 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc67)
    %999 = "ttir.typecast"(%997, %998) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc67)
    %1000 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc721)
    %1001 = "ttir.exp"(%995, %1000) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc721)
    %1002 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc722)
    %1003 = "ttir.add"(%1001, %arg132, %1002) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc722)
    %1004 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc723)
    %1005 = "ttir.log"(%1003, %1004) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc723)
    %1006 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc724)
    %1007 = "ttir.where"(%999, %995, %1005, %1006) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc724)
    %1008 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc725)
    %1009 = "ttir.tanh"(%1007, %1008) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc725)
    %1010 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc726)
    %1011 = "ttir.multiply"(%995, %1009, %1010) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc726)
    %1012 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc727)
    %1013 = "ttir.add"(%951, %1011, %1012) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc727)
    %1014 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1306)
    %1015 = "ttir.transpose"(%1013, %1014) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1306)
    %1016 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1307)
    %1017 = "ttir.transpose"(%1015, %1016) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1307)
    %1018 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1308)
    %1019 = "ttir.conv2d"(%1017, %arg392, %1018) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1308)
    %1020 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1309)
    %1021 = "ttir.transpose"(%1019, %1020) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1309)
    %1022 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1310)
    %1023 = "ttir.transpose"(%1021, %1022) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1310)
    %1024 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc68)
    %1025 = "ttir.multiply"(%1023, %arg133, %1024) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc68)
    %1026 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1311)
    %1027 = "ttir.add"(%1025, %arg134, %1026) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1311)
    %1028 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1312)
    %1029 = "ttir.gt"(%1027, %arg135, %1028) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1312)
    %1030 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc69)
    %1031 = "ttir.typecast"(%1029, %1030) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc69)
    %1032 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1313)
    %1033 = "ttir.exp"(%1027, %1032) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1313)
    %1034 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1314)
    %1035 = "ttir.add"(%1033, %arg136, %1034) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1314)
    %1036 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1315)
    %1037 = "ttir.log"(%1035, %1036) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1315)
    %1038 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1316)
    %1039 = "ttir.where"(%1031, %1027, %1037, %1038) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1316)
    %1040 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1317)
    %1041 = "ttir.tanh"(%1039, %1040) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1317)
    %1042 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1318)
    %1043 = "ttir.multiply"(%1027, %1041, %1042) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1318)
    %1044 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1319)
    %1045 = "ttir.transpose"(%1043, %1044) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1319)
    %1046 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1320)
    %1047 = "ttir.transpose"(%1045, %1046) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1320)
    %1048 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1321)
    %1049 = "ttir.conv2d"(%1047, %arg393, %1048) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x3x3xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1321)
    %1050 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1322)
    %1051 = "ttir.transpose"(%1049, %1050) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1322)
    %1052 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1323)
    %1053 = "ttir.transpose"(%1051, %1052) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1323)
    %1054 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc70)
    %1055 = "ttir.multiply"(%1053, %arg137, %1054) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc70)
    %1056 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc728)
    %1057 = "ttir.add"(%1055, %arg138, %1056) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc728)
    %1058 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc729)
    %1059 = "ttir.gt"(%1057, %arg139, %1058) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc729)
    %1060 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc71)
    %1061 = "ttir.typecast"(%1059, %1060) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc71)
    %1062 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc730)
    %1063 = "ttir.exp"(%1057, %1062) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc730)
    %1064 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc731)
    %1065 = "ttir.add"(%1063, %arg140, %1064) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc731)
    %1066 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc732)
    %1067 = "ttir.log"(%1065, %1066) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc732)
    %1068 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc733)
    %1069 = "ttir.where"(%1061, %1057, %1067, %1068) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc733)
    %1070 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc734)
    %1071 = "ttir.tanh"(%1069, %1070) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc734)
    %1072 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc735)
    %1073 = "ttir.multiply"(%1057, %1071, %1072) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc735)
    %1074 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc736)
    %1075 = "ttir.add"(%1013, %1073, %1074) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc736)
    %1076 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc737)
    %1077 = "ttir.transpose"(%1075, %1076) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc737)
    %1078 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc738)
    %1079 = "ttir.transpose"(%1077, %1078) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc738)
    %1080 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc739)
    %1081 = "ttir.conv2d"(%1079, %arg394, %1080) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<128x128x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc739)
    %1082 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc740)
    %1083 = "ttir.transpose"(%1081, %1082) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc740)
    %1084 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc741)
    %1085 = "ttir.transpose"(%1083, %1084) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc741)
    %1086 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc72)
    %1087 = "ttir.multiply"(%1085, %arg141, %1086) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc72)
    %1088 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc345)
    %1089 = "ttir.add"(%1087, %arg142, %1088) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc345)
    %1090 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc346)
    %1091 = "ttir.gt"(%1089, %arg143, %1090) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc346)
    %1092 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc73)
    %1093 = "ttir.typecast"(%1091, %1092) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc73)
    %1094 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc347)
    %1095 = "ttir.exp"(%1089, %1094) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc347)
    %1096 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc348)
    %1097 = "ttir.add"(%1095, %arg144, %1096) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc348)
    %1098 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc349)
    %1099 = "ttir.log"(%1097, %1098) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc349)
    %1100 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc350)
    %1101 = "ttir.where"(%1093, %1089, %1099, %1100) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc350)
    %1102 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc351)
    %1103 = "ttir.tanh"(%1101, %1102) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc351)
    %1104 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc352)
    %1105 = "ttir.multiply"(%1089, %1103, %1104) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc352)
    %1106 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc742)
    %1107 = "ttir.transpose"(%549, %1106) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc742)
    %1108 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc743)
    %1109 = "ttir.transpose"(%1107, %1108) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc743)
    %1110 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc744)
    %1111 = "ttir.conv2d"(%1109, %arg395, %1110) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc744)
    %1112 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc745)
    %1113 = "ttir.transpose"(%1111, %1112) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc745)
    %1114 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc746)
    %1115 = "ttir.transpose"(%1113, %1114) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc746)
    %1116 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc74)
    %1117 = "ttir.multiply"(%1115, %arg145, %1116) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc74)
    %1118 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc354)
    %1119 = "ttir.add"(%1117, %arg146, %1118) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc354)
    %1120 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc355)
    %1121 = "ttir.gt"(%1119, %arg147, %1120) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc355)
    %1122 = ttir.empty() : tensor<1x128x60x80xi32> loc(#loc75)
    %1123 = "ttir.typecast"(%1121, %1122) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xi32>) -> tensor<1x128x60x80xi32> loc(#loc75)
    %1124 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc356)
    %1125 = "ttir.exp"(%1119, %1124) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc356)
    %1126 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc357)
    %1127 = "ttir.add"(%1125, %arg148, %1126) : (tensor<1x128x60x80xbf16>, tensor<1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc357)
    %1128 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc358)
    %1129 = "ttir.log"(%1127, %1128) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc358)
    %1130 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc359)
    %1131 = "ttir.where"(%1123, %1119, %1129, %1130) : (tensor<1x128x60x80xi32>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc359)
    %1132 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc360)
    %1133 = "ttir.tanh"(%1131, %1132) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc360)
    %1134 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc361)
    %1135 = "ttir.multiply"(%1119, %1133, %1134) : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc361)
    %1136 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc362)
    %1137 = "ttir.concat"(%1105, %1135, %1136) <{dim = -3 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc362)
    %1138 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc747)
    %1139 = "ttir.transpose"(%1137, %1138) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc747)
    %1140 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc748)
    %1141 = "ttir.transpose"(%1139, %1140) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc748)
    %1142 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc749)
    %1143 = "ttir.conv2d"(%1141, %arg396, %1142) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc749)
    %1144 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc750)
    %1145 = "ttir.transpose"(%1143, %1144) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x256xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc750)
    %1146 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc751)
    %1147 = "ttir.transpose"(%1145, %1146) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc751)
    %1148 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc76)
    %1149 = "ttir.multiply"(%1147, %arg149, %1148) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc76)
    %1150 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc364)
    %1151 = "ttir.add"(%1149, %arg150, %1150) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc364)
    %1152 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc365)
    %1153 = "ttir.gt"(%1151, %arg151, %1152) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc365)
    %1154 = ttir.empty() : tensor<1x256x60x80xi32> loc(#loc77)
    %1155 = "ttir.typecast"(%1153, %1154) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xi32>) -> tensor<1x256x60x80xi32> loc(#loc77)
    %1156 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc366)
    %1157 = "ttir.exp"(%1151, %1156) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc366)
    %1158 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc367)
    %1159 = "ttir.add"(%1157, %arg152, %1158) : (tensor<1x256x60x80xbf16>, tensor<1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc367)
    %1160 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc368)
    %1161 = "ttir.log"(%1159, %1160) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc368)
    %1162 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc369)
    %1163 = "ttir.where"(%1155, %1151, %1161, %1162) : (tensor<1x256x60x80xi32>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc369)
    %1164 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc370)
    %1165 = "ttir.tanh"(%1163, %1164) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc370)
    %1166 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc371)
    %1167 = "ttir.multiply"(%1151, %1165, %1166) : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc371)
    %1168 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc752)
    %1169 = "ttir.transpose"(%1167, %1168) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc752)
    %1170 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc753)
    %1171 = "ttir.transpose"(%1169, %1170) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc753)
    %1172 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc754)
    %1173 = "ttir.conv2d"(%1171, %arg397, %1172) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc754)
    %1174 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc755)
    %1175 = "ttir.transpose"(%1173, %1174) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc755)
    %1176 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc756)
    %1177 = "ttir.transpose"(%1175, %1176) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc756)
    %1178 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc78)
    %1179 = "ttir.multiply"(%1177, %arg153, %1178) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc78)
    %1180 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc79)
    %1181 = "ttir.add"(%1179, %arg154, %1180) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc79)
    %1182 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc373)
    %1183 = "ttir.leaky_relu"(%1181, %1182) <{parameter = 1.000000e-01 : f32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc373)
    %1184 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc757)
    %1185 = "ttir.transpose"(%1167, %1184) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc757)
    %1186 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc758)
    %1187 = "ttir.transpose"(%1185, %1186) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc758)
    %1188 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc759)
    %1189 = "ttir.conv2d"(%1187, %arg398, %1188) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc759)
    %1190 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc760)
    %1191 = "ttir.transpose"(%1189, %1190) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc760)
    %1192 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc761)
    %1193 = "ttir.transpose"(%1191, %1192) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc761)
    %1194 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc80)
    %1195 = "ttir.multiply"(%1193, %arg155, %1194) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc80)
    %1196 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc762)
    %1197 = "ttir.add"(%1195, %arg156, %1196) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc762)
    %1198 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc763)
    %1199 = "ttir.gt"(%1197, %arg157, %1198) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc763)
    %1200 = ttir.empty() : tensor<1x512x30x40xi32> loc(#loc81)
    %1201 = "ttir.typecast"(%1199, %1200) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xi32>) -> tensor<1x512x30x40xi32> loc(#loc81)
    %1202 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc764)
    %1203 = "ttir.exp"(%1197, %1202) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc764)
    %1204 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc765)
    %1205 = "ttir.add"(%1203, %arg158, %1204) : (tensor<1x512x30x40xbf16>, tensor<1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc765)
    %1206 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc766)
    %1207 = "ttir.log"(%1205, %1206) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc766)
    %1208 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc767)
    %1209 = "ttir.where"(%1201, %1197, %1207, %1208) : (tensor<1x512x30x40xi32>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc767)
    %1210 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc768)
    %1211 = "ttir.tanh"(%1209, %1210) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc768)
    %1212 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc769)
    %1213 = "ttir.multiply"(%1197, %1211, %1212) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc769)
    %1214 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc770)
    %1215 = "ttir.transpose"(%1213, %1214) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc770)
    %1216 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc771)
    %1217 = "ttir.transpose"(%1215, %1216) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc771)
    %1218 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc772)
    %1219 = "ttir.conv2d"(%1217, %arg399, %1218) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc772)
    %1220 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc773)
    %1221 = "ttir.transpose"(%1219, %1220) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc773)
    %1222 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc774)
    %1223 = "ttir.transpose"(%1221, %1222) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc774)
    %1224 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc82)
    %1225 = "ttir.multiply"(%1223, %arg159, %1224) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc82)
    %1226 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc377)
    %1227 = "ttir.add"(%1225, %arg160, %1226) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc377)
    %1228 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc378)
    %1229 = "ttir.gt"(%1227, %arg161, %1228) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc378)
    %1230 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc83)
    %1231 = "ttir.typecast"(%1229, %1230) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc83)
    %1232 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc379)
    %1233 = "ttir.exp"(%1227, %1232) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc379)
    %1234 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc380)
    %1235 = "ttir.add"(%1233, %arg162, %1234) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc380)
    %1236 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc381)
    %1237 = "ttir.log"(%1235, %1236) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc381)
    %1238 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc382)
    %1239 = "ttir.where"(%1231, %1227, %1237, %1238) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc382)
    %1240 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc383)
    %1241 = "ttir.tanh"(%1239, %1240) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc383)
    %1242 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc384)
    %1243 = "ttir.multiply"(%1227, %1241, %1242) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc384)
    %1244 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1324)
    %1245 = "ttir.transpose"(%1243, %1244) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1324)
    %1246 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1325)
    %1247 = "ttir.transpose"(%1245, %1246) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1325)
    %1248 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1326)
    %1249 = "ttir.conv2d"(%1247, %arg400, %1248) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1326)
    %1250 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1327)
    %1251 = "ttir.transpose"(%1249, %1250) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1327)
    %1252 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1328)
    %1253 = "ttir.transpose"(%1251, %1252) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1328)
    %1254 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc84)
    %1255 = "ttir.multiply"(%1253, %arg163, %1254) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc84)
    %1256 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1329)
    %1257 = "ttir.add"(%1255, %arg164, %1256) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1329)
    %1258 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1330)
    %1259 = "ttir.gt"(%1257, %arg165, %1258) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1330)
    %1260 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc85)
    %1261 = "ttir.typecast"(%1259, %1260) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc85)
    %1262 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1331)
    %1263 = "ttir.exp"(%1257, %1262) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1331)
    %1264 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1332)
    %1265 = "ttir.add"(%1263, %arg166, %1264) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1332)
    %1266 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1333)
    %1267 = "ttir.log"(%1265, %1266) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1333)
    %1268 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1334)
    %1269 = "ttir.where"(%1261, %1257, %1267, %1268) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1334)
    %1270 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1335)
    %1271 = "ttir.tanh"(%1269, %1270) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1335)
    %1272 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1336)
    %1273 = "ttir.multiply"(%1257, %1271, %1272) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1336)
    %1274 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1337)
    %1275 = "ttir.transpose"(%1273, %1274) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1337)
    %1276 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1338)
    %1277 = "ttir.transpose"(%1275, %1276) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1338)
    %1278 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1339)
    %1279 = "ttir.conv2d"(%1277, %arg401, %1278) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1339)
    %1280 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1340)
    %1281 = "ttir.transpose"(%1279, %1280) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1340)
    %1282 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1341)
    %1283 = "ttir.transpose"(%1281, %1282) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1341)
    %1284 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc86)
    %1285 = "ttir.multiply"(%1283, %arg167, %1284) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc86)
    %1286 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc778)
    %1287 = "ttir.add"(%1285, %arg168, %1286) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc778)
    %1288 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc779)
    %1289 = "ttir.gt"(%1287, %arg169, %1288) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc779)
    %1290 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc87)
    %1291 = "ttir.typecast"(%1289, %1290) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc87)
    %1292 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc780)
    %1293 = "ttir.exp"(%1287, %1292) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc780)
    %1294 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc781)
    %1295 = "ttir.add"(%1293, %arg170, %1294) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc781)
    %1296 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc782)
    %1297 = "ttir.log"(%1295, %1296) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc782)
    %1298 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc783)
    %1299 = "ttir.where"(%1291, %1287, %1297, %1298) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc783)
    %1300 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc784)
    %1301 = "ttir.tanh"(%1299, %1300) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc784)
    %1302 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc785)
    %1303 = "ttir.multiply"(%1287, %1301, %1302) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc785)
    %1304 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc786)
    %1305 = "ttir.add"(%1243, %1303, %1304) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc786)
    %1306 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1342)
    %1307 = "ttir.transpose"(%1305, %1306) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1342)
    %1308 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1343)
    %1309 = "ttir.transpose"(%1307, %1308) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1343)
    %1310 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1344)
    %1311 = "ttir.conv2d"(%1309, %arg402, %1310) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1344)
    %1312 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1345)
    %1313 = "ttir.transpose"(%1311, %1312) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1345)
    %1314 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1346)
    %1315 = "ttir.transpose"(%1313, %1314) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1346)
    %1316 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc88)
    %1317 = "ttir.multiply"(%1315, %arg171, %1316) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc88)
    %1318 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1347)
    %1319 = "ttir.add"(%1317, %arg172, %1318) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1347)
    %1320 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1348)
    %1321 = "ttir.gt"(%1319, %arg173, %1320) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1348)
    %1322 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc89)
    %1323 = "ttir.typecast"(%1321, %1322) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc89)
    %1324 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1349)
    %1325 = "ttir.exp"(%1319, %1324) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1349)
    %1326 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1350)
    %1327 = "ttir.add"(%1325, %arg174, %1326) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1350)
    %1328 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1351)
    %1329 = "ttir.log"(%1327, %1328) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1351)
    %1330 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1352)
    %1331 = "ttir.where"(%1323, %1319, %1329, %1330) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1352)
    %1332 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1353)
    %1333 = "ttir.tanh"(%1331, %1332) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1353)
    %1334 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1354)
    %1335 = "ttir.multiply"(%1319, %1333, %1334) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1354)
    %1336 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1355)
    %1337 = "ttir.transpose"(%1335, %1336) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1355)
    %1338 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1356)
    %1339 = "ttir.transpose"(%1337, %1338) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1356)
    %1340 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1357)
    %1341 = "ttir.conv2d"(%1339, %arg403, %1340) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1357)
    %1342 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1358)
    %1343 = "ttir.transpose"(%1341, %1342) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1358)
    %1344 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1359)
    %1345 = "ttir.transpose"(%1343, %1344) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1359)
    %1346 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc90)
    %1347 = "ttir.multiply"(%1345, %arg175, %1346) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc90)
    %1348 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc787)
    %1349 = "ttir.add"(%1347, %arg176, %1348) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc787)
    %1350 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc788)
    %1351 = "ttir.gt"(%1349, %arg177, %1350) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc788)
    %1352 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc91)
    %1353 = "ttir.typecast"(%1351, %1352) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc91)
    %1354 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc789)
    %1355 = "ttir.exp"(%1349, %1354) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc789)
    %1356 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc790)
    %1357 = "ttir.add"(%1355, %arg178, %1356) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc790)
    %1358 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc791)
    %1359 = "ttir.log"(%1357, %1358) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc791)
    %1360 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc792)
    %1361 = "ttir.where"(%1353, %1349, %1359, %1360) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc792)
    %1362 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc793)
    %1363 = "ttir.tanh"(%1361, %1362) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc793)
    %1364 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc794)
    %1365 = "ttir.multiply"(%1349, %1363, %1364) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc794)
    %1366 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc795)
    %1367 = "ttir.add"(%1305, %1365, %1366) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc795)
    %1368 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1360)
    %1369 = "ttir.transpose"(%1367, %1368) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1360)
    %1370 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1361)
    %1371 = "ttir.transpose"(%1369, %1370) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1361)
    %1372 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1362)
    %1373 = "ttir.conv2d"(%1371, %arg404, %1372) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1362)
    %1374 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1363)
    %1375 = "ttir.transpose"(%1373, %1374) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1363)
    %1376 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1364)
    %1377 = "ttir.transpose"(%1375, %1376) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1364)
    %1378 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc92)
    %1379 = "ttir.multiply"(%1377, %arg179, %1378) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc92)
    %1380 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1365)
    %1381 = "ttir.add"(%1379, %arg180, %1380) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1365)
    %1382 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1366)
    %1383 = "ttir.gt"(%1381, %arg181, %1382) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1366)
    %1384 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc93)
    %1385 = "ttir.typecast"(%1383, %1384) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc93)
    %1386 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1367)
    %1387 = "ttir.exp"(%1381, %1386) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1367)
    %1388 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1368)
    %1389 = "ttir.add"(%1387, %arg182, %1388) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1368)
    %1390 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1369)
    %1391 = "ttir.log"(%1389, %1390) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1369)
    %1392 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1370)
    %1393 = "ttir.where"(%1385, %1381, %1391, %1392) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1370)
    %1394 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1371)
    %1395 = "ttir.tanh"(%1393, %1394) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1371)
    %1396 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1372)
    %1397 = "ttir.multiply"(%1381, %1395, %1396) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1372)
    %1398 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1373)
    %1399 = "ttir.transpose"(%1397, %1398) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1373)
    %1400 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1374)
    %1401 = "ttir.transpose"(%1399, %1400) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1374)
    %1402 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1375)
    %1403 = "ttir.conv2d"(%1401, %arg405, %1402) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1375)
    %1404 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1376)
    %1405 = "ttir.transpose"(%1403, %1404) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1376)
    %1406 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1377)
    %1407 = "ttir.transpose"(%1405, %1406) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1377)
    %1408 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc94)
    %1409 = "ttir.multiply"(%1407, %arg183, %1408) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc94)
    %1410 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc796)
    %1411 = "ttir.add"(%1409, %arg184, %1410) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc796)
    %1412 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc797)
    %1413 = "ttir.gt"(%1411, %arg185, %1412) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc797)
    %1414 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc95)
    %1415 = "ttir.typecast"(%1413, %1414) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc95)
    %1416 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc798)
    %1417 = "ttir.exp"(%1411, %1416) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc798)
    %1418 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc799)
    %1419 = "ttir.add"(%1417, %arg186, %1418) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc799)
    %1420 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc800)
    %1421 = "ttir.log"(%1419, %1420) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc800)
    %1422 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc801)
    %1423 = "ttir.where"(%1415, %1411, %1421, %1422) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc801)
    %1424 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc802)
    %1425 = "ttir.tanh"(%1423, %1424) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc802)
    %1426 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc803)
    %1427 = "ttir.multiply"(%1411, %1425, %1426) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc803)
    %1428 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc804)
    %1429 = "ttir.add"(%1367, %1427, %1428) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc804)
    %1430 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1378)
    %1431 = "ttir.transpose"(%1429, %1430) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1378)
    %1432 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1379)
    %1433 = "ttir.transpose"(%1431, %1432) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1379)
    %1434 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1380)
    %1435 = "ttir.conv2d"(%1433, %arg406, %1434) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1380)
    %1436 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1381)
    %1437 = "ttir.transpose"(%1435, %1436) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1381)
    %1438 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1382)
    %1439 = "ttir.transpose"(%1437, %1438) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1382)
    %1440 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc96)
    %1441 = "ttir.multiply"(%1439, %arg187, %1440) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc96)
    %1442 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1383)
    %1443 = "ttir.add"(%1441, %arg188, %1442) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1383)
    %1444 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1384)
    %1445 = "ttir.gt"(%1443, %arg189, %1444) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1384)
    %1446 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc97)
    %1447 = "ttir.typecast"(%1445, %1446) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc97)
    %1448 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1385)
    %1449 = "ttir.exp"(%1443, %1448) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1385)
    %1450 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1386)
    %1451 = "ttir.add"(%1449, %arg190, %1450) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1386)
    %1452 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1387)
    %1453 = "ttir.log"(%1451, %1452) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1387)
    %1454 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1388)
    %1455 = "ttir.where"(%1447, %1443, %1453, %1454) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1388)
    %1456 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1389)
    %1457 = "ttir.tanh"(%1455, %1456) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1389)
    %1458 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1390)
    %1459 = "ttir.multiply"(%1443, %1457, %1458) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1390)
    %1460 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1391)
    %1461 = "ttir.transpose"(%1459, %1460) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1391)
    %1462 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1392)
    %1463 = "ttir.transpose"(%1461, %1462) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1392)
    %1464 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1393)
    %1465 = "ttir.conv2d"(%1463, %arg407, %1464) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1393)
    %1466 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1394)
    %1467 = "ttir.transpose"(%1465, %1466) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1394)
    %1468 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1395)
    %1469 = "ttir.transpose"(%1467, %1468) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1395)
    %1470 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc98)
    %1471 = "ttir.multiply"(%1469, %arg191, %1470) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc98)
    %1472 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc805)
    %1473 = "ttir.add"(%1471, %arg192, %1472) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc805)
    %1474 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc806)
    %1475 = "ttir.gt"(%1473, %arg193, %1474) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc806)
    %1476 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc99)
    %1477 = "ttir.typecast"(%1475, %1476) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc99)
    %1478 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc807)
    %1479 = "ttir.exp"(%1473, %1478) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc807)
    %1480 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc808)
    %1481 = "ttir.add"(%1479, %arg194, %1480) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc808)
    %1482 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc809)
    %1483 = "ttir.log"(%1481, %1482) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc809)
    %1484 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc810)
    %1485 = "ttir.where"(%1477, %1473, %1483, %1484) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc810)
    %1486 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc811)
    %1487 = "ttir.tanh"(%1485, %1486) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc811)
    %1488 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc812)
    %1489 = "ttir.multiply"(%1473, %1487, %1488) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc812)
    %1490 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc813)
    %1491 = "ttir.add"(%1429, %1489, %1490) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc813)
    %1492 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1396)
    %1493 = "ttir.transpose"(%1491, %1492) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1396)
    %1494 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1397)
    %1495 = "ttir.transpose"(%1493, %1494) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1397)
    %1496 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1398)
    %1497 = "ttir.conv2d"(%1495, %arg408, %1496) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1398)
    %1498 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1399)
    %1499 = "ttir.transpose"(%1497, %1498) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1399)
    %1500 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1400)
    %1501 = "ttir.transpose"(%1499, %1500) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1400)
    %1502 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc100)
    %1503 = "ttir.multiply"(%1501, %arg195, %1502) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc100)
    %1504 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1401)
    %1505 = "ttir.add"(%1503, %arg196, %1504) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1401)
    %1506 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1402)
    %1507 = "ttir.gt"(%1505, %arg197, %1506) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1402)
    %1508 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc101)
    %1509 = "ttir.typecast"(%1507, %1508) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc101)
    %1510 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1403)
    %1511 = "ttir.exp"(%1505, %1510) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1403)
    %1512 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1404)
    %1513 = "ttir.add"(%1511, %arg198, %1512) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1404)
    %1514 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1405)
    %1515 = "ttir.log"(%1513, %1514) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1405)
    %1516 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1406)
    %1517 = "ttir.where"(%1509, %1505, %1515, %1516) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1406)
    %1518 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1407)
    %1519 = "ttir.tanh"(%1517, %1518) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1407)
    %1520 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1408)
    %1521 = "ttir.multiply"(%1505, %1519, %1520) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1408)
    %1522 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1409)
    %1523 = "ttir.transpose"(%1521, %1522) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1409)
    %1524 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1410)
    %1525 = "ttir.transpose"(%1523, %1524) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1410)
    %1526 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1411)
    %1527 = "ttir.conv2d"(%1525, %arg409, %1526) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1411)
    %1528 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1412)
    %1529 = "ttir.transpose"(%1527, %1528) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1412)
    %1530 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1413)
    %1531 = "ttir.transpose"(%1529, %1530) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1413)
    %1532 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc102)
    %1533 = "ttir.multiply"(%1531, %arg199, %1532) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc102)
    %1534 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc814)
    %1535 = "ttir.add"(%1533, %arg200, %1534) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc814)
    %1536 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc815)
    %1537 = "ttir.gt"(%1535, %arg201, %1536) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc815)
    %1538 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc103)
    %1539 = "ttir.typecast"(%1537, %1538) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc103)
    %1540 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc816)
    %1541 = "ttir.exp"(%1535, %1540) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc816)
    %1542 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc817)
    %1543 = "ttir.add"(%1541, %arg202, %1542) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc817)
    %1544 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc818)
    %1545 = "ttir.log"(%1543, %1544) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc818)
    %1546 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc819)
    %1547 = "ttir.where"(%1539, %1535, %1545, %1546) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc819)
    %1548 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc820)
    %1549 = "ttir.tanh"(%1547, %1548) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc820)
    %1550 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc821)
    %1551 = "ttir.multiply"(%1535, %1549, %1550) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc821)
    %1552 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc822)
    %1553 = "ttir.add"(%1491, %1551, %1552) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc822)
    %1554 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1414)
    %1555 = "ttir.transpose"(%1553, %1554) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1414)
    %1556 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1415)
    %1557 = "ttir.transpose"(%1555, %1556) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1415)
    %1558 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1416)
    %1559 = "ttir.conv2d"(%1557, %arg410, %1558) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1416)
    %1560 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1417)
    %1561 = "ttir.transpose"(%1559, %1560) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1417)
    %1562 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1418)
    %1563 = "ttir.transpose"(%1561, %1562) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1418)
    %1564 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc104)
    %1565 = "ttir.multiply"(%1563, %arg203, %1564) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc104)
    %1566 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1419)
    %1567 = "ttir.add"(%1565, %arg204, %1566) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1419)
    %1568 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1420)
    %1569 = "ttir.gt"(%1567, %arg205, %1568) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1420)
    %1570 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc105)
    %1571 = "ttir.typecast"(%1569, %1570) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc105)
    %1572 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1421)
    %1573 = "ttir.exp"(%1567, %1572) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1421)
    %1574 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1422)
    %1575 = "ttir.add"(%1573, %arg206, %1574) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1422)
    %1576 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1423)
    %1577 = "ttir.log"(%1575, %1576) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1423)
    %1578 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1424)
    %1579 = "ttir.where"(%1571, %1567, %1577, %1578) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1424)
    %1580 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1425)
    %1581 = "ttir.tanh"(%1579, %1580) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1425)
    %1582 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1426)
    %1583 = "ttir.multiply"(%1567, %1581, %1582) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1426)
    %1584 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1427)
    %1585 = "ttir.transpose"(%1583, %1584) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1427)
    %1586 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1428)
    %1587 = "ttir.transpose"(%1585, %1586) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1428)
    %1588 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1429)
    %1589 = "ttir.conv2d"(%1587, %arg411, %1588) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1429)
    %1590 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1430)
    %1591 = "ttir.transpose"(%1589, %1590) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1430)
    %1592 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1431)
    %1593 = "ttir.transpose"(%1591, %1592) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1431)
    %1594 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc106)
    %1595 = "ttir.multiply"(%1593, %arg207, %1594) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc106)
    %1596 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc823)
    %1597 = "ttir.add"(%1595, %arg208, %1596) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc823)
    %1598 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc824)
    %1599 = "ttir.gt"(%1597, %arg209, %1598) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc824)
    %1600 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc107)
    %1601 = "ttir.typecast"(%1599, %1600) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc107)
    %1602 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc825)
    %1603 = "ttir.exp"(%1597, %1602) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc825)
    %1604 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc826)
    %1605 = "ttir.add"(%1603, %arg210, %1604) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc826)
    %1606 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc827)
    %1607 = "ttir.log"(%1605, %1606) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc827)
    %1608 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc828)
    %1609 = "ttir.where"(%1601, %1597, %1607, %1608) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc828)
    %1610 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc829)
    %1611 = "ttir.tanh"(%1609, %1610) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc829)
    %1612 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc830)
    %1613 = "ttir.multiply"(%1597, %1611, %1612) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc830)
    %1614 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc831)
    %1615 = "ttir.add"(%1553, %1613, %1614) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc831)
    %1616 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1432)
    %1617 = "ttir.transpose"(%1615, %1616) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1432)
    %1618 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1433)
    %1619 = "ttir.transpose"(%1617, %1618) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1433)
    %1620 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1434)
    %1621 = "ttir.conv2d"(%1619, %arg412, %1620) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1434)
    %1622 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1435)
    %1623 = "ttir.transpose"(%1621, %1622) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1435)
    %1624 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1436)
    %1625 = "ttir.transpose"(%1623, %1624) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1436)
    %1626 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc108)
    %1627 = "ttir.multiply"(%1625, %arg211, %1626) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc108)
    %1628 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1437)
    %1629 = "ttir.add"(%1627, %arg212, %1628) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1437)
    %1630 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1438)
    %1631 = "ttir.gt"(%1629, %arg213, %1630) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1438)
    %1632 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc109)
    %1633 = "ttir.typecast"(%1631, %1632) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc109)
    %1634 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1439)
    %1635 = "ttir.exp"(%1629, %1634) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1439)
    %1636 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1440)
    %1637 = "ttir.add"(%1635, %arg214, %1636) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1440)
    %1638 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1441)
    %1639 = "ttir.log"(%1637, %1638) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1441)
    %1640 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1442)
    %1641 = "ttir.where"(%1633, %1629, %1639, %1640) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1442)
    %1642 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1443)
    %1643 = "ttir.tanh"(%1641, %1642) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1443)
    %1644 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1444)
    %1645 = "ttir.multiply"(%1629, %1643, %1644) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1444)
    %1646 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1445)
    %1647 = "ttir.transpose"(%1645, %1646) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1445)
    %1648 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1446)
    %1649 = "ttir.transpose"(%1647, %1648) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1446)
    %1650 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1447)
    %1651 = "ttir.conv2d"(%1649, %arg413, %1650) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1447)
    %1652 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1448)
    %1653 = "ttir.transpose"(%1651, %1652) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1448)
    %1654 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1449)
    %1655 = "ttir.transpose"(%1653, %1654) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1449)
    %1656 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc110)
    %1657 = "ttir.multiply"(%1655, %arg215, %1656) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc110)
    %1658 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc832)
    %1659 = "ttir.add"(%1657, %arg216, %1658) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc832)
    %1660 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc833)
    %1661 = "ttir.gt"(%1659, %arg217, %1660) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc833)
    %1662 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc111)
    %1663 = "ttir.typecast"(%1661, %1662) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc111)
    %1664 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc834)
    %1665 = "ttir.exp"(%1659, %1664) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc834)
    %1666 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc835)
    %1667 = "ttir.add"(%1665, %arg218, %1666) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc835)
    %1668 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc836)
    %1669 = "ttir.log"(%1667, %1668) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc836)
    %1670 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc837)
    %1671 = "ttir.where"(%1663, %1659, %1669, %1670) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc837)
    %1672 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc838)
    %1673 = "ttir.tanh"(%1671, %1672) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc838)
    %1674 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc839)
    %1675 = "ttir.multiply"(%1659, %1673, %1674) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc839)
    %1676 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc840)
    %1677 = "ttir.add"(%1615, %1675, %1676) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc840)
    %1678 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1450)
    %1679 = "ttir.transpose"(%1677, %1678) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1450)
    %1680 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1451)
    %1681 = "ttir.transpose"(%1679, %1680) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1451)
    %1682 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1452)
    %1683 = "ttir.conv2d"(%1681, %arg414, %1682) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1452)
    %1684 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1453)
    %1685 = "ttir.transpose"(%1683, %1684) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1453)
    %1686 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1454)
    %1687 = "ttir.transpose"(%1685, %1686) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1454)
    %1688 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc112)
    %1689 = "ttir.multiply"(%1687, %arg219, %1688) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc112)
    %1690 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1455)
    %1691 = "ttir.add"(%1689, %arg220, %1690) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1455)
    %1692 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1456)
    %1693 = "ttir.gt"(%1691, %arg221, %1692) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1456)
    %1694 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc113)
    %1695 = "ttir.typecast"(%1693, %1694) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc113)
    %1696 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1457)
    %1697 = "ttir.exp"(%1691, %1696) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1457)
    %1698 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1458)
    %1699 = "ttir.add"(%1697, %arg222, %1698) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1458)
    %1700 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1459)
    %1701 = "ttir.log"(%1699, %1700) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1459)
    %1702 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1460)
    %1703 = "ttir.where"(%1695, %1691, %1701, %1702) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1460)
    %1704 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1461)
    %1705 = "ttir.tanh"(%1703, %1704) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1461)
    %1706 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1462)
    %1707 = "ttir.multiply"(%1691, %1705, %1706) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1462)
    %1708 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1463)
    %1709 = "ttir.transpose"(%1707, %1708) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1463)
    %1710 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1464)
    %1711 = "ttir.transpose"(%1709, %1710) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1464)
    %1712 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1465)
    %1713 = "ttir.conv2d"(%1711, %arg415, %1712) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1465)
    %1714 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1466)
    %1715 = "ttir.transpose"(%1713, %1714) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1466)
    %1716 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1467)
    %1717 = "ttir.transpose"(%1715, %1716) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1467)
    %1718 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc114)
    %1719 = "ttir.multiply"(%1717, %arg223, %1718) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc114)
    %1720 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc841)
    %1721 = "ttir.add"(%1719, %arg224, %1720) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc841)
    %1722 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc842)
    %1723 = "ttir.gt"(%1721, %arg225, %1722) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc842)
    %1724 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc115)
    %1725 = "ttir.typecast"(%1723, %1724) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc115)
    %1726 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc843)
    %1727 = "ttir.exp"(%1721, %1726) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc843)
    %1728 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc844)
    %1729 = "ttir.add"(%1727, %arg226, %1728) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc844)
    %1730 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc845)
    %1731 = "ttir.log"(%1729, %1730) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc845)
    %1732 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc846)
    %1733 = "ttir.where"(%1725, %1721, %1731, %1732) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc846)
    %1734 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc847)
    %1735 = "ttir.tanh"(%1733, %1734) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc847)
    %1736 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc848)
    %1737 = "ttir.multiply"(%1721, %1735, %1736) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc848)
    %1738 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc849)
    %1739 = "ttir.add"(%1677, %1737, %1738) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc849)
    %1740 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc850)
    %1741 = "ttir.transpose"(%1739, %1740) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc850)
    %1742 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc851)
    %1743 = "ttir.transpose"(%1741, %1742) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc851)
    %1744 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc852)
    %1745 = "ttir.conv2d"(%1743, %arg416, %1744) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc852)
    %1746 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc853)
    %1747 = "ttir.transpose"(%1745, %1746) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc853)
    %1748 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc854)
    %1749 = "ttir.transpose"(%1747, %1748) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc854)
    %1750 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc116)
    %1751 = "ttir.multiply"(%1749, %arg227, %1750) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc116)
    %1752 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc387)
    %1753 = "ttir.add"(%1751, %arg228, %1752) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc387)
    %1754 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc388)
    %1755 = "ttir.gt"(%1753, %arg229, %1754) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc388)
    %1756 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc117)
    %1757 = "ttir.typecast"(%1755, %1756) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc117)
    %1758 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc389)
    %1759 = "ttir.exp"(%1753, %1758) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc389)
    %1760 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc390)
    %1761 = "ttir.add"(%1759, %arg230, %1760) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc390)
    %1762 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc391)
    %1763 = "ttir.log"(%1761, %1762) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc391)
    %1764 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc392)
    %1765 = "ttir.where"(%1757, %1753, %1763, %1764) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc392)
    %1766 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc393)
    %1767 = "ttir.tanh"(%1765, %1766) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc393)
    %1768 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc394)
    %1769 = "ttir.multiply"(%1753, %1767, %1768) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc394)
    %1770 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc855)
    %1771 = "ttir.transpose"(%1213, %1770) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc855)
    %1772 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc856)
    %1773 = "ttir.transpose"(%1771, %1772) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc856)
    %1774 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc857)
    %1775 = "ttir.conv2d"(%1773, %arg417, %1774) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc857)
    %1776 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc858)
    %1777 = "ttir.transpose"(%1775, %1776) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc858)
    %1778 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc859)
    %1779 = "ttir.transpose"(%1777, %1778) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc859)
    %1780 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc118)
    %1781 = "ttir.multiply"(%1779, %arg231, %1780) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc118)
    %1782 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc396)
    %1783 = "ttir.add"(%1781, %arg232, %1782) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc396)
    %1784 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc397)
    %1785 = "ttir.gt"(%1783, %arg233, %1784) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc397)
    %1786 = ttir.empty() : tensor<1x256x30x40xi32> loc(#loc119)
    %1787 = "ttir.typecast"(%1785, %1786) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xi32>) -> tensor<1x256x30x40xi32> loc(#loc119)
    %1788 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc398)
    %1789 = "ttir.exp"(%1783, %1788) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc398)
    %1790 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc399)
    %1791 = "ttir.add"(%1789, %arg234, %1790) : (tensor<1x256x30x40xbf16>, tensor<1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc399)
    %1792 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc400)
    %1793 = "ttir.log"(%1791, %1792) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc400)
    %1794 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc401)
    %1795 = "ttir.where"(%1787, %1783, %1793, %1794) : (tensor<1x256x30x40xi32>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc401)
    %1796 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc402)
    %1797 = "ttir.tanh"(%1795, %1796) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc402)
    %1798 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc403)
    %1799 = "ttir.multiply"(%1783, %1797, %1798) : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc403)
    %1800 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc404)
    %1801 = "ttir.concat"(%1769, %1799, %1800) <{dim = -3 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc404)
    %1802 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc860)
    %1803 = "ttir.transpose"(%1801, %1802) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc860)
    %1804 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc861)
    %1805 = "ttir.transpose"(%1803, %1804) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc861)
    %1806 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc862)
    %1807 = "ttir.conv2d"(%1805, %arg418, %1806) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc862)
    %1808 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc863)
    %1809 = "ttir.transpose"(%1807, %1808) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc863)
    %1810 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc864)
    %1811 = "ttir.transpose"(%1809, %1810) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc864)
    %1812 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc120)
    %1813 = "ttir.multiply"(%1811, %arg235, %1812) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc120)
    %1814 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc406)
    %1815 = "ttir.add"(%1813, %arg236, %1814) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc406)
    %1816 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc407)
    %1817 = "ttir.gt"(%1815, %arg237, %1816) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc407)
    %1818 = ttir.empty() : tensor<1x512x30x40xi32> loc(#loc121)
    %1819 = "ttir.typecast"(%1817, %1818) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xi32>) -> tensor<1x512x30x40xi32> loc(#loc121)
    %1820 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc408)
    %1821 = "ttir.exp"(%1815, %1820) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc408)
    %1822 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc409)
    %1823 = "ttir.add"(%1821, %arg238, %1822) : (tensor<1x512x30x40xbf16>, tensor<1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc409)
    %1824 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc410)
    %1825 = "ttir.log"(%1823, %1824) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc410)
    %1826 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc411)
    %1827 = "ttir.where"(%1819, %1815, %1825, %1826) : (tensor<1x512x30x40xi32>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc411)
    %1828 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc412)
    %1829 = "ttir.tanh"(%1827, %1828) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc412)
    %1830 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc413)
    %1831 = "ttir.multiply"(%1815, %1829, %1830) : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc413)
    %1832 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc865)
    %1833 = "ttir.transpose"(%1831, %1832) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc865)
    %1834 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc866)
    %1835 = "ttir.transpose"(%1833, %1834) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc866)
    %1836 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc867)
    %1837 = "ttir.conv2d"(%1835, %arg419, %1836) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc867)
    %1838 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc868)
    %1839 = "ttir.transpose"(%1837, %1838) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc868)
    %1840 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc869)
    %1841 = "ttir.transpose"(%1839, %1840) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc869)
    %1842 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc122)
    %1843 = "ttir.multiply"(%1841, %arg239, %1842) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc122)
    %1844 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc123)
    %1845 = "ttir.add"(%1843, %arg240, %1844) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc123)
    %1846 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc415)
    %1847 = "ttir.leaky_relu"(%1845, %1846) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc415)
    %1848 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc870)
    %1849 = "ttir.transpose"(%1831, %1848) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc870)
    %1850 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc871)
    %1851 = "ttir.transpose"(%1849, %1850) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc871)
    %1852 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc872)
    %1853 = "ttir.conv2d"(%1851, %arg420, %1852) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc872)
    %1854 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc873)
    %1855 = "ttir.transpose"(%1853, %1854) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc873)
    %1856 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc874)
    %1857 = "ttir.transpose"(%1855, %1856) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc874)
    %1858 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc124)
    %1859 = "ttir.multiply"(%1857, %arg241, %1858) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc124)
    %1860 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc875)
    %1861 = "ttir.add"(%1859, %arg242, %1860) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc875)
    %1862 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc876)
    %1863 = "ttir.gt"(%1861, %arg243, %1862) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc876)
    %1864 = ttir.empty() : tensor<1x1024x15x20xi32> loc(#loc125)
    %1865 = "ttir.typecast"(%1863, %1864) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xi32>) -> tensor<1x1024x15x20xi32> loc(#loc125)
    %1866 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc877)
    %1867 = "ttir.exp"(%1861, %1866) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc877)
    %1868 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc878)
    %1869 = "ttir.add"(%1867, %arg244, %1868) : (tensor<1x1024x15x20xbf16>, tensor<1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc878)
    %1870 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc879)
    %1871 = "ttir.log"(%1869, %1870) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc879)
    %1872 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc880)
    %1873 = "ttir.where"(%1865, %1861, %1871, %1872) : (tensor<1x1024x15x20xi32>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc880)
    %1874 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc881)
    %1875 = "ttir.tanh"(%1873, %1874) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc881)
    %1876 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc882)
    %1877 = "ttir.multiply"(%1861, %1875, %1876) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc882)
    %1878 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc883)
    %1879 = "ttir.transpose"(%1877, %1878) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc883)
    %1880 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc884)
    %1881 = "ttir.transpose"(%1879, %1880) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc884)
    %1882 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc885)
    %1883 = "ttir.conv2d"(%1881, %arg421, %1882) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc885)
    %1884 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc886)
    %1885 = "ttir.transpose"(%1883, %1884) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc886)
    %1886 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc887)
    %1887 = "ttir.transpose"(%1885, %1886) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc887)
    %1888 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc126)
    %1889 = "ttir.multiply"(%1887, %arg245, %1888) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc126)
    %1890 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc419)
    %1891 = "ttir.add"(%1889, %arg246, %1890) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc419)
    %1892 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc420)
    %1893 = "ttir.gt"(%1891, %arg247, %1892) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc420)
    %1894 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc127)
    %1895 = "ttir.typecast"(%1893, %1894) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc127)
    %1896 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc421)
    %1897 = "ttir.exp"(%1891, %1896) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc421)
    %1898 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc422)
    %1899 = "ttir.add"(%1897, %arg248, %1898) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc422)
    %1900 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc423)
    %1901 = "ttir.log"(%1899, %1900) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc423)
    %1902 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc424)
    %1903 = "ttir.where"(%1895, %1891, %1901, %1902) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc424)
    %1904 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc425)
    %1905 = "ttir.tanh"(%1903, %1904) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc425)
    %1906 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc426)
    %1907 = "ttir.multiply"(%1891, %1905, %1906) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc426)
    %1908 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1468)
    %1909 = "ttir.transpose"(%1907, %1908) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1468)
    %1910 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1469)
    %1911 = "ttir.transpose"(%1909, %1910) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1469)
    %1912 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1470)
    %1913 = "ttir.conv2d"(%1911, %arg422, %1912) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1470)
    %1914 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1471)
    %1915 = "ttir.transpose"(%1913, %1914) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1471)
    %1916 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1472)
    %1917 = "ttir.transpose"(%1915, %1916) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1472)
    %1918 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc128)
    %1919 = "ttir.multiply"(%1917, %arg249, %1918) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc128)
    %1920 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1473)
    %1921 = "ttir.add"(%1919, %arg250, %1920) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1473)
    %1922 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1474)
    %1923 = "ttir.gt"(%1921, %arg251, %1922) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1474)
    %1924 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc129)
    %1925 = "ttir.typecast"(%1923, %1924) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc129)
    %1926 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1475)
    %1927 = "ttir.exp"(%1921, %1926) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1475)
    %1928 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1476)
    %1929 = "ttir.add"(%1927, %arg252, %1928) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1476)
    %1930 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1477)
    %1931 = "ttir.log"(%1929, %1930) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1477)
    %1932 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1478)
    %1933 = "ttir.where"(%1925, %1921, %1931, %1932) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1478)
    %1934 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1479)
    %1935 = "ttir.tanh"(%1933, %1934) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1479)
    %1936 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1480)
    %1937 = "ttir.multiply"(%1921, %1935, %1936) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1480)
    %1938 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1481)
    %1939 = "ttir.transpose"(%1937, %1938) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1481)
    %1940 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1482)
    %1941 = "ttir.transpose"(%1939, %1940) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1482)
    %1942 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1483)
    %1943 = "ttir.conv2d"(%1941, %arg423, %1942) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x3x3xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1483)
    %1944 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1484)
    %1945 = "ttir.transpose"(%1943, %1944) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1484)
    %1946 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1485)
    %1947 = "ttir.transpose"(%1945, %1946) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1485)
    %1948 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc130)
    %1949 = "ttir.multiply"(%1947, %arg253, %1948) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc130)
    %1950 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc891)
    %1951 = "ttir.add"(%1949, %arg254, %1950) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc891)
    %1952 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc892)
    %1953 = "ttir.gt"(%1951, %arg255, %1952) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc892)
    %1954 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc131)
    %1955 = "ttir.typecast"(%1953, %1954) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc131)
    %1956 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc893)
    %1957 = "ttir.exp"(%1951, %1956) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc893)
    %1958 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc894)
    %1959 = "ttir.add"(%1957, %arg256, %1958) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc894)
    %1960 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc895)
    %1961 = "ttir.log"(%1959, %1960) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc895)
    %1962 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc896)
    %1963 = "ttir.where"(%1955, %1951, %1961, %1962) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc896)
    %1964 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc897)
    %1965 = "ttir.tanh"(%1963, %1964) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc897)
    %1966 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc898)
    %1967 = "ttir.multiply"(%1951, %1965, %1966) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc898)
    %1968 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc899)
    %1969 = "ttir.add"(%1907, %1967, %1968) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc899)
    %1970 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1486)
    %1971 = "ttir.transpose"(%1969, %1970) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1486)
    %1972 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1487)
    %1973 = "ttir.transpose"(%1971, %1972) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1487)
    %1974 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1488)
    %1975 = "ttir.conv2d"(%1973, %arg424, %1974) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1488)
    %1976 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1489)
    %1977 = "ttir.transpose"(%1975, %1976) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1489)
    %1978 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1490)
    %1979 = "ttir.transpose"(%1977, %1978) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1490)
    %1980 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc132)
    %1981 = "ttir.multiply"(%1979, %arg257, %1980) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc132)
    %1982 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1491)
    %1983 = "ttir.add"(%1981, %arg258, %1982) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1491)
    %1984 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1492)
    %1985 = "ttir.gt"(%1983, %arg259, %1984) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1492)
    %1986 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc133)
    %1987 = "ttir.typecast"(%1985, %1986) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc133)
    %1988 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1493)
    %1989 = "ttir.exp"(%1983, %1988) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1493)
    %1990 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1494)
    %1991 = "ttir.add"(%1989, %arg260, %1990) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1494)
    %1992 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1495)
    %1993 = "ttir.log"(%1991, %1992) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1495)
    %1994 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1496)
    %1995 = "ttir.where"(%1987, %1983, %1993, %1994) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1496)
    %1996 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1497)
    %1997 = "ttir.tanh"(%1995, %1996) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1497)
    %1998 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1498)
    %1999 = "ttir.multiply"(%1983, %1997, %1998) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1498)
    %2000 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1499)
    %2001 = "ttir.transpose"(%1999, %2000) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1499)
    %2002 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1500)
    %2003 = "ttir.transpose"(%2001, %2002) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1500)
    %2004 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1501)
    %2005 = "ttir.conv2d"(%2003, %arg425, %2004) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x3x3xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1501)
    %2006 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1502)
    %2007 = "ttir.transpose"(%2005, %2006) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1502)
    %2008 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1503)
    %2009 = "ttir.transpose"(%2007, %2008) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1503)
    %2010 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc134)
    %2011 = "ttir.multiply"(%2009, %arg261, %2010) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc134)
    %2012 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc900)
    %2013 = "ttir.add"(%2011, %arg262, %2012) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc900)
    %2014 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc901)
    %2015 = "ttir.gt"(%2013, %arg263, %2014) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc901)
    %2016 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc135)
    %2017 = "ttir.typecast"(%2015, %2016) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc135)
    %2018 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc902)
    %2019 = "ttir.exp"(%2013, %2018) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc902)
    %2020 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc903)
    %2021 = "ttir.add"(%2019, %arg264, %2020) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc903)
    %2022 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc904)
    %2023 = "ttir.log"(%2021, %2022) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc904)
    %2024 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc905)
    %2025 = "ttir.where"(%2017, %2013, %2023, %2024) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc905)
    %2026 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc906)
    %2027 = "ttir.tanh"(%2025, %2026) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc906)
    %2028 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc907)
    %2029 = "ttir.multiply"(%2013, %2027, %2028) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc907)
    %2030 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc908)
    %2031 = "ttir.add"(%1969, %2029, %2030) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc908)
    %2032 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1504)
    %2033 = "ttir.transpose"(%2031, %2032) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1504)
    %2034 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1505)
    %2035 = "ttir.transpose"(%2033, %2034) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1505)
    %2036 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1506)
    %2037 = "ttir.conv2d"(%2035, %arg426, %2036) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1506)
    %2038 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1507)
    %2039 = "ttir.transpose"(%2037, %2038) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1507)
    %2040 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1508)
    %2041 = "ttir.transpose"(%2039, %2040) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1508)
    %2042 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc136)
    %2043 = "ttir.multiply"(%2041, %arg265, %2042) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc136)
    %2044 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1509)
    %2045 = "ttir.add"(%2043, %arg266, %2044) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1509)
    %2046 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1510)
    %2047 = "ttir.gt"(%2045, %arg267, %2046) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1510)
    %2048 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc137)
    %2049 = "ttir.typecast"(%2047, %2048) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc137)
    %2050 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1511)
    %2051 = "ttir.exp"(%2045, %2050) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1511)
    %2052 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1512)
    %2053 = "ttir.add"(%2051, %arg268, %2052) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1512)
    %2054 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1513)
    %2055 = "ttir.log"(%2053, %2054) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1513)
    %2056 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1514)
    %2057 = "ttir.where"(%2049, %2045, %2055, %2056) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1514)
    %2058 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1515)
    %2059 = "ttir.tanh"(%2057, %2058) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1515)
    %2060 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1516)
    %2061 = "ttir.multiply"(%2045, %2059, %2060) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1516)
    %2062 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1517)
    %2063 = "ttir.transpose"(%2061, %2062) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1517)
    %2064 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1518)
    %2065 = "ttir.transpose"(%2063, %2064) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1518)
    %2066 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1519)
    %2067 = "ttir.conv2d"(%2065, %arg427, %2066) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x3x3xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1519)
    %2068 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1520)
    %2069 = "ttir.transpose"(%2067, %2068) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1520)
    %2070 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1521)
    %2071 = "ttir.transpose"(%2069, %2070) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1521)
    %2072 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc138)
    %2073 = "ttir.multiply"(%2071, %arg269, %2072) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc138)
    %2074 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc909)
    %2075 = "ttir.add"(%2073, %arg270, %2074) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc909)
    %2076 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc910)
    %2077 = "ttir.gt"(%2075, %arg271, %2076) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc910)
    %2078 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc139)
    %2079 = "ttir.typecast"(%2077, %2078) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc139)
    %2080 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc911)
    %2081 = "ttir.exp"(%2075, %2080) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc911)
    %2082 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc912)
    %2083 = "ttir.add"(%2081, %arg272, %2082) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc912)
    %2084 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc913)
    %2085 = "ttir.log"(%2083, %2084) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc913)
    %2086 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc914)
    %2087 = "ttir.where"(%2079, %2075, %2085, %2086) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc914)
    %2088 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc915)
    %2089 = "ttir.tanh"(%2087, %2088) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc915)
    %2090 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc916)
    %2091 = "ttir.multiply"(%2075, %2089, %2090) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc916)
    %2092 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc917)
    %2093 = "ttir.add"(%2031, %2091, %2092) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc917)
    %2094 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1522)
    %2095 = "ttir.transpose"(%2093, %2094) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1522)
    %2096 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1523)
    %2097 = "ttir.transpose"(%2095, %2096) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1523)
    %2098 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1524)
    %2099 = "ttir.conv2d"(%2097, %arg428, %2098) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1524)
    %2100 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1525)
    %2101 = "ttir.transpose"(%2099, %2100) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1525)
    %2102 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1526)
    %2103 = "ttir.transpose"(%2101, %2102) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1526)
    %2104 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc140)
    %2105 = "ttir.multiply"(%2103, %arg273, %2104) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc140)
    %2106 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1527)
    %2107 = "ttir.add"(%2105, %arg274, %2106) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1527)
    %2108 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1528)
    %2109 = "ttir.gt"(%2107, %arg275, %2108) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1528)
    %2110 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc141)
    %2111 = "ttir.typecast"(%2109, %2110) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc141)
    %2112 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1529)
    %2113 = "ttir.exp"(%2107, %2112) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1529)
    %2114 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1530)
    %2115 = "ttir.add"(%2113, %arg276, %2114) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1530)
    %2116 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1531)
    %2117 = "ttir.log"(%2115, %2116) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1531)
    %2118 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1532)
    %2119 = "ttir.where"(%2111, %2107, %2117, %2118) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1532)
    %2120 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1533)
    %2121 = "ttir.tanh"(%2119, %2120) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1533)
    %2122 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1534)
    %2123 = "ttir.multiply"(%2107, %2121, %2122) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1534)
    %2124 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1535)
    %2125 = "ttir.transpose"(%2123, %2124) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1535)
    %2126 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1536)
    %2127 = "ttir.transpose"(%2125, %2126) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1536)
    %2128 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1537)
    %2129 = "ttir.conv2d"(%2127, %arg429, %2128) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x3x3xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1537)
    %2130 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1538)
    %2131 = "ttir.transpose"(%2129, %2130) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1538)
    %2132 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1539)
    %2133 = "ttir.transpose"(%2131, %2132) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1539)
    %2134 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc142)
    %2135 = "ttir.multiply"(%2133, %arg277, %2134) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc142)
    %2136 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc918)
    %2137 = "ttir.add"(%2135, %arg278, %2136) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc918)
    %2138 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc919)
    %2139 = "ttir.gt"(%2137, %arg279, %2138) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc919)
    %2140 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc143)
    %2141 = "ttir.typecast"(%2139, %2140) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc143)
    %2142 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc920)
    %2143 = "ttir.exp"(%2137, %2142) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc920)
    %2144 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc921)
    %2145 = "ttir.add"(%2143, %arg280, %2144) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc921)
    %2146 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc922)
    %2147 = "ttir.log"(%2145, %2146) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc922)
    %2148 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc923)
    %2149 = "ttir.where"(%2141, %2137, %2147, %2148) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc923)
    %2150 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc924)
    %2151 = "ttir.tanh"(%2149, %2150) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc924)
    %2152 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc925)
    %2153 = "ttir.multiply"(%2137, %2151, %2152) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc925)
    %2154 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc926)
    %2155 = "ttir.add"(%2093, %2153, %2154) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc926)
    %2156 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc927)
    %2157 = "ttir.transpose"(%2155, %2156) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc927)
    %2158 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc928)
    %2159 = "ttir.transpose"(%2157, %2158) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc928)
    %2160 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc929)
    %2161 = "ttir.conv2d"(%2159, %arg430, %2160) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc929)
    %2162 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc930)
    %2163 = "ttir.transpose"(%2161, %2162) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc930)
    %2164 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc931)
    %2165 = "ttir.transpose"(%2163, %2164) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc931)
    %2166 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc144)
    %2167 = "ttir.multiply"(%2165, %arg281, %2166) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc144)
    %2168 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc429)
    %2169 = "ttir.add"(%2167, %arg282, %2168) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc429)
    %2170 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc430)
    %2171 = "ttir.gt"(%2169, %arg283, %2170) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc430)
    %2172 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc145)
    %2173 = "ttir.typecast"(%2171, %2172) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc145)
    %2174 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc431)
    %2175 = "ttir.exp"(%2169, %2174) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc431)
    %2176 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc432)
    %2177 = "ttir.add"(%2175, %arg284, %2176) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc432)
    %2178 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc433)
    %2179 = "ttir.log"(%2177, %2178) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc433)
    %2180 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc434)
    %2181 = "ttir.where"(%2173, %2169, %2179, %2180) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc434)
    %2182 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc435)
    %2183 = "ttir.tanh"(%2181, %2182) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc435)
    %2184 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc436)
    %2185 = "ttir.multiply"(%2169, %2183, %2184) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc436)
    %2186 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc932)
    %2187 = "ttir.transpose"(%1877, %2186) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc932)
    %2188 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc933)
    %2189 = "ttir.transpose"(%2187, %2188) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc933)
    %2190 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc934)
    %2191 = "ttir.conv2d"(%2189, %arg431, %2190) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc934)
    %2192 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc935)
    %2193 = "ttir.transpose"(%2191, %2192) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc935)
    %2194 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc936)
    %2195 = "ttir.transpose"(%2193, %2194) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc936)
    %2196 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc146)
    %2197 = "ttir.multiply"(%2195, %arg285, %2196) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc146)
    %2198 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc438)
    %2199 = "ttir.add"(%2197, %arg286, %2198) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc438)
    %2200 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc439)
    %2201 = "ttir.gt"(%2199, %arg287, %2200) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc439)
    %2202 = ttir.empty() : tensor<1x512x15x20xi32> loc(#loc147)
    %2203 = "ttir.typecast"(%2201, %2202) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xi32>) -> tensor<1x512x15x20xi32> loc(#loc147)
    %2204 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc440)
    %2205 = "ttir.exp"(%2199, %2204) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc440)
    %2206 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc441)
    %2207 = "ttir.add"(%2205, %arg288, %2206) : (tensor<1x512x15x20xbf16>, tensor<1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc441)
    %2208 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc442)
    %2209 = "ttir.log"(%2207, %2208) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc442)
    %2210 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc443)
    %2211 = "ttir.where"(%2203, %2199, %2209, %2210) : (tensor<1x512x15x20xi32>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc443)
    %2212 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc444)
    %2213 = "ttir.tanh"(%2211, %2212) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc444)
    %2214 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc445)
    %2215 = "ttir.multiply"(%2199, %2213, %2214) : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc445)
    %2216 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc446)
    %2217 = "ttir.concat"(%2185, %2215, %2216) <{dim = -3 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc446)
    %2218 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc937)
    %2219 = "ttir.transpose"(%2217, %2218) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc937)
    %2220 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc938)
    %2221 = "ttir.transpose"(%2219, %2220) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc938)
    %2222 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc939)
    %2223 = "ttir.conv2d"(%2221, %arg432, %2222) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<1024x1024x1x1xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc939)
    %2224 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc940)
    %2225 = "ttir.transpose"(%2223, %2224) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc940)
    %2226 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc941)
    %2227 = "ttir.transpose"(%2225, %2226) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc941)
    %2228 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc148)
    %2229 = "ttir.multiply"(%2227, %arg289, %2228) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc148)
    %2230 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc448)
    %2231 = "ttir.add"(%2229, %arg290, %2230) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc448)
    %2232 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc449)
    %2233 = "ttir.gt"(%2231, %arg291, %2232) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc449)
    %2234 = ttir.empty() : tensor<1x1024x15x20xi32> loc(#loc149)
    %2235 = "ttir.typecast"(%2233, %2234) <{conservative_folding = false}> {dtype = "Int32"} : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xi32>) -> tensor<1x1024x15x20xi32> loc(#loc149)
    %2236 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc450)
    %2237 = "ttir.exp"(%2231, %2236) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc450)
    %2238 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc451)
    %2239 = "ttir.add"(%2237, %arg292, %2238) : (tensor<1x1024x15x20xbf16>, tensor<1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc451)
    %2240 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc452)
    %2241 = "ttir.log"(%2239, %2240) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc452)
    %2242 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc453)
    %2243 = "ttir.where"(%2235, %2231, %2241, %2242) : (tensor<1x1024x15x20xi32>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc453)
    %2244 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc454)
    %2245 = "ttir.tanh"(%2243, %2244) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc454)
    %2246 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc455)
    %2247 = "ttir.multiply"(%2231, %2245, %2246) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc455)
    %2248 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc942)
    %2249 = "ttir.transpose"(%2247, %2248) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc942)
    %2250 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc943)
    %2251 = "ttir.transpose"(%2249, %2250) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc943)
    %2252 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc944)
    %2253 = "ttir.conv2d"(%2251, %arg433, %2252) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc944)
    %2254 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc945)
    %2255 = "ttir.transpose"(%2253, %2254) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc945)
    %2256 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc946)
    %2257 = "ttir.transpose"(%2255, %2256) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc946)
    %2258 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc150)
    %2259 = "ttir.multiply"(%2257, %arg293, %2258) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc150)
    %2260 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc151)
    %2261 = "ttir.add"(%2259, %arg294, %2260) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc151)
    %2262 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc947)
    %2263 = "ttir.leaky_relu"(%2261, %2262) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc947)
    %2264 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc948)
    %2265 = "ttir.transpose"(%2263, %2264) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc948)
    %2266 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc949)
    %2267 = "ttir.transpose"(%2265, %2266) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc949)
    %2268 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc950)
    %2269 = "ttir.conv2d"(%2267, %arg434, %2268) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc950)
    %2270 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc951)
    %2271 = "ttir.transpose"(%2269, %2270) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc951)
    %2272 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc952)
    %2273 = "ttir.transpose"(%2271, %2272) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc952)
    %2274 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc152)
    %2275 = "ttir.multiply"(%2273, %arg295, %2274) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc152)
    %2276 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc153)
    %2277 = "ttir.add"(%2275, %arg296, %2276) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc153)
    %2278 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc459)
    %2279 = "ttir.leaky_relu"(%2277, %2278) <{parameter = 1.000000e-01 : f32}> : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc459)
    %2280 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc953)
    %2281 = "ttir.transpose"(%2279, %2280) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc953)
    %2282 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc954)
    %2283 = "ttir.transpose"(%2281, %2282) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc954)
    %2284 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc955)
    %2285 = "ttir.conv2d"(%2283, %arg435, %2284) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc955)
    %2286 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc956)
    %2287 = "ttir.transpose"(%2285, %2286) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc956)
    %2288 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc957)
    %2289 = "ttir.transpose"(%2287, %2288) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc957)
    %2290 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc154)
    %2291 = "ttir.multiply"(%2289, %arg297, %2290) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc154)
    %2292 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc155)
    %2293 = "ttir.add"(%2291, %arg298, %2292) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc155)
    %2294 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc461)
    %2295 = "ttir.leaky_relu"(%2293, %2294) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc461)
    %2296 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc958)
    %2297 = "ttir.transpose"(%2295, %2296) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc958)
    %2298 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc959)
    %2299 = "ttir.transpose"(%2297, %2298) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc959)
    %2300 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc960)
    %2301 = "ttir.max_pool2d"(%2299, %2300) <{ceil_mode = false, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 13 : si32, kernel_width = 13 : si32, padding_bottom = 6 : si32, padding_left = 6 : si32, padding_right = 6 : si32, padding_top = 6 : si32, stride_height = 1 : si32, stride_width = 1 : si32}> {channel_last = true} : (tensor<1x15x20x512xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc960)
    %2302 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc961)
    %2303 = "ttir.transpose"(%2301, %2302) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc961)
    %2304 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc962)
    %2305 = "ttir.transpose"(%2303, %2304) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc962)
    %2306 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc963)
    %2307 = "ttir.transpose"(%2295, %2306) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc963)
    %2308 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc964)
    %2309 = "ttir.transpose"(%2307, %2308) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc964)
    %2310 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc965)
    %2311 = "ttir.max_pool2d"(%2309, %2310) <{ceil_mode = false, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 9 : si32, kernel_width = 9 : si32, padding_bottom = 4 : si32, padding_left = 4 : si32, padding_right = 4 : si32, padding_top = 4 : si32, stride_height = 1 : si32, stride_width = 1 : si32}> {channel_last = true} : (tensor<1x15x20x512xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc965)
    %2312 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc966)
    %2313 = "ttir.transpose"(%2311, %2312) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc966)
    %2314 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc967)
    %2315 = "ttir.transpose"(%2313, %2314) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc967)
    %2316 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc968)
    %2317 = "ttir.transpose"(%2295, %2316) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc968)
    %2318 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc969)
    %2319 = "ttir.transpose"(%2317, %2318) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc969)
    %2320 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc970)
    %2321 = "ttir.max_pool2d"(%2319, %2320) <{ceil_mode = false, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 5 : si32, kernel_width = 5 : si32, padding_bottom = 2 : si32, padding_left = 2 : si32, padding_right = 2 : si32, padding_top = 2 : si32, stride_height = 1 : si32, stride_width = 1 : si32}> {channel_last = true} : (tensor<1x15x20x512xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc970)
    %2322 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc971)
    %2323 = "ttir.transpose"(%2321, %2322) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc971)
    %2324 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc972)
    %2325 = "ttir.transpose"(%2323, %2324) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc972)
    %2326 = ttir.empty() : tensor<1x2048x15x20xbf16> loc(#loc465)
    %2327 = "ttir.concat"(%2305, %2315, %2325, %2295, %2326) <{dim = -3 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x2048x15x20xbf16>) -> tensor<1x2048x15x20xbf16> loc(#loc465)
    %2328 = ttir.empty() : tensor<1x15x2048x20xbf16> loc(#loc973)
    %2329 = "ttir.transpose"(%2327, %2328) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x2048x15x20xbf16>, tensor<1x15x2048x20xbf16>) -> tensor<1x15x2048x20xbf16> loc(#loc973)
    %2330 = ttir.empty() : tensor<1x15x20x2048xbf16> loc(#loc974)
    %2331 = "ttir.transpose"(%2329, %2330) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x2048x20xbf16>, tensor<1x15x20x2048xbf16>) -> tensor<1x15x20x2048xbf16> loc(#loc974)
    %2332 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc975)
    %2333 = "ttir.conv2d"(%2331, %arg436, %2332) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x2048xbf16>, tensor<512x2048x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc975)
    %2334 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc976)
    %2335 = "ttir.transpose"(%2333, %2334) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc976)
    %2336 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc977)
    %2337 = "ttir.transpose"(%2335, %2336) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc977)
    %2338 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc156)
    %2339 = "ttir.multiply"(%2337, %arg299, %2338) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc156)
    %2340 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc157)
    %2341 = "ttir.add"(%2339, %arg300, %2340) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc157)
    %2342 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc467)
    %2343 = "ttir.leaky_relu"(%2341, %2342) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc467)
    %2344 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc978)
    %2345 = "ttir.transpose"(%2343, %2344) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc978)
    %2346 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc979)
    %2347 = "ttir.transpose"(%2345, %2346) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc979)
    %2348 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc980)
    %2349 = "ttir.conv2d"(%2347, %arg437, %2348) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc980)
    %2350 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc981)
    %2351 = "ttir.transpose"(%2349, %2350) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc981)
    %2352 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc982)
    %2353 = "ttir.transpose"(%2351, %2352) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc982)
    %2354 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc158)
    %2355 = "ttir.multiply"(%2353, %arg301, %2354) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc158)
    %2356 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc159)
    %2357 = "ttir.add"(%2355, %arg302, %2356) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc159)
    %2358 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc469)
    %2359 = "ttir.leaky_relu"(%2357, %2358) <{parameter = 1.000000e-01 : f32}> : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc469)
    %2360 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc983)
    %2361 = "ttir.transpose"(%2359, %2360) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc983)
    %2362 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc984)
    %2363 = "ttir.transpose"(%2361, %2362) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc984)
    %2364 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc985)
    %2365 = "ttir.conv2d"(%2363, %arg438, %2364) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc985)
    %2366 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc986)
    %2367 = "ttir.transpose"(%2365, %2366) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc986)
    %2368 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc987)
    %2369 = "ttir.transpose"(%2367, %2368) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc987)
    %2370 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc160)
    %2371 = "ttir.multiply"(%2369, %arg303, %2370) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc160)
    %2372 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc161)
    %2373 = "ttir.add"(%2371, %arg304, %2372) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc161)
    %2374 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc471)
    %2375 = "ttir.leaky_relu"(%2373, %2374) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc471)
    %2376 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc988)
    %2377 = "ttir.transpose"(%2375, %2376) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc988)
    %2378 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc989)
    %2379 = "ttir.transpose"(%2377, %2378) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc989)
    %2380 = ttir.empty() : tensor<1x15x20x256xbf16> loc(#loc990)
    %2381 = "ttir.conv2d"(%2379, %arg439, %2380) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x15x20x256xbf16>) -> tensor<1x15x20x256xbf16> loc(#loc990)
    %2382 = ttir.empty() : tensor<1x15x256x20xbf16> loc(#loc991)
    %2383 = "ttir.transpose"(%2381, %2382) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x256xbf16>, tensor<1x15x256x20xbf16>) -> tensor<1x15x256x20xbf16> loc(#loc991)
    %2384 = ttir.empty() : tensor<1x256x15x20xbf16> loc(#loc992)
    %2385 = "ttir.transpose"(%2383, %2384) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x256x20xbf16>, tensor<1x256x15x20xbf16>) -> tensor<1x256x15x20xbf16> loc(#loc992)
    %2386 = ttir.empty() : tensor<1x256x15x20xbf16> loc(#loc162)
    %2387 = "ttir.multiply"(%2385, %arg305, %2386) : (tensor<1x256x15x20xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x15x20xbf16>) -> tensor<1x256x15x20xbf16> loc(#loc162)
    %2388 = ttir.empty() : tensor<1x256x15x20xbf16> loc(#loc163)
    %2389 = "ttir.add"(%2387, %arg306, %2388) : (tensor<1x256x15x20xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x15x20xbf16>) -> tensor<1x256x15x20xbf16> loc(#loc163)
    %2390 = ttir.empty() : tensor<1x256x15x20xbf16> loc(#loc473)
    %2391 = "ttir.leaky_relu"(%2389, %2390) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x15x20xbf16>, tensor<1x256x15x20xbf16>) -> tensor<1x256x15x20xbf16> loc(#loc473)
    %2392 = ttir.empty() : tensor<1x15x256x20xbf16> loc(#loc993)
    %2393 = "ttir.transpose"(%2391, %2392) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x15x20xbf16>, tensor<1x15x256x20xbf16>) -> tensor<1x15x256x20xbf16> loc(#loc993)
    %2394 = ttir.empty() : tensor<1x15x20x256xbf16> loc(#loc994)
    %2395 = "ttir.transpose"(%2393, %2394) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x256x20xbf16>, tensor<1x15x20x256xbf16>) -> tensor<1x15x20x256xbf16> loc(#loc994)
    %2396 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc995)
    %2397 = "ttir.upsample2d"(%2395, %2396) <{mode = "nearest", scale_factor = 2 : si32}> {channel_last = true} : (tensor<1x15x20x256xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc995)
    %2398 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc996)
    %2399 = "ttir.transpose"(%2397, %2398) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc996)
    %2400 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc997)
    %2401 = "ttir.transpose"(%2399, %2400) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc997)
    %2402 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc475)
    %2403 = "ttir.concat"(%1847, %2401, %2402) <{dim = -3 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc475)
    %2404 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc998)
    %2405 = "ttir.transpose"(%2403, %2404) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc998)
    %2406 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc999)
    %2407 = "ttir.transpose"(%2405, %2406) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc999)
    %2408 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1000)
    %2409 = "ttir.conv2d"(%2407, %arg440, %2408) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1000)
    %2410 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1001)
    %2411 = "ttir.transpose"(%2409, %2410) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1001)
    %2412 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1002)
    %2413 = "ttir.transpose"(%2411, %2412) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1002)
    %2414 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc164)
    %2415 = "ttir.multiply"(%2413, %arg307, %2414) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc164)
    %2416 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc165)
    %2417 = "ttir.add"(%2415, %arg308, %2416) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc165)
    %2418 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc477)
    %2419 = "ttir.leaky_relu"(%2417, %2418) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc477)
    %2420 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1003)
    %2421 = "ttir.transpose"(%2419, %2420) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1003)
    %2422 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1004)
    %2423 = "ttir.transpose"(%2421, %2422) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1004)
    %2424 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1005)
    %2425 = "ttir.conv2d"(%2423, %arg441, %2424) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1005)
    %2426 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1006)
    %2427 = "ttir.transpose"(%2425, %2426) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1006)
    %2428 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc1007)
    %2429 = "ttir.transpose"(%2427, %2428) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc1007)
    %2430 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc166)
    %2431 = "ttir.multiply"(%2429, %arg309, %2430) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc166)
    %2432 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc167)
    %2433 = "ttir.add"(%2431, %arg310, %2432) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc167)
    %2434 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc479)
    %2435 = "ttir.leaky_relu"(%2433, %2434) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc479)
    %2436 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1008)
    %2437 = "ttir.transpose"(%2435, %2436) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1008)
    %2438 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1009)
    %2439 = "ttir.transpose"(%2437, %2438) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1009)
    %2440 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1010)
    %2441 = "ttir.conv2d"(%2439, %arg442, %2440) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1010)
    %2442 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1011)
    %2443 = "ttir.transpose"(%2441, %2442) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1011)
    %2444 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1012)
    %2445 = "ttir.transpose"(%2443, %2444) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1012)
    %2446 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc168)
    %2447 = "ttir.multiply"(%2445, %arg311, %2446) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc168)
    %2448 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc169)
    %2449 = "ttir.add"(%2447, %arg312, %2448) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc169)
    %2450 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc481)
    %2451 = "ttir.leaky_relu"(%2449, %2450) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc481)
    %2452 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1013)
    %2453 = "ttir.transpose"(%2451, %2452) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1013)
    %2454 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1014)
    %2455 = "ttir.transpose"(%2453, %2454) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1014)
    %2456 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1015)
    %2457 = "ttir.conv2d"(%2455, %arg443, %2456) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1015)
    %2458 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1016)
    %2459 = "ttir.transpose"(%2457, %2458) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1016)
    %2460 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc1017)
    %2461 = "ttir.transpose"(%2459, %2460) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc1017)
    %2462 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc170)
    %2463 = "ttir.multiply"(%2461, %arg313, %2462) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc170)
    %2464 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc171)
    %2465 = "ttir.add"(%2463, %arg314, %2464) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc171)
    %2466 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc483)
    %2467 = "ttir.leaky_relu"(%2465, %2466) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc483)
    %2468 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1018)
    %2469 = "ttir.transpose"(%2467, %2468) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1018)
    %2470 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1019)
    %2471 = "ttir.transpose"(%2469, %2470) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1019)
    %2472 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1020)
    %2473 = "ttir.conv2d"(%2471, %arg444, %2472) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1020)
    %2474 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1021)
    %2475 = "ttir.transpose"(%2473, %2474) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1021)
    %2476 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1022)
    %2477 = "ttir.transpose"(%2475, %2476) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1022)
    %2478 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc172)
    %2479 = "ttir.multiply"(%2477, %arg315, %2478) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc172)
    %2480 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc173)
    %2481 = "ttir.add"(%2479, %arg316, %2480) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc173)
    %2482 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc485)
    %2483 = "ttir.leaky_relu"(%2481, %2482) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc485)
    %2484 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1023)
    %2485 = "ttir.transpose"(%2483, %2484) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1023)
    %2486 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1024)
    %2487 = "ttir.transpose"(%2485, %2486) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1024)
    %2488 = ttir.empty() : tensor<1x30x40x128xbf16> loc(#loc1025)
    %2489 = "ttir.conv2d"(%2487, %arg445, %2488) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x30x40x128xbf16>) -> tensor<1x30x40x128xbf16> loc(#loc1025)
    %2490 = ttir.empty() : tensor<1x30x128x40xbf16> loc(#loc1026)
    %2491 = "ttir.transpose"(%2489, %2490) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x128xbf16>, tensor<1x30x128x40xbf16>) -> tensor<1x30x128x40xbf16> loc(#loc1026)
    %2492 = ttir.empty() : tensor<1x128x30x40xbf16> loc(#loc1027)
    %2493 = "ttir.transpose"(%2491, %2492) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x128x40xbf16>, tensor<1x128x30x40xbf16>) -> tensor<1x128x30x40xbf16> loc(#loc1027)
    %2494 = ttir.empty() : tensor<1x128x30x40xbf16> loc(#loc174)
    %2495 = "ttir.multiply"(%2493, %arg317, %2494) : (tensor<1x128x30x40xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x30x40xbf16>) -> tensor<1x128x30x40xbf16> loc(#loc174)
    %2496 = ttir.empty() : tensor<1x128x30x40xbf16> loc(#loc175)
    %2497 = "ttir.add"(%2495, %arg318, %2496) : (tensor<1x128x30x40xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x30x40xbf16>) -> tensor<1x128x30x40xbf16> loc(#loc175)
    %2498 = ttir.empty() : tensor<1x128x30x40xbf16> loc(#loc487)
    %2499 = "ttir.leaky_relu"(%2497, %2498) <{parameter = 1.000000e-01 : f32}> : (tensor<1x128x30x40xbf16>, tensor<1x128x30x40xbf16>) -> tensor<1x128x30x40xbf16> loc(#loc487)
    %2500 = ttir.empty() : tensor<1x30x128x40xbf16> loc(#loc488)
    %2501 = "ttir.transpose"(%2499, %2500) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x30x40xbf16>, tensor<1x30x128x40xbf16>) -> tensor<1x30x128x40xbf16> loc(#loc488)
    %2502 = ttir.empty() : tensor<1x30x40x128xbf16> loc(#loc489)
    %2503 = "ttir.transpose"(%2501, %2502) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x128x40xbf16>, tensor<1x30x40x128xbf16>) -> tensor<1x30x40x128xbf16> loc(#loc489)
    %2504 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc490)
    %2505 = "ttir.upsample2d"(%2503, %2504) <{mode = "nearest", scale_factor = 2 : si32}> {channel_last = true} : (tensor<1x30x40x128xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc490)
    %2506 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc491)
    %2507 = "ttir.transpose"(%2505, %2506) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc491)
    %2508 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc492)
    %2509 = "ttir.transpose"(%2507, %2508) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc492)
    %2510 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc493)
    %2511 = "ttir.concat"(%1183, %2509, %2510) <{dim = -3 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc493)
    %2512 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1028)
    %2513 = "ttir.transpose"(%2511, %2512) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1028)
    %2514 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1029)
    %2515 = "ttir.transpose"(%2513, %2514) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1029)
    %2516 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1030)
    %2517 = "ttir.conv2d"(%2515, %arg446, %2516) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1030)
    %2518 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1031)
    %2519 = "ttir.transpose"(%2517, %2518) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1031)
    %2520 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1032)
    %2521 = "ttir.transpose"(%2519, %2520) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1032)
    %2522 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc176)
    %2523 = "ttir.multiply"(%2521, %arg319, %2522) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc176)
    %2524 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc177)
    %2525 = "ttir.add"(%2523, %arg320, %2524) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc177)
    %2526 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc495)
    %2527 = "ttir.leaky_relu"(%2525, %2526) <{parameter = 1.000000e-01 : f32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc495)
    %2528 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1033)
    %2529 = "ttir.transpose"(%2527, %2528) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1033)
    %2530 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1034)
    %2531 = "ttir.transpose"(%2529, %2530) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1034)
    %2532 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1035)
    %2533 = "ttir.conv2d"(%2531, %arg447, %2532) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<256x128x3x3xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1035)
    %2534 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1036)
    %2535 = "ttir.transpose"(%2533, %2534) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x256xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1036)
    %2536 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc1037)
    %2537 = "ttir.transpose"(%2535, %2536) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc1037)
    %2538 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc178)
    %2539 = "ttir.multiply"(%2537, %arg321, %2538) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc178)
    %2540 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc179)
    %2541 = "ttir.add"(%2539, %arg322, %2540) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc179)
    %2542 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc497)
    %2543 = "ttir.leaky_relu"(%2541, %2542) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc497)
    %2544 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1038)
    %2545 = "ttir.transpose"(%2543, %2544) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1038)
    %2546 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1039)
    %2547 = "ttir.transpose"(%2545, %2546) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1039)
    %2548 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1040)
    %2549 = "ttir.conv2d"(%2547, %arg448, %2548) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1040)
    %2550 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1041)
    %2551 = "ttir.transpose"(%2549, %2550) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1041)
    %2552 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1042)
    %2553 = "ttir.transpose"(%2551, %2552) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1042)
    %2554 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc180)
    %2555 = "ttir.multiply"(%2553, %arg323, %2554) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc180)
    %2556 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc181)
    %2557 = "ttir.add"(%2555, %arg324, %2556) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc181)
    %2558 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc499)
    %2559 = "ttir.leaky_relu"(%2557, %2558) <{parameter = 1.000000e-01 : f32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc499)
    %2560 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1043)
    %2561 = "ttir.transpose"(%2559, %2560) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1043)
    %2562 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1044)
    %2563 = "ttir.transpose"(%2561, %2562) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1044)
    %2564 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1045)
    %2565 = "ttir.conv2d"(%2563, %arg449, %2564) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<256x128x3x3xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1045)
    %2566 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1046)
    %2567 = "ttir.transpose"(%2565, %2566) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x256xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1046)
    %2568 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc1047)
    %2569 = "ttir.transpose"(%2567, %2568) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc1047)
    %2570 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc182)
    %2571 = "ttir.multiply"(%2569, %arg325, %2570) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc182)
    %2572 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc183)
    %2573 = "ttir.add"(%2571, %arg326, %2572) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc183)
    %2574 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc501)
    %2575 = "ttir.leaky_relu"(%2573, %2574) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc501)
    %2576 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1048)
    %2577 = "ttir.transpose"(%2575, %2576) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1048)
    %2578 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1049)
    %2579 = "ttir.transpose"(%2577, %2578) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1049)
    %2580 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1050)
    %2581 = "ttir.conv2d"(%2579, %arg450, %2580) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<128x256x1x1xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1050)
    %2582 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1051)
    %2583 = "ttir.transpose"(%2581, %2582) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x128xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1051)
    %2584 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc1052)
    %2585 = "ttir.transpose"(%2583, %2584) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc1052)
    %2586 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc184)
    %2587 = "ttir.multiply"(%2585, %arg327, %2586) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc184)
    %2588 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc185)
    %2589 = "ttir.add"(%2587, %arg328, %2588) : (tensor<1x128x60x80xbf16>, tensor<1x128x1x1xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc185)
    %2590 = ttir.empty() : tensor<1x128x60x80xbf16> loc(#loc503)
    %2591 = "ttir.leaky_relu"(%2589, %2590) <{parameter = 1.000000e-01 : f32}> : (tensor<1x128x60x80xbf16>, tensor<1x128x60x80xbf16>) -> tensor<1x128x60x80xbf16> loc(#loc503)
    %2592 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1053)
    %2593 = "ttir.transpose"(%2591, %2592) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1053)
    %2594 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1054)
    %2595 = "ttir.transpose"(%2593, %2594) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1054)
    %2596 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1055)
    %2597 = "ttir.conv2d"(%2595, %arg451, %2596) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<256x128x3x3xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1055)
    %2598 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1056)
    %2599 = "ttir.transpose"(%2597, %2598) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x256xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1056)
    %2600 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc1057)
    %2601 = "ttir.transpose"(%2599, %2600) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc1057)
    %2602 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc186)
    %2603 = "ttir.multiply"(%2601, %arg329, %2602) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc186)
    %2604 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc187)
    %2605 = "ttir.add"(%2603, %arg330, %2604) : (tensor<1x256x60x80xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc187)
    %2606 = ttir.empty() : tensor<1x256x60x80xbf16> loc(#loc1058)
    %2607 = "ttir.leaky_relu"(%2605, %2606) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x60x80xbf16>, tensor<1x256x60x80xbf16>) -> tensor<1x256x60x80xbf16> loc(#loc1058)
    %2608 = ttir.empty() : tensor<1x60x256x80xbf16> loc(#loc1059)
    %2609 = "ttir.transpose"(%2607, %2608) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x60x80xbf16>, tensor<1x60x256x80xbf16>) -> tensor<1x60x256x80xbf16> loc(#loc1059)
    %2610 = ttir.empty() : tensor<1x60x80x256xbf16> loc(#loc1060)
    %2611 = "ttir.transpose"(%2609, %2610) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x256x80xbf16>, tensor<1x60x80x256xbf16>) -> tensor<1x60x80x256xbf16> loc(#loc1060)
    %2612 = ttir.empty() : tensor<1x60x80x255xbf16> loc(#loc1061)
    %2613 = "ttir.conv2d"(%2611, %arg452, %arg453, %2612) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x60x80x256xbf16>, tensor<255x256x1x1xbf16>, tensor<1x1x1x255xbf16>, tensor<1x60x80x255xbf16>) -> tensor<1x60x80x255xbf16> loc(#loc1061)
    %2614 = ttir.empty() : tensor<1x60x255x80xbf16> loc(#loc1062)
    %2615 = "ttir.transpose"(%2613, %2614) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x80x255xbf16>, tensor<1x60x255x80xbf16>) -> tensor<1x60x255x80xbf16> loc(#loc1062)
    %2616 = ttir.empty() : tensor<1x255x60x80xbf16> loc(#loc1063)
    %2617 = "ttir.transpose"(%2615, %2616) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x60x255x80xbf16>, tensor<1x255x60x80xbf16>) -> tensor<1x255x60x80xbf16> loc(#loc1063)
    %2618 = ttir.empty() : tensor<1x60x128x80xbf16> loc(#loc1064)
    %2619 = "ttir.transpose"(%2591, %2618) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x128x60x80xbf16>, tensor<1x60x128x80xbf16>) -> tensor<1x60x128x80xbf16> loc(#loc1064)
    %2620 = ttir.empty() : tensor<1x60x80x128xbf16> loc(#loc1065)
    %2621 = "ttir.transpose"(%2619, %2620) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x60x128x80xbf16>, tensor<1x60x80x128xbf16>) -> tensor<1x60x80x128xbf16> loc(#loc1065)
    %2622 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1066)
    %2623 = "ttir.conv2d"(%2621, %arg454, %2622) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x60x80x128xbf16>, tensor<256x128x3x3xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1066)
    %2624 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1067)
    %2625 = "ttir.transpose"(%2623, %2624) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1067)
    %2626 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1068)
    %2627 = "ttir.transpose"(%2625, %2626) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1068)
    %2628 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc188)
    %2629 = "ttir.multiply"(%2627, %arg331, %2628) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc188)
    %2630 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc189)
    %2631 = "ttir.add"(%2629, %arg332, %2630) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc189)
    %2632 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc508)
    %2633 = "ttir.leaky_relu"(%2631, %2632) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc508)
    %2634 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc509)
    %2635 = "ttir.concat"(%2633, %2483, %2634) <{dim = -3 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc509)
    %2636 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1069)
    %2637 = "ttir.transpose"(%2635, %2636) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1069)
    %2638 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1070)
    %2639 = "ttir.transpose"(%2637, %2638) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1070)
    %2640 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1071)
    %2641 = "ttir.conv2d"(%2639, %arg455, %2640) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1071)
    %2642 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1072)
    %2643 = "ttir.transpose"(%2641, %2642) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1072)
    %2644 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1073)
    %2645 = "ttir.transpose"(%2643, %2644) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1073)
    %2646 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc190)
    %2647 = "ttir.multiply"(%2645, %arg333, %2646) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc190)
    %2648 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc191)
    %2649 = "ttir.add"(%2647, %arg334, %2648) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc191)
    %2650 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc511)
    %2651 = "ttir.leaky_relu"(%2649, %2650) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc511)
    %2652 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1074)
    %2653 = "ttir.transpose"(%2651, %2652) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1074)
    %2654 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1075)
    %2655 = "ttir.transpose"(%2653, %2654) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1075)
    %2656 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1076)
    %2657 = "ttir.conv2d"(%2655, %arg456, %2656) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1076)
    %2658 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1077)
    %2659 = "ttir.transpose"(%2657, %2658) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1077)
    %2660 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc1078)
    %2661 = "ttir.transpose"(%2659, %2660) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc1078)
    %2662 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc192)
    %2663 = "ttir.multiply"(%2661, %arg335, %2662) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc192)
    %2664 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc193)
    %2665 = "ttir.add"(%2663, %arg336, %2664) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc193)
    %2666 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc513)
    %2667 = "ttir.leaky_relu"(%2665, %2666) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc513)
    %2668 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1079)
    %2669 = "ttir.transpose"(%2667, %2668) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1079)
    %2670 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1080)
    %2671 = "ttir.transpose"(%2669, %2670) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1080)
    %2672 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1081)
    %2673 = "ttir.conv2d"(%2671, %arg457, %2672) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1081)
    %2674 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1082)
    %2675 = "ttir.transpose"(%2673, %2674) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1082)
    %2676 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1083)
    %2677 = "ttir.transpose"(%2675, %2676) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1083)
    %2678 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc194)
    %2679 = "ttir.multiply"(%2677, %arg337, %2678) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc194)
    %2680 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc195)
    %2681 = "ttir.add"(%2679, %arg338, %2680) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc195)
    %2682 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc515)
    %2683 = "ttir.leaky_relu"(%2681, %2682) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc515)
    %2684 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1084)
    %2685 = "ttir.transpose"(%2683, %2684) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1084)
    %2686 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1085)
    %2687 = "ttir.transpose"(%2685, %2686) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1085)
    %2688 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1086)
    %2689 = "ttir.conv2d"(%2687, %arg458, %2688) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1086)
    %2690 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1087)
    %2691 = "ttir.transpose"(%2689, %2690) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1087)
    %2692 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc1088)
    %2693 = "ttir.transpose"(%2691, %2692) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc1088)
    %2694 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc196)
    %2695 = "ttir.multiply"(%2693, %arg339, %2694) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc196)
    %2696 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc197)
    %2697 = "ttir.add"(%2695, %arg340, %2696) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc197)
    %2698 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc517)
    %2699 = "ttir.leaky_relu"(%2697, %2698) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc517)
    %2700 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1089)
    %2701 = "ttir.transpose"(%2699, %2700) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1089)
    %2702 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1090)
    %2703 = "ttir.transpose"(%2701, %2702) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1090)
    %2704 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1091)
    %2705 = "ttir.conv2d"(%2703, %arg459, %2704) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<256x512x1x1xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1091)
    %2706 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1092)
    %2707 = "ttir.transpose"(%2705, %2706) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x256xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1092)
    %2708 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc1093)
    %2709 = "ttir.transpose"(%2707, %2708) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc1093)
    %2710 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc198)
    %2711 = "ttir.multiply"(%2709, %arg341, %2710) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc198)
    %2712 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc199)
    %2713 = "ttir.add"(%2711, %arg342, %2712) : (tensor<1x256x30x40xbf16>, tensor<1x256x1x1xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc199)
    %2714 = ttir.empty() : tensor<1x256x30x40xbf16> loc(#loc519)
    %2715 = "ttir.leaky_relu"(%2713, %2714) <{parameter = 1.000000e-01 : f32}> : (tensor<1x256x30x40xbf16>, tensor<1x256x30x40xbf16>) -> tensor<1x256x30x40xbf16> loc(#loc519)
    %2716 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1094)
    %2717 = "ttir.transpose"(%2715, %2716) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1094)
    %2718 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1095)
    %2719 = "ttir.transpose"(%2717, %2718) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1095)
    %2720 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1096)
    %2721 = "ttir.conv2d"(%2719, %arg460, %2720) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1096)
    %2722 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1097)
    %2723 = "ttir.transpose"(%2721, %2722) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x512xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1097)
    %2724 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc1098)
    %2725 = "ttir.transpose"(%2723, %2724) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc1098)
    %2726 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc200)
    %2727 = "ttir.multiply"(%2725, %arg343, %2726) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc200)
    %2728 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc201)
    %2729 = "ttir.add"(%2727, %arg344, %2728) : (tensor<1x512x30x40xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc201)
    %2730 = ttir.empty() : tensor<1x512x30x40xbf16> loc(#loc521)
    %2731 = "ttir.leaky_relu"(%2729, %2730) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x30x40xbf16>, tensor<1x512x30x40xbf16>) -> tensor<1x512x30x40xbf16> loc(#loc521)
    %2732 = ttir.empty() : tensor<1x30x512x40xbf16> loc(#loc1099)
    %2733 = "ttir.transpose"(%2731, %2732) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x30x40xbf16>, tensor<1x30x512x40xbf16>) -> tensor<1x30x512x40xbf16> loc(#loc1099)
    %2734 = ttir.empty() : tensor<1x30x40x512xbf16> loc(#loc1100)
    %2735 = "ttir.transpose"(%2733, %2734) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x512x40xbf16>, tensor<1x30x40x512xbf16>) -> tensor<1x30x40x512xbf16> loc(#loc1100)
    %2736 = ttir.empty() : tensor<1x30x40x255xbf16> loc(#loc1101)
    %2737 = "ttir.conv2d"(%2735, %arg461, %arg462, %2736) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x30x40x512xbf16>, tensor<255x512x1x1xbf16>, tensor<1x1x1x255xbf16>, tensor<1x30x40x255xbf16>) -> tensor<1x30x40x255xbf16> loc(#loc1101)
    %2738 = ttir.empty() : tensor<1x30x255x40xbf16> loc(#loc1102)
    %2739 = "ttir.transpose"(%2737, %2738) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x40x255xbf16>, tensor<1x30x255x40xbf16>) -> tensor<1x30x255x40xbf16> loc(#loc1102)
    %2740 = ttir.empty() : tensor<1x255x30x40xbf16> loc(#loc1103)
    %2741 = "ttir.transpose"(%2739, %2740) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x30x255x40xbf16>, tensor<1x255x30x40xbf16>) -> tensor<1x255x30x40xbf16> loc(#loc1103)
    %2742 = ttir.empty() : tensor<1x30x256x40xbf16> loc(#loc1104)
    %2743 = "ttir.transpose"(%2715, %2742) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x256x30x40xbf16>, tensor<1x30x256x40xbf16>) -> tensor<1x30x256x40xbf16> loc(#loc1104)
    %2744 = ttir.empty() : tensor<1x30x40x256xbf16> loc(#loc1105)
    %2745 = "ttir.transpose"(%2743, %2744) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x30x256x40xbf16>, tensor<1x30x40x256xbf16>) -> tensor<1x30x40x256xbf16> loc(#loc1105)
    %2746 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1106)
    %2747 = "ttir.conv2d"(%2745, %arg463, %2746) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<1x30x40x256xbf16>, tensor<512x256x3x3xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1106)
    %2748 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1107)
    %2749 = "ttir.transpose"(%2747, %2748) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1107)
    %2750 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1108)
    %2751 = "ttir.transpose"(%2749, %2750) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1108)
    %2752 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc202)
    %2753 = "ttir.multiply"(%2751, %arg345, %2752) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc202)
    %2754 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc203)
    %2755 = "ttir.add"(%2753, %arg346, %2754) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc203)
    %2756 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc524)
    %2757 = "ttir.leaky_relu"(%2755, %2756) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc524)
    %2758 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc525)
    %2759 = "ttir.concat"(%2757, %2375, %2758) <{dim = -3 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc525)
    %2760 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1109)
    %2761 = "ttir.transpose"(%2759, %2760) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1109)
    %2762 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1110)
    %2763 = "ttir.transpose"(%2761, %2762) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1110)
    %2764 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1111)
    %2765 = "ttir.conv2d"(%2763, %arg464, %2764) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1111)
    %2766 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1112)
    %2767 = "ttir.transpose"(%2765, %2766) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1112)
    %2768 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1113)
    %2769 = "ttir.transpose"(%2767, %2768) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1113)
    %2770 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc204)
    %2771 = "ttir.multiply"(%2769, %arg347, %2770) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc204)
    %2772 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc205)
    %2773 = "ttir.add"(%2771, %arg348, %2772) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc205)
    %2774 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc527)
    %2775 = "ttir.leaky_relu"(%2773, %2774) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc527)
    %2776 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1114)
    %2777 = "ttir.transpose"(%2775, %2776) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1114)
    %2778 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1115)
    %2779 = "ttir.transpose"(%2777, %2778) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1115)
    %2780 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1116)
    %2781 = "ttir.conv2d"(%2779, %arg465, %2780) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1116)
    %2782 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1117)
    %2783 = "ttir.transpose"(%2781, %2782) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1117)
    %2784 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc1118)
    %2785 = "ttir.transpose"(%2783, %2784) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc1118)
    %2786 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc206)
    %2787 = "ttir.multiply"(%2785, %arg349, %2786) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc206)
    %2788 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc207)
    %2789 = "ttir.add"(%2787, %arg350, %2788) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc207)
    %2790 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc529)
    %2791 = "ttir.leaky_relu"(%2789, %2790) <{parameter = 1.000000e-01 : f32}> : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc529)
    %2792 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1119)
    %2793 = "ttir.transpose"(%2791, %2792) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1119)
    %2794 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1120)
    %2795 = "ttir.transpose"(%2793, %2794) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1120)
    %2796 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1121)
    %2797 = "ttir.conv2d"(%2795, %arg466, %2796) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1121)
    %2798 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1122)
    %2799 = "ttir.transpose"(%2797, %2798) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1122)
    %2800 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1123)
    %2801 = "ttir.transpose"(%2799, %2800) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1123)
    %2802 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc208)
    %2803 = "ttir.multiply"(%2801, %arg351, %2802) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc208)
    %2804 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc209)
    %2805 = "ttir.add"(%2803, %arg352, %2804) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc209)
    %2806 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc531)
    %2807 = "ttir.leaky_relu"(%2805, %2806) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc531)
    %2808 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1124)
    %2809 = "ttir.transpose"(%2807, %2808) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1124)
    %2810 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1125)
    %2811 = "ttir.transpose"(%2809, %2810) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1125)
    %2812 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1126)
    %2813 = "ttir.conv2d"(%2811, %arg467, %2812) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1126)
    %2814 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1127)
    %2815 = "ttir.transpose"(%2813, %2814) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1127)
    %2816 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc1128)
    %2817 = "ttir.transpose"(%2815, %2816) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc1128)
    %2818 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc210)
    %2819 = "ttir.multiply"(%2817, %arg353, %2818) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc210)
    %2820 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc211)
    %2821 = "ttir.add"(%2819, %arg354, %2820) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc211)
    %2822 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc533)
    %2823 = "ttir.leaky_relu"(%2821, %2822) <{parameter = 1.000000e-01 : f32}> : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc533)
    %2824 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1129)
    %2825 = "ttir.transpose"(%2823, %2824) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1129)
    %2826 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1130)
    %2827 = "ttir.transpose"(%2825, %2826) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1130)
    %2828 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1131)
    %2829 = "ttir.conv2d"(%2827, %arg468, %2828) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<512x1024x1x1xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1131)
    %2830 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1132)
    %2831 = "ttir.transpose"(%2829, %2830) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x512xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1132)
    %2832 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc1133)
    %2833 = "ttir.transpose"(%2831, %2832) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc1133)
    %2834 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc212)
    %2835 = "ttir.multiply"(%2833, %arg355, %2834) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc212)
    %2836 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc213)
    %2837 = "ttir.add"(%2835, %arg356, %2836) : (tensor<1x512x15x20xbf16>, tensor<1x512x1x1xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc213)
    %2838 = ttir.empty() : tensor<1x512x15x20xbf16> loc(#loc535)
    %2839 = "ttir.leaky_relu"(%2837, %2838) <{parameter = 1.000000e-01 : f32}> : (tensor<1x512x15x20xbf16>, tensor<1x512x15x20xbf16>) -> tensor<1x512x15x20xbf16> loc(#loc535)
    %2840 = ttir.empty() : tensor<1x15x512x20xbf16> loc(#loc1134)
    %2841 = "ttir.transpose"(%2839, %2840) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x512x15x20xbf16>, tensor<1x15x512x20xbf16>) -> tensor<1x15x512x20xbf16> loc(#loc1134)
    %2842 = ttir.empty() : tensor<1x15x20x512xbf16> loc(#loc1135)
    %2843 = "ttir.transpose"(%2841, %2842) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x512x20xbf16>, tensor<1x15x20x512xbf16>) -> tensor<1x15x20x512xbf16> loc(#loc1135)
    %2844 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1136)
    %2845 = "ttir.conv2d"(%2843, %arg469, %2844) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x512xbf16>, tensor<1024x512x3x3xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1136)
    %2846 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1137)
    %2847 = "ttir.transpose"(%2845, %2846) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x1024xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1137)
    %2848 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc1138)
    %2849 = "ttir.transpose"(%2847, %2848) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc1138)
    %2850 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc214)
    %2851 = "ttir.multiply"(%2849, %arg357, %2850) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc214)
    %2852 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc215)
    %2853 = "ttir.add"(%2851, %arg358, %2852) : (tensor<1x1024x15x20xbf16>, tensor<1x1024x1x1xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc215)
    %2854 = ttir.empty() : tensor<1x1024x15x20xbf16> loc(#loc537)
    %2855 = "ttir.leaky_relu"(%2853, %2854) <{parameter = 1.000000e-01 : f32}> : (tensor<1x1024x15x20xbf16>, tensor<1x1024x15x20xbf16>) -> tensor<1x1024x15x20xbf16> loc(#loc537)
    %2856 = ttir.empty() : tensor<1x15x1024x20xbf16> loc(#loc1139)
    %2857 = "ttir.transpose"(%2855, %2856) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x1024x15x20xbf16>, tensor<1x15x1024x20xbf16>) -> tensor<1x15x1024x20xbf16> loc(#loc1139)
    %2858 = ttir.empty() : tensor<1x15x20x1024xbf16> loc(#loc1140)
    %2859 = "ttir.transpose"(%2857, %2858) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x1024x20xbf16>, tensor<1x15x20x1024xbf16>) -> tensor<1x15x20x1024xbf16> loc(#loc1140)
    %2860 = ttir.empty() : tensor<1x15x20x255xbf16> loc(#loc1141)
    %2861 = "ttir.conv2d"(%2859, %arg470, %arg471, %2860) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<1x15x20x1024xbf16>, tensor<255x1024x1x1xbf16>, tensor<1x1x1x255xbf16>, tensor<1x15x20x255xbf16>) -> tensor<1x15x20x255xbf16> loc(#loc1141)
    %2862 = ttir.empty() : tensor<1x15x255x20xbf16> loc(#loc1142)
    %2863 = "ttir.transpose"(%2861, %2862) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<1x15x20x255xbf16>, tensor<1x15x255x20xbf16>) -> tensor<1x15x255x20xbf16> loc(#loc1142)
    %2864 = ttir.empty() : tensor<1x255x15x20xbf16> loc(#loc1143)
    %2865 = "ttir.transpose"(%2863, %2864) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<1x15x255x20xbf16>, tensor<1x255x15x20xbf16>) -> tensor<1x255x15x20xbf16> loc(#loc1143)
    return %2617, %2741, %2865 : tensor<1x255x60x80xbf16>, tensor<1x255x30x40xbf16>, tensor<1x255x15x20xbf16> loc(#loc216)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("test.benchmark.utils.Yolov4Wrapper::")
#loc2 = loc("multiply_7")
#loc3 = loc("cast_15")
#loc4 = loc("multiply_29")
#loc5 = loc("cast_37")
#loc6 = loc("multiply_51")
#loc7 = loc("cast_59")
#loc8 = loc("multiply_73")
#loc9 = loc("cast_81")
#loc10 = loc("multiply_95")
#loc11 = loc("cast_103")
#loc12 = loc("multiply_118")
#loc13 = loc("cast_126")
#loc14 = loc("multiply_140")
#loc15 = loc("cast_148")
#loc16 = loc("multiply_163")
#loc17 = loc("cast_171")
#loc18 = loc("multiply_185")
#loc19 = loc("cast_193")
#loc20 = loc("multiply_207")
#loc21 = loc("cast_215")
#loc22 = loc("multiply_229")
#loc23 = loc("cast_237")
#loc24 = loc("multiply_251")
#loc25 = loc("cast_259")
#loc26 = loc("multiply_274")
#loc27 = loc("cast_282")
#loc28 = loc("multiply_296")
#loc29 = loc("cast_304")
#loc30 = loc("multiply_319")
#loc31 = loc("cast_327")
#loc32 = loc("multiply_341")
#loc33 = loc("cast_349")
#loc34 = loc("multiply_364")
#loc35 = loc("cast_372")
#loc36 = loc("multiply_386")
#loc37 = loc("cast_394")
#loc38 = loc("multiply_408")
#loc39 = loc("cast_416")
#loc40 = loc("multiply_430")
#loc41 = loc("cast_438")
#loc42 = loc("multiply_452")
#loc43 = loc("cast_460")
#loc44 = loc("multiply_475")
#loc45 = loc("cast_483")
#loc46 = loc("multiply_497")
#loc47 = loc("cast_505")
#loc48 = loc("multiply_520")
#loc49 = loc("cast_528")
#loc50 = loc("multiply_542")
#loc51 = loc("cast_550")
#loc52 = loc("multiply_565")
#loc53 = loc("cast_573")
#loc54 = loc("multiply_587")
#loc55 = loc("cast_595")
#loc56 = loc("multiply_610")
#loc57 = loc("cast_618")
#loc58 = loc("multiply_632")
#loc59 = loc("cast_640")
#loc60 = loc("multiply_655")
#loc61 = loc("cast_663")
#loc62 = loc("multiply_677")
#loc63 = loc("cast_685")
#loc64 = loc("multiply_700")
#loc65 = loc("cast_708")
#loc66 = loc("multiply_722")
#loc67 = loc("cast_730")
#loc68 = loc("multiply_745")
#loc69 = loc("cast_753")
#loc70 = loc("multiply_767")
#loc71 = loc("cast_775")
#loc72 = loc("multiply_790")
#loc73 = loc("cast_798")
#loc74 = loc("multiply_812")
#loc75 = loc("cast_820")
#loc76 = loc("multiply_835")
#loc77 = loc("cast_843")
#loc78 = loc("multiply_857")
#loc79 = loc("add_863")
#loc80 = loc("multiply_872")
#loc81 = loc("cast_880")
#loc82 = loc("multiply_894")
#loc83 = loc("cast_902")
#loc84 = loc("multiply_916")
#loc85 = loc("cast_924")
#loc86 = loc("multiply_938")
#loc87 = loc("cast_946")
#loc88 = loc("multiply_961")
#loc89 = loc("cast_969")
#loc90 = loc("multiply_983")
#loc91 = loc("cast_991")
#loc92 = loc("multiply_1006")
#loc93 = loc("cast_1014")
#loc94 = loc("multiply_1028")
#loc95 = loc("cast_1036")
#loc96 = loc("multiply_1051")
#loc97 = loc("cast_1059")
#loc98 = loc("multiply_1073")
#loc99 = loc("cast_1081")
#loc100 = loc("multiply_1096")
#loc101 = loc("cast_1104")
#loc102 = loc("multiply_1118")
#loc103 = loc("cast_1126")
#loc104 = loc("multiply_1141")
#loc105 = loc("cast_1149")
#loc106 = loc("multiply_1163")
#loc107 = loc("cast_1171")
#loc108 = loc("multiply_1186")
#loc109 = loc("cast_1194")
#loc110 = loc("multiply_1208")
#loc111 = loc("cast_1216")
#loc112 = loc("multiply_1231")
#loc113 = loc("cast_1239")
#loc114 = loc("multiply_1253")
#loc115 = loc("cast_1261")
#loc116 = loc("multiply_1276")
#loc117 = loc("cast_1284")
#loc118 = loc("multiply_1298")
#loc119 = loc("cast_1306")
#loc120 = loc("multiply_1321")
#loc121 = loc("cast_1329")
#loc122 = loc("multiply_1343")
#loc123 = loc("add_1349")
#loc124 = loc("multiply_1358")
#loc125 = loc("cast_1366")
#loc126 = loc("multiply_1380")
#loc127 = loc("cast_1388")
#loc128 = loc("multiply_1402")
#loc129 = loc("cast_1410")
#loc130 = loc("multiply_1424")
#loc131 = loc("cast_1432")
#loc132 = loc("multiply_1447")
#loc133 = loc("cast_1455")
#loc134 = loc("multiply_1469")
#loc135 = loc("cast_1477")
#loc136 = loc("multiply_1492")
#loc137 = loc("cast_1500")
#loc138 = loc("multiply_1514")
#loc139 = loc("cast_1522")
#loc140 = loc("multiply_1537")
#loc141 = loc("cast_1545")
#loc142 = loc("multiply_1559")
#loc143 = loc("cast_1567")
#loc144 = loc("multiply_1582")
#loc145 = loc("cast_1590")
#loc146 = loc("multiply_1604")
#loc147 = loc("cast_1612")
#loc148 = loc("multiply_1627")
#loc149 = loc("cast_1635")
#loc150 = loc("multiply_1649")
#loc151 = loc("add_1655")
#loc152 = loc("multiply_1664")
#loc153 = loc("add_1670")
#loc154 = loc("multiply_1679")
#loc155 = loc("add_1685")
#loc156 = loc("multiply_1698")
#loc157 = loc("add_1704")
#loc158 = loc("multiply_1713")
#loc159 = loc("add_1719")
#loc160 = loc("multiply_1728")
#loc161 = loc("add_1734")
#loc162 = loc("multiply_1743")
#loc163 = loc("add_1749")
#loc164 = loc("multiply_1760")
#loc165 = loc("add_1766")
#loc166 = loc("multiply_1775")
#loc167 = loc("add_1781")
#loc168 = loc("multiply_1790")
#loc169 = loc("add_1796")
#loc170 = loc("multiply_1805")
#loc171 = loc("add_1811")
#loc172 = loc("multiply_1820")
#loc173 = loc("add_1826")
#loc174 = loc("multiply_1835")
#loc175 = loc("add_1841")
#loc176 = loc("multiply_1852")
#loc177 = loc("add_1858")
#loc178 = loc("multiply_1867")
#loc179 = loc("add_1873")
#loc180 = loc("multiply_1882")
#loc181 = loc("add_1888")
#loc182 = loc("multiply_1897")
#loc183 = loc("add_1903")
#loc184 = loc("multiply_1912")
#loc185 = loc("add_1918")
#loc186 = loc("multiply_1927")
#loc187 = loc("add_1933")
#loc188 = loc("multiply_1946")
#loc189 = loc("add_1952")
#loc190 = loc("multiply_1962")
#loc191 = loc("add_1968")
#loc192 = loc("multiply_1977")
#loc193 = loc("add_1983")
#loc194 = loc("multiply_1992")
#loc195 = loc("add_1998")
#loc196 = loc("multiply_2007")
#loc197 = loc("add_2013")
#loc198 = loc("multiply_2022")
#loc199 = loc("add_2028")
#loc200 = loc("multiply_2037")
#loc201 = loc("add_2043")
#loc202 = loc("multiply_2056")
#loc203 = loc("add_2062")
#loc204 = loc("multiply_2072")
#loc205 = loc("add_2078")
#loc206 = loc("multiply_2087")
#loc207 = loc("add_2093")
#loc208 = loc("multiply_2102")
#loc209 = loc("add_2108")
#loc210 = loc("multiply_2117")
#loc211 = loc("add_2123")
#loc212 = loc("multiply_2132")
#loc213 = loc("add_2138")
#loc214 = loc("multiply_2147")
#loc215 = loc("add_2153")
#loc216 = loc(unknown)
#loc217 = loc("third_party.tt_forge_models.yolov4.pytorch.src.yolov4.Yolov4::model"(#loc1))
#loc218 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample1.DownSample1::downsample1"(#loc217))
#loc219 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample2.DownSample2::downsample2"(#loc217))
#loc220 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample3.DownSample3::downsample3"(#loc217))
#loc221 = loc("third_party.tt_forge_models.yolov4.pytorch.src.neck.Neck::neck"(#loc217))
#loc222 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample4.DownSample4::downsample4"(#loc217))
#loc223 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample5.DownSample5::downsample5"(#loc217))
#loc224 = loc("third_party.tt_forge_models.yolov4.pytorch.src.head.Head::head"(#loc217))
#loc225 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc218))
#loc226 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample1.Mish::mish"(#loc218))
#loc227 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc218))
#loc228 = loc("add_35"(#loc218))
#loc229 = loc("greater_36"(#loc218))
#loc230 = loc("exp_38"(#loc218))
#loc231 = loc("add_39"(#loc218))
#loc232 = loc("log_40"(#loc218))
#loc233 = loc("where_41"(#loc218))
#loc234 = loc("tanh_42"(#loc218))
#loc235 = loc("multiply_43"(#loc218))
#loc236 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc218))
#loc237 = loc("add_57"(#loc218))
#loc238 = loc("greater_58"(#loc218))
#loc239 = loc("exp_60"(#loc218))
#loc240 = loc("add_61"(#loc218))
#loc241 = loc("log_62"(#loc218))
#loc242 = loc("where_63"(#loc218))
#loc243 = loc("tanh_64"(#loc218))
#loc244 = loc("multiply_65"(#loc218))
#loc245 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc218))
#loc246 = loc("add_79"(#loc218))
#loc247 = loc("greater_80"(#loc218))
#loc248 = loc("exp_82"(#loc218))
#loc249 = loc("add_83"(#loc218))
#loc250 = loc("log_84"(#loc218))
#loc251 = loc("where_85"(#loc218))
#loc252 = loc("tanh_86"(#loc218))
#loc253 = loc("multiply_87"(#loc218))
#loc254 = loc("torch.nn.modules.conv.Conv2d::c6"(#loc218))
#loc255 = loc("add_101"(#loc218))
#loc256 = loc("greater_102"(#loc218))
#loc257 = loc("exp_104"(#loc218))
#loc258 = loc("add_105"(#loc218))
#loc259 = loc("log_106"(#loc218))
#loc260 = loc("where_107"(#loc218))
#loc261 = loc("tanh_108"(#loc218))
#loc262 = loc("multiply_109"(#loc218))
#loc263 = loc("add_110"(#loc218))
#loc264 = loc("torch.nn.modules.conv.Conv2d::c7"(#loc218))
#loc265 = loc("add_124"(#loc218))
#loc266 = loc("greater_125"(#loc218))
#loc267 = loc("exp_127"(#loc218))
#loc268 = loc("add_128"(#loc218))
#loc269 = loc("log_129"(#loc218))
#loc270 = loc("where_130"(#loc218))
#loc271 = loc("tanh_131"(#loc218))
#loc272 = loc("multiply_132"(#loc218))
#loc273 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc218))
#loc274 = loc("add_146"(#loc218))
#loc275 = loc("greater_147"(#loc218))
#loc276 = loc("exp_149"(#loc218))
#loc277 = loc("add_150"(#loc218))
#loc278 = loc("log_151"(#loc218))
#loc279 = loc("where_152"(#loc218))
#loc280 = loc("tanh_153"(#loc218))
#loc281 = loc("multiply_154"(#loc218))
#loc282 = loc("concatenate_155"(#loc218))
#loc283 = loc("torch.nn.modules.conv.Conv2d::c8"(#loc218))
#loc284 = loc("add_169"(#loc218))
#loc285 = loc("greater_170"(#loc218))
#loc286 = loc("exp_172"(#loc218))
#loc287 = loc("add_173"(#loc218))
#loc288 = loc("log_174"(#loc218))
#loc289 = loc("where_175"(#loc218))
#loc290 = loc("tanh_176"(#loc218))
#loc291 = loc("multiply_177"(#loc218))
#loc292 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc219))
#loc293 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample2.Mish::mish"(#loc219))
#loc294 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc219))
#loc295 = loc("add_213"(#loc219))
#loc296 = loc("greater_214"(#loc219))
#loc297 = loc("exp_216"(#loc219))
#loc298 = loc("add_217"(#loc219))
#loc299 = loc("log_218"(#loc219))
#loc300 = loc("where_219"(#loc219))
#loc301 = loc("tanh_220"(#loc219))
#loc302 = loc("multiply_221"(#loc219))
#loc303 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.ResBlock::res"(#loc219))
#loc304 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc219))
#loc305 = loc("add_325"(#loc219))
#loc306 = loc("greater_326"(#loc219))
#loc307 = loc("exp_328"(#loc219))
#loc308 = loc("add_329"(#loc219))
#loc309 = loc("log_330"(#loc219))
#loc310 = loc("where_331"(#loc219))
#loc311 = loc("tanh_332"(#loc219))
#loc312 = loc("multiply_333"(#loc219))
#loc313 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc219))
#loc314 = loc("add_347"(#loc219))
#loc315 = loc("greater_348"(#loc219))
#loc316 = loc("exp_350"(#loc219))
#loc317 = loc("add_351"(#loc219))
#loc318 = loc("log_352"(#loc219))
#loc319 = loc("where_353"(#loc219))
#loc320 = loc("tanh_354"(#loc219))
#loc321 = loc("multiply_355"(#loc219))
#loc322 = loc("concatenate_356"(#loc219))
#loc323 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc219))
#loc324 = loc("add_370"(#loc219))
#loc325 = loc("greater_371"(#loc219))
#loc326 = loc("exp_373"(#loc219))
#loc327 = loc("add_374"(#loc219))
#loc328 = loc("log_375"(#loc219))
#loc329 = loc("where_376"(#loc219))
#loc330 = loc("tanh_377"(#loc219))
#loc331 = loc("multiply_378"(#loc219))
#loc332 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc220))
#loc333 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample3.Mish::mish"(#loc220))
#loc334 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc220))
#loc335 = loc("add_414"(#loc220))
#loc336 = loc("greater_415"(#loc220))
#loc337 = loc("exp_417"(#loc220))
#loc338 = loc("add_418"(#loc220))
#loc339 = loc("log_419"(#loc220))
#loc340 = loc("where_420"(#loc220))
#loc341 = loc("tanh_421"(#loc220))
#loc342 = loc("multiply_422"(#loc220))
#loc343 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.ResBlock::res"(#loc220))
#loc344 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc220))
#loc345 = loc("add_796"(#loc220))
#loc346 = loc("greater_797"(#loc220))
#loc347 = loc("exp_799"(#loc220))
#loc348 = loc("add_800"(#loc220))
#loc349 = loc("log_801"(#loc220))
#loc350 = loc("where_802"(#loc220))
#loc351 = loc("tanh_803"(#loc220))
#loc352 = loc("multiply_804"(#loc220))
#loc353 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc220))
#loc354 = loc("add_818"(#loc220))
#loc355 = loc("greater_819"(#loc220))
#loc356 = loc("exp_821"(#loc220))
#loc357 = loc("add_822"(#loc220))
#loc358 = loc("log_823"(#loc220))
#loc359 = loc("where_824"(#loc220))
#loc360 = loc("tanh_825"(#loc220))
#loc361 = loc("multiply_826"(#loc220))
#loc362 = loc("concatenate_827"(#loc220))
#loc363 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc220))
#loc364 = loc("add_841"(#loc220))
#loc365 = loc("greater_842"(#loc220))
#loc366 = loc("exp_844"(#loc220))
#loc367 = loc("add_845"(#loc220))
#loc368 = loc("log_846"(#loc220))
#loc369 = loc("where_847"(#loc220))
#loc370 = loc("tanh_848"(#loc220))
#loc371 = loc("multiply_849"(#loc220))
#loc372 = loc("torch.nn.modules.conv.Conv2d::c9_2"(#loc221))
#loc373 = loc("leaky_relu_864"(#loc221))
#loc374 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc222))
#loc375 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample4.Mish::mish"(#loc222))
#loc376 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc222))
#loc377 = loc("add_900"(#loc222))
#loc378 = loc("greater_901"(#loc222))
#loc379 = loc("exp_903"(#loc222))
#loc380 = loc("add_904"(#loc222))
#loc381 = loc("log_905"(#loc222))
#loc382 = loc("where_906"(#loc222))
#loc383 = loc("tanh_907"(#loc222))
#loc384 = loc("multiply_908"(#loc222))
#loc385 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.ResBlock::res"(#loc222))
#loc386 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc222))
#loc387 = loc("add_1282"(#loc222))
#loc388 = loc("greater_1283"(#loc222))
#loc389 = loc("exp_1285"(#loc222))
#loc390 = loc("add_1286"(#loc222))
#loc391 = loc("log_1287"(#loc222))
#loc392 = loc("where_1288"(#loc222))
#loc393 = loc("tanh_1289"(#loc222))
#loc394 = loc("multiply_1290"(#loc222))
#loc395 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc222))
#loc396 = loc("add_1304"(#loc222))
#loc397 = loc("greater_1305"(#loc222))
#loc398 = loc("exp_1307"(#loc222))
#loc399 = loc("add_1308"(#loc222))
#loc400 = loc("log_1309"(#loc222))
#loc401 = loc("where_1310"(#loc222))
#loc402 = loc("tanh_1311"(#loc222))
#loc403 = loc("multiply_1312"(#loc222))
#loc404 = loc("concatenate_1313"(#loc222))
#loc405 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc222))
#loc406 = loc("add_1327"(#loc222))
#loc407 = loc("greater_1328"(#loc222))
#loc408 = loc("exp_1330"(#loc222))
#loc409 = loc("add_1331"(#loc222))
#loc410 = loc("log_1332"(#loc222))
#loc411 = loc("where_1333"(#loc222))
#loc412 = loc("tanh_1334"(#loc222))
#loc413 = loc("multiply_1335"(#loc222))
#loc414 = loc("torch.nn.modules.conv.Conv2d::c7_2"(#loc221))
#loc415 = loc("leaky_relu_1350"(#loc221))
#loc416 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc223))
#loc417 = loc("third_party.tt_forge_models.yolov4.pytorch.src.downsample5.Mish::mish"(#loc223))
#loc418 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc223))
#loc419 = loc("add_1386"(#loc223))
#loc420 = loc("greater_1387"(#loc223))
#loc421 = loc("exp_1389"(#loc223))
#loc422 = loc("add_1390"(#loc223))
#loc423 = loc("log_1391"(#loc223))
#loc424 = loc("where_1392"(#loc223))
#loc425 = loc("tanh_1393"(#loc223))
#loc426 = loc("multiply_1394"(#loc223))
#loc427 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.ResBlock::res"(#loc223))
#loc428 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc223))
#loc429 = loc("add_1588"(#loc223))
#loc430 = loc("greater_1589"(#loc223))
#loc431 = loc("exp_1591"(#loc223))
#loc432 = loc("add_1592"(#loc223))
#loc433 = loc("log_1593"(#loc223))
#loc434 = loc("where_1594"(#loc223))
#loc435 = loc("tanh_1595"(#loc223))
#loc436 = loc("multiply_1596"(#loc223))
#loc437 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc223))
#loc438 = loc("add_1610"(#loc223))
#loc439 = loc("greater_1611"(#loc223))
#loc440 = loc("exp_1613"(#loc223))
#loc441 = loc("add_1614"(#loc223))
#loc442 = loc("log_1615"(#loc223))
#loc443 = loc("where_1616"(#loc223))
#loc444 = loc("tanh_1617"(#loc223))
#loc445 = loc("multiply_1618"(#loc223))
#loc446 = loc("concatenate_1619"(#loc223))
#loc447 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc223))
#loc448 = loc("add_1633"(#loc223))
#loc449 = loc("greater_1634"(#loc223))
#loc450 = loc("exp_1636"(#loc223))
#loc451 = loc("add_1637"(#loc223))
#loc452 = loc("log_1638"(#loc223))
#loc453 = loc("where_1639"(#loc223))
#loc454 = loc("tanh_1640"(#loc223))
#loc455 = loc("multiply_1641"(#loc223))
#loc456 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc221))
#loc457 = loc("torch.nn.modules.activation.LeakyReLU::relu"(#loc221))
#loc458 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc221))
#loc459 = loc("leaky_relu_1671"(#loc221))
#loc460 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc221))
#loc461 = loc("leaky_relu_1686"(#loc221))
#loc462 = loc("torch.nn.modules.pooling.MaxPool2d::p3"(#loc221))
#loc463 = loc("torch.nn.modules.pooling.MaxPool2d::p2"(#loc221))
#loc464 = loc("torch.nn.modules.pooling.MaxPool2d::p1"(#loc221))
#loc465 = loc("concatenate_1690"(#loc221))
#loc466 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc221))
#loc467 = loc("leaky_relu_1705"(#loc221))
#loc468 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc221))
#loc469 = loc("leaky_relu_1720"(#loc221))
#loc470 = loc("torch.nn.modules.conv.Conv2d::c6"(#loc221))
#loc471 = loc("leaky_relu_1735"(#loc221))
#loc472 = loc("torch.nn.modules.conv.Conv2d::c7"(#loc221))
#loc473 = loc("leaky_relu_1750"(#loc221))
#loc474 = loc("torch.nn.modules.upsampling.Upsample::u"(#loc221))
#loc475 = loc("concatenate_1752"(#loc221))
#loc476 = loc("torch.nn.modules.conv.Conv2d::c7_3"(#loc221))
#loc477 = loc("leaky_relu_1767"(#loc221))
#loc478 = loc("torch.nn.modules.conv.Conv2d::c8"(#loc221))
#loc479 = loc("leaky_relu_1782"(#loc221))
#loc480 = loc("torch.nn.modules.conv.Conv2d::c7_4"(#loc221))
#loc481 = loc("leaky_relu_1797"(#loc221))
#loc482 = loc("torch.nn.modules.conv.Conv2d::c8_2"(#loc221))
#loc483 = loc("leaky_relu_1812"(#loc221))
#loc484 = loc("torch.nn.modules.conv.Conv2d::c7_5"(#loc221))
#loc485 = loc("leaky_relu_1827"(#loc221))
#loc486 = loc("torch.nn.modules.conv.Conv2d::c9"(#loc221))
#loc487 = loc("leaky_relu_1842"(#loc221))
#loc488 = loc("resize2d_1843.dc.transpose.0"(#loc221))
#loc489 = loc("resize2d_1843.dc.transpose.1"(#loc221))
#loc490 = loc("resize2d_1843.dc.upsample2d.2"(#loc221))
#loc491 = loc("resize2d_1843.dc.transpose.3"(#loc221))
#loc492 = loc("resize2d_1843.dc.transpose.4"(#loc221))
#loc493 = loc("concatenate_1844"(#loc221))
#loc494 = loc("torch.nn.modules.conv.Conv2d::c9_3"(#loc221))
#loc495 = loc("leaky_relu_1859"(#loc221))
#loc496 = loc("torch.nn.modules.conv.Conv2d::c10"(#loc221))
#loc497 = loc("leaky_relu_1874"(#loc221))
#loc498 = loc("torch.nn.modules.conv.Conv2d::c9_4"(#loc221))
#loc499 = loc("leaky_relu_1889"(#loc221))
#loc500 = loc("torch.nn.modules.conv.Conv2d::c10_2"(#loc221))
#loc501 = loc("leaky_relu_1904"(#loc221))
#loc502 = loc("torch.nn.modules.conv.Conv2d::c9_5"(#loc221))
#loc503 = loc("leaky_relu_1919"(#loc221))
#loc504 = loc("torch.nn.modules.conv.Conv2d::c1"(#loc224))
#loc505 = loc("torch.nn.modules.activation.LeakyReLU::relu"(#loc224))
#loc506 = loc("torch.nn.modules.conv.Conv2d::c2"(#loc224))
#loc507 = loc("torch.nn.modules.conv.Conv2d::c3"(#loc224))
#loc508 = loc("leaky_relu_1953"(#loc224))
#loc509 = loc("concatenate_1954"(#loc224))
#loc510 = loc("torch.nn.modules.conv.Conv2d::c4"(#loc224))
#loc511 = loc("leaky_relu_1969"(#loc224))
#loc512 = loc("torch.nn.modules.conv.Conv2d::c5"(#loc224))
#loc513 = loc("leaky_relu_1984"(#loc224))
#loc514 = loc("torch.nn.modules.conv.Conv2d::c6"(#loc224))
#loc515 = loc("leaky_relu_1999"(#loc224))
#loc516 = loc("torch.nn.modules.conv.Conv2d::c7"(#loc224))
#loc517 = loc("leaky_relu_2014"(#loc224))
#loc518 = loc("torch.nn.modules.conv.Conv2d::c8"(#loc224))
#loc519 = loc("leaky_relu_2029"(#loc224))
#loc520 = loc("torch.nn.modules.conv.Conv2d::c9"(#loc224))
#loc521 = loc("leaky_relu_2044"(#loc224))
#loc522 = loc("torch.nn.modules.conv.Conv2d::c10"(#loc224))
#loc523 = loc("torch.nn.modules.conv.Conv2d::c11"(#loc224))
#loc524 = loc("leaky_relu_2063"(#loc224))
#loc525 = loc("concatenate_2064"(#loc224))
#loc526 = loc("torch.nn.modules.conv.Conv2d::c12"(#loc224))
#loc527 = loc("leaky_relu_2079"(#loc224))
#loc528 = loc("torch.nn.modules.conv.Conv2d::c13"(#loc224))
#loc529 = loc("leaky_relu_2094"(#loc224))
#loc530 = loc("torch.nn.modules.conv.Conv2d::c14"(#loc224))
#loc531 = loc("leaky_relu_2109"(#loc224))
#loc532 = loc("torch.nn.modules.conv.Conv2d::c15"(#loc224))
#loc533 = loc("leaky_relu_2124"(#loc224))
#loc534 = loc("torch.nn.modules.conv.Conv2d::c16"(#loc224))
#loc535 = loc("leaky_relu_2139"(#loc224))
#loc536 = loc("torch.nn.modules.conv.Conv2d::c17"(#loc224))
#loc537 = loc("leaky_relu_2154"(#loc224))
#loc538 = loc("torch.nn.modules.conv.Conv2d::c18"(#loc224))
#loc539 = loc("conv2d_0.dc.transpose.0"(#loc225))
#loc540 = loc("conv2d_0.dc.transpose.1"(#loc225))
#loc541 = loc("conv2d_0.dc.conv2d.2"(#loc225))
#loc542 = loc("conv2d_0.dc.transpose.3"(#loc225))
#loc543 = loc("conv2d_0.dc.transpose.4"(#loc225))
#loc544 = loc("add_13"(#loc226))
#loc545 = loc("greater_14"(#loc226))
#loc546 = loc("exp_16"(#loc226))
#loc547 = loc("add_17"(#loc226))
#loc548 = loc("log_18"(#loc226))
#loc549 = loc("where_19"(#loc226))
#loc550 = loc("tanh_20"(#loc226))
#loc551 = loc("multiply_21"(#loc226))
#loc552 = loc("conv2d_22.dc.transpose.0"(#loc227))
#loc553 = loc("conv2d_22.dc.transpose.1"(#loc227))
#loc554 = loc("conv2d_22.dc.conv2d.2"(#loc227))
#loc555 = loc("conv2d_22.dc.transpose.3"(#loc227))
#loc556 = loc("conv2d_22.dc.transpose.4"(#loc227))
#loc557 = loc("conv2d_44.dc.transpose.0"(#loc236))
#loc558 = loc("conv2d_44.dc.transpose.1"(#loc236))
#loc559 = loc("conv2d_44.dc.conv2d.2"(#loc236))
#loc560 = loc("conv2d_44.dc.transpose.3"(#loc236))
#loc561 = loc("conv2d_44.dc.transpose.4"(#loc236))
#loc562 = loc("conv2d_66.dc.transpose.0"(#loc245))
#loc563 = loc("conv2d_66.dc.transpose.1"(#loc245))
#loc564 = loc("conv2d_66.dc.conv2d.2"(#loc245))
#loc565 = loc("conv2d_66.dc.transpose.3"(#loc245))
#loc566 = loc("conv2d_66.dc.transpose.4"(#loc245))
#loc567 = loc("conv2d_88.dc.transpose.0"(#loc254))
#loc568 = loc("conv2d_88.dc.transpose.1"(#loc254))
#loc569 = loc("conv2d_88.dc.conv2d.2"(#loc254))
#loc570 = loc("conv2d_88.dc.transpose.3"(#loc254))
#loc571 = loc("conv2d_88.dc.transpose.4"(#loc254))
#loc572 = loc("conv2d_111.dc.transpose.0"(#loc264))
#loc573 = loc("conv2d_111.dc.transpose.1"(#loc264))
#loc574 = loc("conv2d_111.dc.conv2d.2"(#loc264))
#loc575 = loc("conv2d_111.dc.transpose.3"(#loc264))
#loc576 = loc("conv2d_111.dc.transpose.4"(#loc264))
#loc577 = loc("conv2d_133.dc.transpose.0"(#loc273))
#loc578 = loc("conv2d_133.dc.transpose.1"(#loc273))
#loc579 = loc("conv2d_133.dc.conv2d.2"(#loc273))
#loc580 = loc("conv2d_133.dc.transpose.3"(#loc273))
#loc581 = loc("conv2d_133.dc.transpose.4"(#loc273))
#loc582 = loc("conv2d_156.dc.transpose.0"(#loc283))
#loc583 = loc("conv2d_156.dc.transpose.1"(#loc283))
#loc584 = loc("conv2d_156.dc.conv2d.2"(#loc283))
#loc585 = loc("conv2d_156.dc.transpose.3"(#loc283))
#loc586 = loc("conv2d_156.dc.transpose.4"(#loc283))
#loc587 = loc("conv2d_178.dc.transpose.0"(#loc292))
#loc588 = loc("conv2d_178.dc.transpose.1"(#loc292))
#loc589 = loc("conv2d_178.dc.conv2d.2"(#loc292))
#loc590 = loc("conv2d_178.dc.transpose.3"(#loc292))
#loc591 = loc("conv2d_178.dc.transpose.4"(#loc292))
#loc592 = loc("add_191"(#loc293))
#loc593 = loc("greater_192"(#loc293))
#loc594 = loc("exp_194"(#loc293))
#loc595 = loc("add_195"(#loc293))
#loc596 = loc("log_196"(#loc293))
#loc597 = loc("where_197"(#loc293))
#loc598 = loc("tanh_198"(#loc293))
#loc599 = loc("multiply_199"(#loc293))
#loc600 = loc("conv2d_200.dc.transpose.0"(#loc294))
#loc601 = loc("conv2d_200.dc.transpose.1"(#loc294))
#loc602 = loc("conv2d_200.dc.conv2d.2"(#loc294))
#loc603 = loc("conv2d_200.dc.transpose.3"(#loc294))
#loc604 = loc("conv2d_200.dc.transpose.4"(#loc294))
#loc605 = loc("torch.nn.modules.conv.Conv2d::0.0"(#loc303))
#loc606 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.Mish::0.2"(#loc303))
#loc607 = loc("torch.nn.modules.conv.Conv2d::0.3"(#loc303))
#loc608 = loc("add_257"(#loc303))
#loc609 = loc("greater_258"(#loc303))
#loc610 = loc("exp_260"(#loc303))
#loc611 = loc("add_261"(#loc303))
#loc612 = loc("log_262"(#loc303))
#loc613 = loc("where_263"(#loc303))
#loc614 = loc("tanh_264"(#loc303))
#loc615 = loc("multiply_265"(#loc303))
#loc616 = loc("add_266"(#loc303))
#loc617 = loc("torch.nn.modules.conv.Conv2d::0"(#loc303))
#loc618 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.Mish::2"(#loc303))
#loc619 = loc("torch.nn.modules.conv.Conv2d::3"(#loc303))
#loc620 = loc("add_302"(#loc303))
#loc621 = loc("greater_303"(#loc303))
#loc622 = loc("exp_305"(#loc303))
#loc623 = loc("add_306"(#loc303))
#loc624 = loc("log_307"(#loc303))
#loc625 = loc("where_308"(#loc303))
#loc626 = loc("tanh_309"(#loc303))
#loc627 = loc("multiply_310"(#loc303))
#loc628 = loc("add_311"(#loc303))
#loc629 = loc("conv2d_312.dc.transpose.0"(#loc304))
#loc630 = loc("conv2d_312.dc.transpose.1"(#loc304))
#loc631 = loc("conv2d_312.dc.conv2d.2"(#loc304))
#loc632 = loc("conv2d_312.dc.transpose.3"(#loc304))
#loc633 = loc("conv2d_312.dc.transpose.4"(#loc304))
#loc634 = loc("conv2d_334.dc.transpose.0"(#loc313))
#loc635 = loc("conv2d_334.dc.transpose.1"(#loc313))
#loc636 = loc("conv2d_334.dc.conv2d.2"(#loc313))
#loc637 = loc("conv2d_334.dc.transpose.3"(#loc313))
#loc638 = loc("conv2d_334.dc.transpose.4"(#loc313))
#loc639 = loc("conv2d_357.dc.transpose.0"(#loc323))
#loc640 = loc("conv2d_357.dc.transpose.1"(#loc323))
#loc641 = loc("conv2d_357.dc.conv2d.2"(#loc323))
#loc642 = loc("conv2d_357.dc.transpose.3"(#loc323))
#loc643 = loc("conv2d_357.dc.transpose.4"(#loc323))
#loc644 = loc("conv2d_379.dc.transpose.0"(#loc332))
#loc645 = loc("conv2d_379.dc.transpose.1"(#loc332))
#loc646 = loc("conv2d_379.dc.conv2d.2"(#loc332))
#loc647 = loc("conv2d_379.dc.transpose.3"(#loc332))
#loc648 = loc("conv2d_379.dc.transpose.4"(#loc332))
#loc649 = loc("add_392"(#loc333))
#loc650 = loc("greater_393"(#loc333))
#loc651 = loc("exp_395"(#loc333))
#loc652 = loc("add_396"(#loc333))
#loc653 = loc("log_397"(#loc333))
#loc654 = loc("where_398"(#loc333))
#loc655 = loc("tanh_399"(#loc333))
#loc656 = loc("multiply_400"(#loc333))
#loc657 = loc("conv2d_401.dc.transpose.0"(#loc334))
#loc658 = loc("conv2d_401.dc.transpose.1"(#loc334))
#loc659 = loc("conv2d_401.dc.conv2d.2"(#loc334))
#loc660 = loc("conv2d_401.dc.transpose.3"(#loc334))
#loc661 = loc("conv2d_401.dc.transpose.4"(#loc334))
#loc662 = loc("torch.nn.modules.conv.Conv2d::0"(#loc343))
#loc663 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.Mish::2"(#loc343))
#loc664 = loc("torch.nn.modules.conv.Conv2d::3"(#loc343))
#loc665 = loc("add_458"(#loc343))
#loc666 = loc("greater_459"(#loc343))
#loc667 = loc("exp_461"(#loc343))
#loc668 = loc("add_462"(#loc343))
#loc669 = loc("log_463"(#loc343))
#loc670 = loc("where_464"(#loc343))
#loc671 = loc("tanh_465"(#loc343))
#loc672 = loc("multiply_466"(#loc343))
#loc673 = loc("add_467"(#loc343))
#loc674 = loc("add_503"(#loc343))
#loc675 = loc("greater_504"(#loc343))
#loc676 = loc("exp_506"(#loc343))
#loc677 = loc("add_507"(#loc343))
#loc678 = loc("log_508"(#loc343))
#loc679 = loc("where_509"(#loc343))
#loc680 = loc("tanh_510"(#loc343))
#loc681 = loc("multiply_511"(#loc343))
#loc682 = loc("add_512"(#loc343))
#loc683 = loc("add_548"(#loc343))
#loc684 = loc("greater_549"(#loc343))
#loc685 = loc("exp_551"(#loc343))
#loc686 = loc("add_552"(#loc343))
#loc687 = loc("log_553"(#loc343))
#loc688 = loc("where_554"(#loc343))
#loc689 = loc("tanh_555"(#loc343))
#loc690 = loc("multiply_556"(#loc343))
#loc691 = loc("add_557"(#loc343))
#loc692 = loc("add_593"(#loc343))
#loc693 = loc("greater_594"(#loc343))
#loc694 = loc("exp_596"(#loc343))
#loc695 = loc("add_597"(#loc343))
#loc696 = loc("log_598"(#loc343))
#loc697 = loc("where_599"(#loc343))
#loc698 = loc("tanh_600"(#loc343))
#loc699 = loc("multiply_601"(#loc343))
#loc700 = loc("add_602"(#loc343))
#loc701 = loc("add_638"(#loc343))
#loc702 = loc("greater_639"(#loc343))
#loc703 = loc("exp_641"(#loc343))
#loc704 = loc("add_642"(#loc343))
#loc705 = loc("log_643"(#loc343))
#loc706 = loc("where_644"(#loc343))
#loc707 = loc("tanh_645"(#loc343))
#loc708 = loc("multiply_646"(#loc343))
#loc709 = loc("add_647"(#loc343))
#loc710 = loc("add_683"(#loc343))
#loc711 = loc("greater_684"(#loc343))
#loc712 = loc("exp_686"(#loc343))
#loc713 = loc("add_687"(#loc343))
#loc714 = loc("log_688"(#loc343))
#loc715 = loc("where_689"(#loc343))
#loc716 = loc("tanh_690"(#loc343))
#loc717 = loc("multiply_691"(#loc343))
#loc718 = loc("add_692"(#loc343))
#loc719 = loc("add_728"(#loc343))
#loc720 = loc("greater_729"(#loc343))
#loc721 = loc("exp_731"(#loc343))
#loc722 = loc("add_732"(#loc343))
#loc723 = loc("log_733"(#loc343))
#loc724 = loc("where_734"(#loc343))
#loc725 = loc("tanh_735"(#loc343))
#loc726 = loc("multiply_736"(#loc343))
#loc727 = loc("add_737"(#loc343))
#loc728 = loc("add_773"(#loc343))
#loc729 = loc("greater_774"(#loc343))
#loc730 = loc("exp_776"(#loc343))
#loc731 = loc("add_777"(#loc343))
#loc732 = loc("log_778"(#loc343))
#loc733 = loc("where_779"(#loc343))
#loc734 = loc("tanh_780"(#loc343))
#loc735 = loc("multiply_781"(#loc343))
#loc736 = loc("add_782"(#loc343))
#loc737 = loc("conv2d_783.dc.transpose.0"(#loc344))
#loc738 = loc("conv2d_783.dc.transpose.1"(#loc344))
#loc739 = loc("conv2d_783.dc.conv2d.2"(#loc344))
#loc740 = loc("conv2d_783.dc.transpose.3"(#loc344))
#loc741 = loc("conv2d_783.dc.transpose.4"(#loc344))
#loc742 = loc("conv2d_805.dc.transpose.0"(#loc353))
#loc743 = loc("conv2d_805.dc.transpose.1"(#loc353))
#loc744 = loc("conv2d_805.dc.conv2d.2"(#loc353))
#loc745 = loc("conv2d_805.dc.transpose.3"(#loc353))
#loc746 = loc("conv2d_805.dc.transpose.4"(#loc353))
#loc747 = loc("conv2d_828.dc.transpose.0"(#loc363))
#loc748 = loc("conv2d_828.dc.transpose.1"(#loc363))
#loc749 = loc("conv2d_828.dc.conv2d.2"(#loc363))
#loc750 = loc("conv2d_828.dc.transpose.3"(#loc363))
#loc751 = loc("conv2d_828.dc.transpose.4"(#loc363))
#loc752 = loc("conv2d_850.dc.transpose.0"(#loc372))
#loc753 = loc("conv2d_850.dc.transpose.1"(#loc372))
#loc754 = loc("conv2d_850.dc.conv2d.2"(#loc372))
#loc755 = loc("conv2d_850.dc.transpose.3"(#loc372))
#loc756 = loc("conv2d_850.dc.transpose.4"(#loc372))
#loc757 = loc("conv2d_865.dc.transpose.0"(#loc374))
#loc758 = loc("conv2d_865.dc.transpose.1"(#loc374))
#loc759 = loc("conv2d_865.dc.conv2d.2"(#loc374))
#loc760 = loc("conv2d_865.dc.transpose.3"(#loc374))
#loc761 = loc("conv2d_865.dc.transpose.4"(#loc374))
#loc762 = loc("add_878"(#loc375))
#loc763 = loc("greater_879"(#loc375))
#loc764 = loc("exp_881"(#loc375))
#loc765 = loc("add_882"(#loc375))
#loc766 = loc("log_883"(#loc375))
#loc767 = loc("where_884"(#loc375))
#loc768 = loc("tanh_885"(#loc375))
#loc769 = loc("multiply_886"(#loc375))
#loc770 = loc("conv2d_887.dc.transpose.0"(#loc376))
#loc771 = loc("conv2d_887.dc.transpose.1"(#loc376))
#loc772 = loc("conv2d_887.dc.conv2d.2"(#loc376))
#loc773 = loc("conv2d_887.dc.transpose.3"(#loc376))
#loc774 = loc("conv2d_887.dc.transpose.4"(#loc376))
#loc775 = loc("torch.nn.modules.conv.Conv2d::0"(#loc385))
#loc776 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.Mish::2"(#loc385))
#loc777 = loc("torch.nn.modules.conv.Conv2d::3"(#loc385))
#loc778 = loc("add_944"(#loc385))
#loc779 = loc("greater_945"(#loc385))
#loc780 = loc("exp_947"(#loc385))
#loc781 = loc("add_948"(#loc385))
#loc782 = loc("log_949"(#loc385))
#loc783 = loc("where_950"(#loc385))
#loc784 = loc("tanh_951"(#loc385))
#loc785 = loc("multiply_952"(#loc385))
#loc786 = loc("add_953"(#loc385))
#loc787 = loc("add_989"(#loc385))
#loc788 = loc("greater_990"(#loc385))
#loc789 = loc("exp_992"(#loc385))
#loc790 = loc("add_993"(#loc385))
#loc791 = loc("log_994"(#loc385))
#loc792 = loc("where_995"(#loc385))
#loc793 = loc("tanh_996"(#loc385))
#loc794 = loc("multiply_997"(#loc385))
#loc795 = loc("add_998"(#loc385))
#loc796 = loc("add_1034"(#loc385))
#loc797 = loc("greater_1035"(#loc385))
#loc798 = loc("exp_1037"(#loc385))
#loc799 = loc("add_1038"(#loc385))
#loc800 = loc("log_1039"(#loc385))
#loc801 = loc("where_1040"(#loc385))
#loc802 = loc("tanh_1041"(#loc385))
#loc803 = loc("multiply_1042"(#loc385))
#loc804 = loc("add_1043"(#loc385))
#loc805 = loc("add_1079"(#loc385))
#loc806 = loc("greater_1080"(#loc385))
#loc807 = loc("exp_1082"(#loc385))
#loc808 = loc("add_1083"(#loc385))
#loc809 = loc("log_1084"(#loc385))
#loc810 = loc("where_1085"(#loc385))
#loc811 = loc("tanh_1086"(#loc385))
#loc812 = loc("multiply_1087"(#loc385))
#loc813 = loc("add_1088"(#loc385))
#loc814 = loc("add_1124"(#loc385))
#loc815 = loc("greater_1125"(#loc385))
#loc816 = loc("exp_1127"(#loc385))
#loc817 = loc("add_1128"(#loc385))
#loc818 = loc("log_1129"(#loc385))
#loc819 = loc("where_1130"(#loc385))
#loc820 = loc("tanh_1131"(#loc385))
#loc821 = loc("multiply_1132"(#loc385))
#loc822 = loc("add_1133"(#loc385))
#loc823 = loc("add_1169"(#loc385))
#loc824 = loc("greater_1170"(#loc385))
#loc825 = loc("exp_1172"(#loc385))
#loc826 = loc("add_1173"(#loc385))
#loc827 = loc("log_1174"(#loc385))
#loc828 = loc("where_1175"(#loc385))
#loc829 = loc("tanh_1176"(#loc385))
#loc830 = loc("multiply_1177"(#loc385))
#loc831 = loc("add_1178"(#loc385))
#loc832 = loc("add_1214"(#loc385))
#loc833 = loc("greater_1215"(#loc385))
#loc834 = loc("exp_1217"(#loc385))
#loc835 = loc("add_1218"(#loc385))
#loc836 = loc("log_1219"(#loc385))
#loc837 = loc("where_1220"(#loc385))
#loc838 = loc("tanh_1221"(#loc385))
#loc839 = loc("multiply_1222"(#loc385))
#loc840 = loc("add_1223"(#loc385))
#loc841 = loc("add_1259"(#loc385))
#loc842 = loc("greater_1260"(#loc385))
#loc843 = loc("exp_1262"(#loc385))
#loc844 = loc("add_1263"(#loc385))
#loc845 = loc("log_1264"(#loc385))
#loc846 = loc("where_1265"(#loc385))
#loc847 = loc("tanh_1266"(#loc385))
#loc848 = loc("multiply_1267"(#loc385))
#loc849 = loc("add_1268"(#loc385))
#loc850 = loc("conv2d_1269.dc.transpose.0"(#loc386))
#loc851 = loc("conv2d_1269.dc.transpose.1"(#loc386))
#loc852 = loc("conv2d_1269.dc.conv2d.2"(#loc386))
#loc853 = loc("conv2d_1269.dc.transpose.3"(#loc386))
#loc854 = loc("conv2d_1269.dc.transpose.4"(#loc386))
#loc855 = loc("conv2d_1291.dc.transpose.0"(#loc395))
#loc856 = loc("conv2d_1291.dc.transpose.1"(#loc395))
#loc857 = loc("conv2d_1291.dc.conv2d.2"(#loc395))
#loc858 = loc("conv2d_1291.dc.transpose.3"(#loc395))
#loc859 = loc("conv2d_1291.dc.transpose.4"(#loc395))
#loc860 = loc("conv2d_1314.dc.transpose.0"(#loc405))
#loc861 = loc("conv2d_1314.dc.transpose.1"(#loc405))
#loc862 = loc("conv2d_1314.dc.conv2d.2"(#loc405))
#loc863 = loc("conv2d_1314.dc.transpose.3"(#loc405))
#loc864 = loc("conv2d_1314.dc.transpose.4"(#loc405))
#loc865 = loc("conv2d_1336.dc.transpose.0"(#loc414))
#loc866 = loc("conv2d_1336.dc.transpose.1"(#loc414))
#loc867 = loc("conv2d_1336.dc.conv2d.2"(#loc414))
#loc868 = loc("conv2d_1336.dc.transpose.3"(#loc414))
#loc869 = loc("conv2d_1336.dc.transpose.4"(#loc414))
#loc870 = loc("conv2d_1351.dc.transpose.0"(#loc416))
#loc871 = loc("conv2d_1351.dc.transpose.1"(#loc416))
#loc872 = loc("conv2d_1351.dc.conv2d.2"(#loc416))
#loc873 = loc("conv2d_1351.dc.transpose.3"(#loc416))
#loc874 = loc("conv2d_1351.dc.transpose.4"(#loc416))
#loc875 = loc("add_1364"(#loc417))
#loc876 = loc("greater_1365"(#loc417))
#loc877 = loc("exp_1367"(#loc417))
#loc878 = loc("add_1368"(#loc417))
#loc879 = loc("log_1369"(#loc417))
#loc880 = loc("where_1370"(#loc417))
#loc881 = loc("tanh_1371"(#loc417))
#loc882 = loc("multiply_1372"(#loc417))
#loc883 = loc("conv2d_1373.dc.transpose.0"(#loc418))
#loc884 = loc("conv2d_1373.dc.transpose.1"(#loc418))
#loc885 = loc("conv2d_1373.dc.conv2d.2"(#loc418))
#loc886 = loc("conv2d_1373.dc.transpose.3"(#loc418))
#loc887 = loc("conv2d_1373.dc.transpose.4"(#loc418))
#loc888 = loc("torch.nn.modules.conv.Conv2d::0"(#loc427))
#loc889 = loc("third_party.tt_forge_models.yolov4.pytorch.src.resblock.Mish::2"(#loc427))
#loc890 = loc("torch.nn.modules.conv.Conv2d::3"(#loc427))
#loc891 = loc("add_1430"(#loc427))
#loc892 = loc("greater_1431"(#loc427))
#loc893 = loc("exp_1433"(#loc427))
#loc894 = loc("add_1434"(#loc427))
#loc895 = loc("log_1435"(#loc427))
#loc896 = loc("where_1436"(#loc427))
#loc897 = loc("tanh_1437"(#loc427))
#loc898 = loc("multiply_1438"(#loc427))
#loc899 = loc("add_1439"(#loc427))
#loc900 = loc("add_1475"(#loc427))
#loc901 = loc("greater_1476"(#loc427))
#loc902 = loc("exp_1478"(#loc427))
#loc903 = loc("add_1479"(#loc427))
#loc904 = loc("log_1480"(#loc427))
#loc905 = loc("where_1481"(#loc427))
#loc906 = loc("tanh_1482"(#loc427))
#loc907 = loc("multiply_1483"(#loc427))
#loc908 = loc("add_1484"(#loc427))
#loc909 = loc("add_1520"(#loc427))
#loc910 = loc("greater_1521"(#loc427))
#loc911 = loc("exp_1523"(#loc427))
#loc912 = loc("add_1524"(#loc427))
#loc913 = loc("log_1525"(#loc427))
#loc914 = loc("where_1526"(#loc427))
#loc915 = loc("tanh_1527"(#loc427))
#loc916 = loc("multiply_1528"(#loc427))
#loc917 = loc("add_1529"(#loc427))
#loc918 = loc("add_1565"(#loc427))
#loc919 = loc("greater_1566"(#loc427))
#loc920 = loc("exp_1568"(#loc427))
#loc921 = loc("add_1569"(#loc427))
#loc922 = loc("log_1570"(#loc427))
#loc923 = loc("where_1571"(#loc427))
#loc924 = loc("tanh_1572"(#loc427))
#loc925 = loc("multiply_1573"(#loc427))
#loc926 = loc("add_1574"(#loc427))
#loc927 = loc("conv2d_1575.dc.transpose.0"(#loc428))
#loc928 = loc("conv2d_1575.dc.transpose.1"(#loc428))
#loc929 = loc("conv2d_1575.dc.conv2d.2"(#loc428))
#loc930 = loc("conv2d_1575.dc.transpose.3"(#loc428))
#loc931 = loc("conv2d_1575.dc.transpose.4"(#loc428))
#loc932 = loc("conv2d_1597.dc.transpose.0"(#loc437))
#loc933 = loc("conv2d_1597.dc.transpose.1"(#loc437))
#loc934 = loc("conv2d_1597.dc.conv2d.2"(#loc437))
#loc935 = loc("conv2d_1597.dc.transpose.3"(#loc437))
#loc936 = loc("conv2d_1597.dc.transpose.4"(#loc437))
#loc937 = loc("conv2d_1620.dc.transpose.0"(#loc447))
#loc938 = loc("conv2d_1620.dc.transpose.1"(#loc447))
#loc939 = loc("conv2d_1620.dc.conv2d.2"(#loc447))
#loc940 = loc("conv2d_1620.dc.transpose.3"(#loc447))
#loc941 = loc("conv2d_1620.dc.transpose.4"(#loc447))
#loc942 = loc("conv2d_1642.dc.transpose.0"(#loc456))
#loc943 = loc("conv2d_1642.dc.transpose.1"(#loc456))
#loc944 = loc("conv2d_1642.dc.conv2d.2"(#loc456))
#loc945 = loc("conv2d_1642.dc.transpose.3"(#loc456))
#loc946 = loc("conv2d_1642.dc.transpose.4"(#loc456))
#loc947 = loc("leaky_relu_1656"(#loc457))
#loc948 = loc("conv2d_1657.dc.transpose.0"(#loc458))
#loc949 = loc("conv2d_1657.dc.transpose.1"(#loc458))
#loc950 = loc("conv2d_1657.dc.conv2d.2"(#loc458))
#loc951 = loc("conv2d_1657.dc.transpose.3"(#loc458))
#loc952 = loc("conv2d_1657.dc.transpose.4"(#loc458))
#loc953 = loc("conv2d_1672.dc.transpose.0"(#loc460))
#loc954 = loc("conv2d_1672.dc.transpose.1"(#loc460))
#loc955 = loc("conv2d_1672.dc.conv2d.2"(#loc460))
#loc956 = loc("conv2d_1672.dc.transpose.3"(#loc460))
#loc957 = loc("conv2d_1672.dc.transpose.4"(#loc460))
#loc958 = loc("max_pool2d_1687.dc.transpose.0"(#loc462))
#loc959 = loc("max_pool2d_1687.dc.transpose.1"(#loc462))
#loc960 = loc("max_pool2d_1687.dc.max_pool2d.2"(#loc462))
#loc961 = loc("max_pool2d_1687.dc.transpose.3"(#loc462))
#loc962 = loc("max_pool2d_1687.dc.transpose.4"(#loc462))
#loc963 = loc("max_pool2d_1688.dc.transpose.0"(#loc463))
#loc964 = loc("max_pool2d_1688.dc.transpose.1"(#loc463))
#loc965 = loc("max_pool2d_1688.dc.max_pool2d.2"(#loc463))
#loc966 = loc("max_pool2d_1688.dc.transpose.3"(#loc463))
#loc967 = loc("max_pool2d_1688.dc.transpose.4"(#loc463))
#loc968 = loc("max_pool2d_1689.dc.transpose.0"(#loc464))
#loc969 = loc("max_pool2d_1689.dc.transpose.1"(#loc464))
#loc970 = loc("max_pool2d_1689.dc.max_pool2d.2"(#loc464))
#loc971 = loc("max_pool2d_1689.dc.transpose.3"(#loc464))
#loc972 = loc("max_pool2d_1689.dc.transpose.4"(#loc464))
#loc973 = loc("conv2d_1691.dc.transpose.0"(#loc466))
#loc974 = loc("conv2d_1691.dc.transpose.1"(#loc466))
#loc975 = loc("conv2d_1691.dc.conv2d.2"(#loc466))
#loc976 = loc("conv2d_1691.dc.transpose.3"(#loc466))
#loc977 = loc("conv2d_1691.dc.transpose.4"(#loc466))
#loc978 = loc("conv2d_1706.dc.transpose.0"(#loc468))
#loc979 = loc("conv2d_1706.dc.transpose.1"(#loc468))
#loc980 = loc("conv2d_1706.dc.conv2d.2"(#loc468))
#loc981 = loc("conv2d_1706.dc.transpose.3"(#loc468))
#loc982 = loc("conv2d_1706.dc.transpose.4"(#loc468))
#loc983 = loc("conv2d_1721.dc.transpose.0"(#loc470))
#loc984 = loc("conv2d_1721.dc.transpose.1"(#loc470))
#loc985 = loc("conv2d_1721.dc.conv2d.2"(#loc470))
#loc986 = loc("conv2d_1721.dc.transpose.3"(#loc470))
#loc987 = loc("conv2d_1721.dc.transpose.4"(#loc470))
#loc988 = loc("conv2d_1736.dc.transpose.0"(#loc472))
#loc989 = loc("conv2d_1736.dc.transpose.1"(#loc472))
#loc990 = loc("conv2d_1736.dc.conv2d.2"(#loc472))
#loc991 = loc("conv2d_1736.dc.transpose.3"(#loc472))
#loc992 = loc("conv2d_1736.dc.transpose.4"(#loc472))
#loc993 = loc("resize2d_1751.dc.transpose.0"(#loc474))
#loc994 = loc("resize2d_1751.dc.transpose.1"(#loc474))
#loc995 = loc("resize2d_1751.dc.upsample2d.2"(#loc474))
#loc996 = loc("resize2d_1751.dc.transpose.3"(#loc474))
#loc997 = loc("resize2d_1751.dc.transpose.4"(#loc474))
#loc998 = loc("conv2d_1753.dc.transpose.0"(#loc476))
#loc999 = loc("conv2d_1753.dc.transpose.1"(#loc476))
#loc1000 = loc("conv2d_1753.dc.conv2d.2"(#loc476))
#loc1001 = loc("conv2d_1753.dc.transpose.3"(#loc476))
#loc1002 = loc("conv2d_1753.dc.transpose.4"(#loc476))
#loc1003 = loc("conv2d_1768.dc.transpose.0"(#loc478))
#loc1004 = loc("conv2d_1768.dc.transpose.1"(#loc478))
#loc1005 = loc("conv2d_1768.dc.conv2d.2"(#loc478))
#loc1006 = loc("conv2d_1768.dc.transpose.3"(#loc478))
#loc1007 = loc("conv2d_1768.dc.transpose.4"(#loc478))
#loc1008 = loc("conv2d_1783.dc.transpose.0"(#loc480))
#loc1009 = loc("conv2d_1783.dc.transpose.1"(#loc480))
#loc1010 = loc("conv2d_1783.dc.conv2d.2"(#loc480))
#loc1011 = loc("conv2d_1783.dc.transpose.3"(#loc480))
#loc1012 = loc("conv2d_1783.dc.transpose.4"(#loc480))
#loc1013 = loc("conv2d_1798.dc.transpose.0"(#loc482))
#loc1014 = loc("conv2d_1798.dc.transpose.1"(#loc482))
#loc1015 = loc("conv2d_1798.dc.conv2d.2"(#loc482))
#loc1016 = loc("conv2d_1798.dc.transpose.3"(#loc482))
#loc1017 = loc("conv2d_1798.dc.transpose.4"(#loc482))
#loc1018 = loc("conv2d_1813.dc.transpose.0"(#loc484))
#loc1019 = loc("conv2d_1813.dc.transpose.1"(#loc484))
#loc1020 = loc("conv2d_1813.dc.conv2d.2"(#loc484))
#loc1021 = loc("conv2d_1813.dc.transpose.3"(#loc484))
#loc1022 = loc("conv2d_1813.dc.transpose.4"(#loc484))
#loc1023 = loc("conv2d_1828.dc.transpose.0"(#loc486))
#loc1024 = loc("conv2d_1828.dc.transpose.1"(#loc486))
#loc1025 = loc("conv2d_1828.dc.conv2d.2"(#loc486))
#loc1026 = loc("conv2d_1828.dc.transpose.3"(#loc486))
#loc1027 = loc("conv2d_1828.dc.transpose.4"(#loc486))
#loc1028 = loc("conv2d_1845.dc.transpose.0"(#loc494))
#loc1029 = loc("conv2d_1845.dc.transpose.1"(#loc494))
#loc1030 = loc("conv2d_1845.dc.conv2d.2"(#loc494))
#loc1031 = loc("conv2d_1845.dc.transpose.3"(#loc494))
#loc1032 = loc("conv2d_1845.dc.transpose.4"(#loc494))
#loc1033 = loc("conv2d_1860.dc.transpose.0"(#loc496))
#loc1034 = loc("conv2d_1860.dc.transpose.1"(#loc496))
#loc1035 = loc("conv2d_1860.dc.conv2d.2"(#loc496))
#loc1036 = loc("conv2d_1860.dc.transpose.3"(#loc496))
#loc1037 = loc("conv2d_1860.dc.transpose.4"(#loc496))
#loc1038 = loc("conv2d_1875.dc.transpose.0"(#loc498))
#loc1039 = loc("conv2d_1875.dc.transpose.1"(#loc498))
#loc1040 = loc("conv2d_1875.dc.conv2d.2"(#loc498))
#loc1041 = loc("conv2d_1875.dc.transpose.3"(#loc498))
#loc1042 = loc("conv2d_1875.dc.transpose.4"(#loc498))
#loc1043 = loc("conv2d_1890.dc.transpose.0"(#loc500))
#loc1044 = loc("conv2d_1890.dc.transpose.1"(#loc500))
#loc1045 = loc("conv2d_1890.dc.conv2d.2"(#loc500))
#loc1046 = loc("conv2d_1890.dc.transpose.3"(#loc500))
#loc1047 = loc("conv2d_1890.dc.transpose.4"(#loc500))
#loc1048 = loc("conv2d_1905.dc.transpose.0"(#loc502))
#loc1049 = loc("conv2d_1905.dc.transpose.1"(#loc502))
#loc1050 = loc("conv2d_1905.dc.conv2d.2"(#loc502))
#loc1051 = loc("conv2d_1905.dc.transpose.3"(#loc502))
#loc1052 = loc("conv2d_1905.dc.transpose.4"(#loc502))
#loc1053 = loc("conv2d_1920.dc.transpose.0"(#loc504))
#loc1054 = loc("conv2d_1920.dc.transpose.1"(#loc504))
#loc1055 = loc("conv2d_1920.dc.conv2d.2"(#loc504))
#loc1056 = loc("conv2d_1920.dc.transpose.3"(#loc504))
#loc1057 = loc("conv2d_1920.dc.transpose.4"(#loc504))
#loc1058 = loc("leaky_relu_1934"(#loc505))
#loc1059 = loc("conv2d_1935.dc.transpose.0"(#loc506))
#loc1060 = loc("conv2d_1935.dc.transpose.1"(#loc506))
#loc1061 = loc("conv2d_1935.dc.conv2d.4"(#loc506))
#loc1062 = loc("conv2d_1935.dc.transpose.5"(#loc506))
#loc1063 = loc("conv2d_1935.dc.transpose.6"(#loc506))
#loc1064 = loc("conv2d_1939.dc.transpose.0"(#loc507))
#loc1065 = loc("conv2d_1939.dc.transpose.1"(#loc507))
#loc1066 = loc("conv2d_1939.dc.conv2d.2"(#loc507))
#loc1067 = loc("conv2d_1939.dc.transpose.3"(#loc507))
#loc1068 = loc("conv2d_1939.dc.transpose.4"(#loc507))
#loc1069 = loc("conv2d_1955.dc.transpose.0"(#loc510))
#loc1070 = loc("conv2d_1955.dc.transpose.1"(#loc510))
#loc1071 = loc("conv2d_1955.dc.conv2d.2"(#loc510))
#loc1072 = loc("conv2d_1955.dc.transpose.3"(#loc510))
#loc1073 = loc("conv2d_1955.dc.transpose.4"(#loc510))
#loc1074 = loc("conv2d_1970.dc.transpose.0"(#loc512))
#loc1075 = loc("conv2d_1970.dc.transpose.1"(#loc512))
#loc1076 = loc("conv2d_1970.dc.conv2d.2"(#loc512))
#loc1077 = loc("conv2d_1970.dc.transpose.3"(#loc512))
#loc1078 = loc("conv2d_1970.dc.transpose.4"(#loc512))
#loc1079 = loc("conv2d_1985.dc.transpose.0"(#loc514))
#loc1080 = loc("conv2d_1985.dc.transpose.1"(#loc514))
#loc1081 = loc("conv2d_1985.dc.conv2d.2"(#loc514))
#loc1082 = loc("conv2d_1985.dc.transpose.3"(#loc514))
#loc1083 = loc("conv2d_1985.dc.transpose.4"(#loc514))
#loc1084 = loc("conv2d_2000.dc.transpose.0"(#loc516))
#loc1085 = loc("conv2d_2000.dc.transpose.1"(#loc516))
#loc1086 = loc("conv2d_2000.dc.conv2d.2"(#loc516))
#loc1087 = loc("conv2d_2000.dc.transpose.3"(#loc516))
#loc1088 = loc("conv2d_2000.dc.transpose.4"(#loc516))
#loc1089 = loc("conv2d_2015.dc.transpose.0"(#loc518))
#loc1090 = loc("conv2d_2015.dc.transpose.1"(#loc518))
#loc1091 = loc("conv2d_2015.dc.conv2d.2"(#loc518))
#loc1092 = loc("conv2d_2015.dc.transpose.3"(#loc518))
#loc1093 = loc("conv2d_2015.dc.transpose.4"(#loc518))
#loc1094 = loc("conv2d_2030.dc.transpose.0"(#loc520))
#loc1095 = loc("conv2d_2030.dc.transpose.1"(#loc520))
#loc1096 = loc("conv2d_2030.dc.conv2d.2"(#loc520))
#loc1097 = loc("conv2d_2030.dc.transpose.3"(#loc520))
#loc1098 = loc("conv2d_2030.dc.transpose.4"(#loc520))
#loc1099 = loc("conv2d_2045.dc.transpose.0"(#loc522))
#loc1100 = loc("conv2d_2045.dc.transpose.1"(#loc522))
#loc1101 = loc("conv2d_2045.dc.conv2d.4"(#loc522))
#loc1102 = loc("conv2d_2045.dc.transpose.5"(#loc522))
#loc1103 = loc("conv2d_2045.dc.transpose.6"(#loc522))
#loc1104 = loc("conv2d_2049.dc.transpose.0"(#loc523))
#loc1105 = loc("conv2d_2049.dc.transpose.1"(#loc523))
#loc1106 = loc("conv2d_2049.dc.conv2d.2"(#loc523))
#loc1107 = loc("conv2d_2049.dc.transpose.3"(#loc523))
#loc1108 = loc("conv2d_2049.dc.transpose.4"(#loc523))
#loc1109 = loc("conv2d_2065.dc.transpose.0"(#loc526))
#loc1110 = loc("conv2d_2065.dc.transpose.1"(#loc526))
#loc1111 = loc("conv2d_2065.dc.conv2d.2"(#loc526))
#loc1112 = loc("conv2d_2065.dc.transpose.3"(#loc526))
#loc1113 = loc("conv2d_2065.dc.transpose.4"(#loc526))
#loc1114 = loc("conv2d_2080.dc.transpose.0"(#loc528))
#loc1115 = loc("conv2d_2080.dc.transpose.1"(#loc528))
#loc1116 = loc("conv2d_2080.dc.conv2d.2"(#loc528))
#loc1117 = loc("conv2d_2080.dc.transpose.3"(#loc528))
#loc1118 = loc("conv2d_2080.dc.transpose.4"(#loc528))
#loc1119 = loc("conv2d_2095.dc.transpose.0"(#loc530))
#loc1120 = loc("conv2d_2095.dc.transpose.1"(#loc530))
#loc1121 = loc("conv2d_2095.dc.conv2d.2"(#loc530))
#loc1122 = loc("conv2d_2095.dc.transpose.3"(#loc530))
#loc1123 = loc("conv2d_2095.dc.transpose.4"(#loc530))
#loc1124 = loc("conv2d_2110.dc.transpose.0"(#loc532))
#loc1125 = loc("conv2d_2110.dc.transpose.1"(#loc532))
#loc1126 = loc("conv2d_2110.dc.conv2d.2"(#loc532))
#loc1127 = loc("conv2d_2110.dc.transpose.3"(#loc532))
#loc1128 = loc("conv2d_2110.dc.transpose.4"(#loc532))
#loc1129 = loc("conv2d_2125.dc.transpose.0"(#loc534))
#loc1130 = loc("conv2d_2125.dc.transpose.1"(#loc534))
#loc1131 = loc("conv2d_2125.dc.conv2d.2"(#loc534))
#loc1132 = loc("conv2d_2125.dc.transpose.3"(#loc534))
#loc1133 = loc("conv2d_2125.dc.transpose.4"(#loc534))
#loc1134 = loc("conv2d_2140.dc.transpose.0"(#loc536))
#loc1135 = loc("conv2d_2140.dc.transpose.1"(#loc536))
#loc1136 = loc("conv2d_2140.dc.conv2d.2"(#loc536))
#loc1137 = loc("conv2d_2140.dc.transpose.3"(#loc536))
#loc1138 = loc("conv2d_2140.dc.transpose.4"(#loc536))
#loc1139 = loc("conv2d_2155.dc.transpose.0"(#loc538))
#loc1140 = loc("conv2d_2155.dc.transpose.1"(#loc538))
#loc1141 = loc("conv2d_2155.dc.conv2d.4"(#loc538))
#loc1142 = loc("conv2d_2155.dc.transpose.5"(#loc538))
#loc1143 = loc("conv2d_2155.dc.transpose.6"(#loc538))
#loc1144 = loc("conv2d_222.dc.transpose.0"(#loc605))
#loc1145 = loc("conv2d_222.dc.transpose.1"(#loc605))
#loc1146 = loc("conv2d_222.dc.conv2d.2"(#loc605))
#loc1147 = loc("conv2d_222.dc.transpose.3"(#loc605))
#loc1148 = loc("conv2d_222.dc.transpose.4"(#loc605))
#loc1149 = loc("add_235"(#loc606))
#loc1150 = loc("greater_236"(#loc606))
#loc1151 = loc("exp_238"(#loc606))
#loc1152 = loc("add_239"(#loc606))
#loc1153 = loc("log_240"(#loc606))
#loc1154 = loc("where_241"(#loc606))
#loc1155 = loc("tanh_242"(#loc606))
#loc1156 = loc("multiply_243"(#loc606))
#loc1157 = loc("conv2d_244.dc.transpose.0"(#loc607))
#loc1158 = loc("conv2d_244.dc.transpose.1"(#loc607))
#loc1159 = loc("conv2d_244.dc.conv2d.2"(#loc607))
#loc1160 = loc("conv2d_244.dc.transpose.3"(#loc607))
#loc1161 = loc("conv2d_244.dc.transpose.4"(#loc607))
#loc1162 = loc("conv2d_267.dc.transpose.0"(#loc617))
#loc1163 = loc("conv2d_267.dc.transpose.1"(#loc617))
#loc1164 = loc("conv2d_267.dc.conv2d.2"(#loc617))
#loc1165 = loc("conv2d_267.dc.transpose.3"(#loc617))
#loc1166 = loc("conv2d_267.dc.transpose.4"(#loc617))
#loc1167 = loc("add_280"(#loc618))
#loc1168 = loc("greater_281"(#loc618))
#loc1169 = loc("exp_283"(#loc618))
#loc1170 = loc("add_284"(#loc618))
#loc1171 = loc("log_285"(#loc618))
#loc1172 = loc("where_286"(#loc618))
#loc1173 = loc("tanh_287"(#loc618))
#loc1174 = loc("multiply_288"(#loc618))
#loc1175 = loc("conv2d_289.dc.transpose.0"(#loc619))
#loc1176 = loc("conv2d_289.dc.transpose.1"(#loc619))
#loc1177 = loc("conv2d_289.dc.conv2d.2"(#loc619))
#loc1178 = loc("conv2d_289.dc.transpose.3"(#loc619))
#loc1179 = loc("conv2d_289.dc.transpose.4"(#loc619))
#loc1180 = loc("conv2d_423.dc.transpose.0"(#loc662))
#loc1181 = loc("conv2d_423.dc.transpose.1"(#loc662))
#loc1182 = loc("conv2d_423.dc.conv2d.2"(#loc662))
#loc1183 = loc("conv2d_423.dc.transpose.3"(#loc662))
#loc1184 = loc("conv2d_423.dc.transpose.4"(#loc662))
#loc1185 = loc("add_436"(#loc663))
#loc1186 = loc("greater_437"(#loc663))
#loc1187 = loc("exp_439"(#loc663))
#loc1188 = loc("add_440"(#loc663))
#loc1189 = loc("log_441"(#loc663))
#loc1190 = loc("where_442"(#loc663))
#loc1191 = loc("tanh_443"(#loc663))
#loc1192 = loc("multiply_444"(#loc663))
#loc1193 = loc("conv2d_445.dc.transpose.0"(#loc664))
#loc1194 = loc("conv2d_445.dc.transpose.1"(#loc664))
#loc1195 = loc("conv2d_445.dc.conv2d.2"(#loc664))
#loc1196 = loc("conv2d_445.dc.transpose.3"(#loc664))
#loc1197 = loc("conv2d_445.dc.transpose.4"(#loc664))
#loc1198 = loc("conv2d_468.dc.transpose.0"(#loc662))
#loc1199 = loc("conv2d_468.dc.transpose.1"(#loc662))
#loc1200 = loc("conv2d_468.dc.conv2d.2"(#loc662))
#loc1201 = loc("conv2d_468.dc.transpose.3"(#loc662))
#loc1202 = loc("conv2d_468.dc.transpose.4"(#loc662))
#loc1203 = loc("add_481"(#loc663))
#loc1204 = loc("greater_482"(#loc663))
#loc1205 = loc("exp_484"(#loc663))
#loc1206 = loc("add_485"(#loc663))
#loc1207 = loc("log_486"(#loc663))
#loc1208 = loc("where_487"(#loc663))
#loc1209 = loc("tanh_488"(#loc663))
#loc1210 = loc("multiply_489"(#loc663))
#loc1211 = loc("conv2d_490.dc.transpose.0"(#loc664))
#loc1212 = loc("conv2d_490.dc.transpose.1"(#loc664))
#loc1213 = loc("conv2d_490.dc.conv2d.2"(#loc664))
#loc1214 = loc("conv2d_490.dc.transpose.3"(#loc664))
#loc1215 = loc("conv2d_490.dc.transpose.4"(#loc664))
#loc1216 = loc("conv2d_513.dc.transpose.0"(#loc662))
#loc1217 = loc("conv2d_513.dc.transpose.1"(#loc662))
#loc1218 = loc("conv2d_513.dc.conv2d.2"(#loc662))
#loc1219 = loc("conv2d_513.dc.transpose.3"(#loc662))
#loc1220 = loc("conv2d_513.dc.transpose.4"(#loc662))
#loc1221 = loc("add_526"(#loc663))
#loc1222 = loc("greater_527"(#loc663))
#loc1223 = loc("exp_529"(#loc663))
#loc1224 = loc("add_530"(#loc663))
#loc1225 = loc("log_531"(#loc663))
#loc1226 = loc("where_532"(#loc663))
#loc1227 = loc("tanh_533"(#loc663))
#loc1228 = loc("multiply_534"(#loc663))
#loc1229 = loc("conv2d_535.dc.transpose.0"(#loc664))
#loc1230 = loc("conv2d_535.dc.transpose.1"(#loc664))
#loc1231 = loc("conv2d_535.dc.conv2d.2"(#loc664))
#loc1232 = loc("conv2d_535.dc.transpose.3"(#loc664))
#loc1233 = loc("conv2d_535.dc.transpose.4"(#loc664))
#loc1234 = loc("conv2d_558.dc.transpose.0"(#loc662))
#loc1235 = loc("conv2d_558.dc.transpose.1"(#loc662))
#loc1236 = loc("conv2d_558.dc.conv2d.2"(#loc662))
#loc1237 = loc("conv2d_558.dc.transpose.3"(#loc662))
#loc1238 = loc("conv2d_558.dc.transpose.4"(#loc662))
#loc1239 = loc("add_571"(#loc663))
#loc1240 = loc("greater_572"(#loc663))
#loc1241 = loc("exp_574"(#loc663))
#loc1242 = loc("add_575"(#loc663))
#loc1243 = loc("log_576"(#loc663))
#loc1244 = loc("where_577"(#loc663))
#loc1245 = loc("tanh_578"(#loc663))
#loc1246 = loc("multiply_579"(#loc663))
#loc1247 = loc("conv2d_580.dc.transpose.0"(#loc664))
#loc1248 = loc("conv2d_580.dc.transpose.1"(#loc664))
#loc1249 = loc("conv2d_580.dc.conv2d.2"(#loc664))
#loc1250 = loc("conv2d_580.dc.transpose.3"(#loc664))
#loc1251 = loc("conv2d_580.dc.transpose.4"(#loc664))
#loc1252 = loc("conv2d_603.dc.transpose.0"(#loc662))
#loc1253 = loc("conv2d_603.dc.transpose.1"(#loc662))
#loc1254 = loc("conv2d_603.dc.conv2d.2"(#loc662))
#loc1255 = loc("conv2d_603.dc.transpose.3"(#loc662))
#loc1256 = loc("conv2d_603.dc.transpose.4"(#loc662))
#loc1257 = loc("add_616"(#loc663))
#loc1258 = loc("greater_617"(#loc663))
#loc1259 = loc("exp_619"(#loc663))
#loc1260 = loc("add_620"(#loc663))
#loc1261 = loc("log_621"(#loc663))
#loc1262 = loc("where_622"(#loc663))
#loc1263 = loc("tanh_623"(#loc663))
#loc1264 = loc("multiply_624"(#loc663))
#loc1265 = loc("conv2d_625.dc.transpose.0"(#loc664))
#loc1266 = loc("conv2d_625.dc.transpose.1"(#loc664))
#loc1267 = loc("conv2d_625.dc.conv2d.2"(#loc664))
#loc1268 = loc("conv2d_625.dc.transpose.3"(#loc664))
#loc1269 = loc("conv2d_625.dc.transpose.4"(#loc664))
#loc1270 = loc("conv2d_648.dc.transpose.0"(#loc662))
#loc1271 = loc("conv2d_648.dc.transpose.1"(#loc662))
#loc1272 = loc("conv2d_648.dc.conv2d.2"(#loc662))
#loc1273 = loc("conv2d_648.dc.transpose.3"(#loc662))
#loc1274 = loc("conv2d_648.dc.transpose.4"(#loc662))
#loc1275 = loc("add_661"(#loc663))
#loc1276 = loc("greater_662"(#loc663))
#loc1277 = loc("exp_664"(#loc663))
#loc1278 = loc("add_665"(#loc663))
#loc1279 = loc("log_666"(#loc663))
#loc1280 = loc("where_667"(#loc663))
#loc1281 = loc("tanh_668"(#loc663))
#loc1282 = loc("multiply_669"(#loc663))
#loc1283 = loc("conv2d_670.dc.transpose.0"(#loc664))
#loc1284 = loc("conv2d_670.dc.transpose.1"(#loc664))
#loc1285 = loc("conv2d_670.dc.conv2d.2"(#loc664))
#loc1286 = loc("conv2d_670.dc.transpose.3"(#loc664))
#loc1287 = loc("conv2d_670.dc.transpose.4"(#loc664))
#loc1288 = loc("conv2d_693.dc.transpose.0"(#loc662))
#loc1289 = loc("conv2d_693.dc.transpose.1"(#loc662))
#loc1290 = loc("conv2d_693.dc.conv2d.2"(#loc662))
#loc1291 = loc("conv2d_693.dc.transpose.3"(#loc662))
#loc1292 = loc("conv2d_693.dc.transpose.4"(#loc662))
#loc1293 = loc("add_706"(#loc663))
#loc1294 = loc("greater_707"(#loc663))
#loc1295 = loc("exp_709"(#loc663))
#loc1296 = loc("add_710"(#loc663))
#loc1297 = loc("log_711"(#loc663))
#loc1298 = loc("where_712"(#loc663))
#loc1299 = loc("tanh_713"(#loc663))
#loc1300 = loc("multiply_714"(#loc663))
#loc1301 = loc("conv2d_715.dc.transpose.0"(#loc664))
#loc1302 = loc("conv2d_715.dc.transpose.1"(#loc664))
#loc1303 = loc("conv2d_715.dc.conv2d.2"(#loc664))
#loc1304 = loc("conv2d_715.dc.transpose.3"(#loc664))
#loc1305 = loc("conv2d_715.dc.transpose.4"(#loc664))
#loc1306 = loc("conv2d_738.dc.transpose.0"(#loc662))
#loc1307 = loc("conv2d_738.dc.transpose.1"(#loc662))
#loc1308 = loc("conv2d_738.dc.conv2d.2"(#loc662))
#loc1309 = loc("conv2d_738.dc.transpose.3"(#loc662))
#loc1310 = loc("conv2d_738.dc.transpose.4"(#loc662))
#loc1311 = loc("add_751"(#loc663))
#loc1312 = loc("greater_752"(#loc663))
#loc1313 = loc("exp_754"(#loc663))
#loc1314 = loc("add_755"(#loc663))
#loc1315 = loc("log_756"(#loc663))
#loc1316 = loc("where_757"(#loc663))
#loc1317 = loc("tanh_758"(#loc663))
#loc1318 = loc("multiply_759"(#loc663))
#loc1319 = loc("conv2d_760.dc.transpose.0"(#loc664))
#loc1320 = loc("conv2d_760.dc.transpose.1"(#loc664))
#loc1321 = loc("conv2d_760.dc.conv2d.2"(#loc664))
#loc1322 = loc("conv2d_760.dc.transpose.3"(#loc664))
#loc1323 = loc("conv2d_760.dc.transpose.4"(#loc664))
#loc1324 = loc("conv2d_909.dc.transpose.0"(#loc775))
#loc1325 = loc("conv2d_909.dc.transpose.1"(#loc775))
#loc1326 = loc("conv2d_909.dc.conv2d.2"(#loc775))
#loc1327 = loc("conv2d_909.dc.transpose.3"(#loc775))
#loc1328 = loc("conv2d_909.dc.transpose.4"(#loc775))
#loc1329 = loc("add_922"(#loc776))
#loc1330 = loc("greater_923"(#loc776))
#loc1331 = loc("exp_925"(#loc776))
#loc1332 = loc("add_926"(#loc776))
#loc1333 = loc("log_927"(#loc776))
#loc1334 = loc("where_928"(#loc776))
#loc1335 = loc("tanh_929"(#loc776))
#loc1336 = loc("multiply_930"(#loc776))
#loc1337 = loc("conv2d_931.dc.transpose.0"(#loc777))
#loc1338 = loc("conv2d_931.dc.transpose.1"(#loc777))
#loc1339 = loc("conv2d_931.dc.conv2d.2"(#loc777))
#loc1340 = loc("conv2d_931.dc.transpose.3"(#loc777))
#loc1341 = loc("conv2d_931.dc.transpose.4"(#loc777))
#loc1342 = loc("conv2d_954.dc.transpose.0"(#loc775))
#loc1343 = loc("conv2d_954.dc.transpose.1"(#loc775))
#loc1344 = loc("conv2d_954.dc.conv2d.2"(#loc775))
#loc1345 = loc("conv2d_954.dc.transpose.3"(#loc775))
#loc1346 = loc("conv2d_954.dc.transpose.4"(#loc775))
#loc1347 = loc("add_967"(#loc776))
#loc1348 = loc("greater_968"(#loc776))
#loc1349 = loc("exp_970"(#loc776))
#loc1350 = loc("add_971"(#loc776))
#loc1351 = loc("log_972"(#loc776))
#loc1352 = loc("where_973"(#loc776))
#loc1353 = loc("tanh_974"(#loc776))
#loc1354 = loc("multiply_975"(#loc776))
#loc1355 = loc("conv2d_976.dc.transpose.0"(#loc777))
#loc1356 = loc("conv2d_976.dc.transpose.1"(#loc777))
#loc1357 = loc("conv2d_976.dc.conv2d.2"(#loc777))
#loc1358 = loc("conv2d_976.dc.transpose.3"(#loc777))
#loc1359 = loc("conv2d_976.dc.transpose.4"(#loc777))
#loc1360 = loc("conv2d_999.dc.transpose.0"(#loc775))
#loc1361 = loc("conv2d_999.dc.transpose.1"(#loc775))
#loc1362 = loc("conv2d_999.dc.conv2d.2"(#loc775))
#loc1363 = loc("conv2d_999.dc.transpose.3"(#loc775))
#loc1364 = loc("conv2d_999.dc.transpose.4"(#loc775))
#loc1365 = loc("add_1012"(#loc776))
#loc1366 = loc("greater_1013"(#loc776))
#loc1367 = loc("exp_1015"(#loc776))
#loc1368 = loc("add_1016"(#loc776))
#loc1369 = loc("log_1017"(#loc776))
#loc1370 = loc("where_1018"(#loc776))
#loc1371 = loc("tanh_1019"(#loc776))
#loc1372 = loc("multiply_1020"(#loc776))
#loc1373 = loc("conv2d_1021.dc.transpose.0"(#loc777))
#loc1374 = loc("conv2d_1021.dc.transpose.1"(#loc777))
#loc1375 = loc("conv2d_1021.dc.conv2d.2"(#loc777))
#loc1376 = loc("conv2d_1021.dc.transpose.3"(#loc777))
#loc1377 = loc("conv2d_1021.dc.transpose.4"(#loc777))
#loc1378 = loc("conv2d_1044.dc.transpose.0"(#loc775))
#loc1379 = loc("conv2d_1044.dc.transpose.1"(#loc775))
#loc1380 = loc("conv2d_1044.dc.conv2d.2"(#loc775))
#loc1381 = loc("conv2d_1044.dc.transpose.3"(#loc775))
#loc1382 = loc("conv2d_1044.dc.transpose.4"(#loc775))
#loc1383 = loc("add_1057"(#loc776))
#loc1384 = loc("greater_1058"(#loc776))
#loc1385 = loc("exp_1060"(#loc776))
#loc1386 = loc("add_1061"(#loc776))
#loc1387 = loc("log_1062"(#loc776))
#loc1388 = loc("where_1063"(#loc776))
#loc1389 = loc("tanh_1064"(#loc776))
#loc1390 = loc("multiply_1065"(#loc776))
#loc1391 = loc("conv2d_1066.dc.transpose.0"(#loc777))
#loc1392 = loc("conv2d_1066.dc.transpose.1"(#loc777))
#loc1393 = loc("conv2d_1066.dc.conv2d.2"(#loc777))
#loc1394 = loc("conv2d_1066.dc.transpose.3"(#loc777))
#loc1395 = loc("conv2d_1066.dc.transpose.4"(#loc777))
#loc1396 = loc("conv2d_1089.dc.transpose.0"(#loc775))
#loc1397 = loc("conv2d_1089.dc.transpose.1"(#loc775))
#loc1398 = loc("conv2d_1089.dc.conv2d.2"(#loc775))
#loc1399 = loc("conv2d_1089.dc.transpose.3"(#loc775))
#loc1400 = loc("conv2d_1089.dc.transpose.4"(#loc775))
#loc1401 = loc("add_1102"(#loc776))
#loc1402 = loc("greater_1103"(#loc776))
#loc1403 = loc("exp_1105"(#loc776))
#loc1404 = loc("add_1106"(#loc776))
#loc1405 = loc("log_1107"(#loc776))
#loc1406 = loc("where_1108"(#loc776))
#loc1407 = loc("tanh_1109"(#loc776))
#loc1408 = loc("multiply_1110"(#loc776))
#loc1409 = loc("conv2d_1111.dc.transpose.0"(#loc777))
#loc1410 = loc("conv2d_1111.dc.transpose.1"(#loc777))
#loc1411 = loc("conv2d_1111.dc.conv2d.2"(#loc777))
#loc1412 = loc("conv2d_1111.dc.transpose.3"(#loc777))
#loc1413 = loc("conv2d_1111.dc.transpose.4"(#loc777))
#loc1414 = loc("conv2d_1134.dc.transpose.0"(#loc775))
#loc1415 = loc("conv2d_1134.dc.transpose.1"(#loc775))
#loc1416 = loc("conv2d_1134.dc.conv2d.2"(#loc775))
#loc1417 = loc("conv2d_1134.dc.transpose.3"(#loc775))
#loc1418 = loc("conv2d_1134.dc.transpose.4"(#loc775))
#loc1419 = loc("add_1147"(#loc776))
#loc1420 = loc("greater_1148"(#loc776))
#loc1421 = loc("exp_1150"(#loc776))
#loc1422 = loc("add_1151"(#loc776))
#loc1423 = loc("log_1152"(#loc776))
#loc1424 = loc("where_1153"(#loc776))
#loc1425 = loc("tanh_1154"(#loc776))
#loc1426 = loc("multiply_1155"(#loc776))
#loc1427 = loc("conv2d_1156.dc.transpose.0"(#loc777))
#loc1428 = loc("conv2d_1156.dc.transpose.1"(#loc777))
#loc1429 = loc("conv2d_1156.dc.conv2d.2"(#loc777))
#loc1430 = loc("conv2d_1156.dc.transpose.3"(#loc777))
#loc1431 = loc("conv2d_1156.dc.transpose.4"(#loc777))
#loc1432 = loc("conv2d_1179.dc.transpose.0"(#loc775))
#loc1433 = loc("conv2d_1179.dc.transpose.1"(#loc775))
#loc1434 = loc("conv2d_1179.dc.conv2d.2"(#loc775))
#loc1435 = loc("conv2d_1179.dc.transpose.3"(#loc775))
#loc1436 = loc("conv2d_1179.dc.transpose.4"(#loc775))
#loc1437 = loc("add_1192"(#loc776))
#loc1438 = loc("greater_1193"(#loc776))
#loc1439 = loc("exp_1195"(#loc776))
#loc1440 = loc("add_1196"(#loc776))
#loc1441 = loc("log_1197"(#loc776))
#loc1442 = loc("where_1198"(#loc776))
#loc1443 = loc("tanh_1199"(#loc776))
#loc1444 = loc("multiply_1200"(#loc776))
#loc1445 = loc("conv2d_1201.dc.transpose.0"(#loc777))
#loc1446 = loc("conv2d_1201.dc.transpose.1"(#loc777))
#loc1447 = loc("conv2d_1201.dc.conv2d.2"(#loc777))
#loc1448 = loc("conv2d_1201.dc.transpose.3"(#loc777))
#loc1449 = loc("conv2d_1201.dc.transpose.4"(#loc777))
#loc1450 = loc("conv2d_1224.dc.transpose.0"(#loc775))
#loc1451 = loc("conv2d_1224.dc.transpose.1"(#loc775))
#loc1452 = loc("conv2d_1224.dc.conv2d.2"(#loc775))
#loc1453 = loc("conv2d_1224.dc.transpose.3"(#loc775))
#loc1454 = loc("conv2d_1224.dc.transpose.4"(#loc775))
#loc1455 = loc("add_1237"(#loc776))
#loc1456 = loc("greater_1238"(#loc776))
#loc1457 = loc("exp_1240"(#loc776))
#loc1458 = loc("add_1241"(#loc776))
#loc1459 = loc("log_1242"(#loc776))
#loc1460 = loc("where_1243"(#loc776))
#loc1461 = loc("tanh_1244"(#loc776))
#loc1462 = loc("multiply_1245"(#loc776))
#loc1463 = loc("conv2d_1246.dc.transpose.0"(#loc777))
#loc1464 = loc("conv2d_1246.dc.transpose.1"(#loc777))
#loc1465 = loc("conv2d_1246.dc.conv2d.2"(#loc777))
#loc1466 = loc("conv2d_1246.dc.transpose.3"(#loc777))
#loc1467 = loc("conv2d_1246.dc.transpose.4"(#loc777))
#loc1468 = loc("conv2d_1395.dc.transpose.0"(#loc888))
#loc1469 = loc("conv2d_1395.dc.transpose.1"(#loc888))
#loc1470 = loc("conv2d_1395.dc.conv2d.2"(#loc888))
#loc1471 = loc("conv2d_1395.dc.transpose.3"(#loc888))
#loc1472 = loc("conv2d_1395.dc.transpose.4"(#loc888))
#loc1473 = loc("add_1408"(#loc889))
#loc1474 = loc("greater_1409"(#loc889))
#loc1475 = loc("exp_1411"(#loc889))
#loc1476 = loc("add_1412"(#loc889))
#loc1477 = loc("log_1413"(#loc889))
#loc1478 = loc("where_1414"(#loc889))
#loc1479 = loc("tanh_1415"(#loc889))
#loc1480 = loc("multiply_1416"(#loc889))
#loc1481 = loc("conv2d_1417.dc.transpose.0"(#loc890))
#loc1482 = loc("conv2d_1417.dc.transpose.1"(#loc890))
#loc1483 = loc("conv2d_1417.dc.conv2d.2"(#loc890))
#loc1484 = loc("conv2d_1417.dc.transpose.3"(#loc890))
#loc1485 = loc("conv2d_1417.dc.transpose.4"(#loc890))
#loc1486 = loc("conv2d_1440.dc.transpose.0"(#loc888))
#loc1487 = loc("conv2d_1440.dc.transpose.1"(#loc888))
#loc1488 = loc("conv2d_1440.dc.conv2d.2"(#loc888))
#loc1489 = loc("conv2d_1440.dc.transpose.3"(#loc888))
#loc1490 = loc("conv2d_1440.dc.transpose.4"(#loc888))
#loc1491 = loc("add_1453"(#loc889))
#loc1492 = loc("greater_1454"(#loc889))
#loc1493 = loc("exp_1456"(#loc889))
#loc1494 = loc("add_1457"(#loc889))
#loc1495 = loc("log_1458"(#loc889))
#loc1496 = loc("where_1459"(#loc889))
#loc1497 = loc("tanh_1460"(#loc889))
#loc1498 = loc("multiply_1461"(#loc889))
#loc1499 = loc("conv2d_1462.dc.transpose.0"(#loc890))
#loc1500 = loc("conv2d_1462.dc.transpose.1"(#loc890))
#loc1501 = loc("conv2d_1462.dc.conv2d.2"(#loc890))
#loc1502 = loc("conv2d_1462.dc.transpose.3"(#loc890))
#loc1503 = loc("conv2d_1462.dc.transpose.4"(#loc890))
#loc1504 = loc("conv2d_1485.dc.transpose.0"(#loc888))
#loc1505 = loc("conv2d_1485.dc.transpose.1"(#loc888))
#loc1506 = loc("conv2d_1485.dc.conv2d.2"(#loc888))
#loc1507 = loc("conv2d_1485.dc.transpose.3"(#loc888))
#loc1508 = loc("conv2d_1485.dc.transpose.4"(#loc888))
#loc1509 = loc("add_1498"(#loc889))
#loc1510 = loc("greater_1499"(#loc889))
#loc1511 = loc("exp_1501"(#loc889))
#loc1512 = loc("add_1502"(#loc889))
#loc1513 = loc("log_1503"(#loc889))
#loc1514 = loc("where_1504"(#loc889))
#loc1515 = loc("tanh_1505"(#loc889))
#loc1516 = loc("multiply_1506"(#loc889))
#loc1517 = loc("conv2d_1507.dc.transpose.0"(#loc890))
#loc1518 = loc("conv2d_1507.dc.transpose.1"(#loc890))
#loc1519 = loc("conv2d_1507.dc.conv2d.2"(#loc890))
#loc1520 = loc("conv2d_1507.dc.transpose.3"(#loc890))
#loc1521 = loc("conv2d_1507.dc.transpose.4"(#loc890))
#loc1522 = loc("conv2d_1530.dc.transpose.0"(#loc888))
#loc1523 = loc("conv2d_1530.dc.transpose.1"(#loc888))
#loc1524 = loc("conv2d_1530.dc.conv2d.2"(#loc888))
#loc1525 = loc("conv2d_1530.dc.transpose.3"(#loc888))
#loc1526 = loc("conv2d_1530.dc.transpose.4"(#loc888))
#loc1527 = loc("add_1543"(#loc889))
#loc1528 = loc("greater_1544"(#loc889))
#loc1529 = loc("exp_1546"(#loc889))
#loc1530 = loc("add_1547"(#loc889))
#loc1531 = loc("log_1548"(#loc889))
#loc1532 = loc("where_1549"(#loc889))
#loc1533 = loc("tanh_1550"(#loc889))
#loc1534 = loc("multiply_1551"(#loc889))
#loc1535 = loc("conv2d_1552.dc.transpose.0"(#loc890))
#loc1536 = loc("conv2d_1552.dc.transpose.1"(#loc890))
#loc1537 = loc("conv2d_1552.dc.conv2d.2"(#loc890))
#loc1538 = loc("conv2d_1552.dc.transpose.3"(#loc890))
#loc1539 = loc("conv2d_1552.dc.transpose.4"(#loc890))
