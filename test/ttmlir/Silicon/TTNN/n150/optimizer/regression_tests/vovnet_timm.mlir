// REQUIRES: opmodel, regression
// RUN: ttmlir-opt --ttir-to-ttnn-backend-pipeline="system-desc-path=%system_desc_path% enable-optimizer=true memory-layout-analysis-enabled=false enable-fusing-pass=true" -o vovnet_timm_ttnn.mlir %s
// RUN: ttmlir-translate --ttnn-to-flatbuffer vovnet_timm_ttnn.mlir > %t.ttnn
#loc = loc("VovnetTimm":0:0)
module @VovnetTimm {
  func.func @forward(%arg0: tensor<8x3x224x224xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "input_1"} loc("VovnetTimm":0:0), %arg1: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3"} loc("VovnetTimm":0:0), %arg2: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_3_fork_clone635"} loc("VovnetTimm":0:0), %arg3: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_20"} loc("VovnetTimm":0:0), %arg4: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_20_fork_clone598"} loc("VovnetTimm":0:0), %arg5: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_37"} loc("VovnetTimm":0:0), %arg6: tensor<1x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_37_fork_clone510"} loc("VovnetTimm":0:0), %arg7: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_52"} loc("VovnetTimm":0:0), %arg8: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_52_fork_clone601"} loc("VovnetTimm":0:0), %arg9: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_69"} loc("VovnetTimm":0:0), %arg10: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_69_fork_clone515"} loc("VovnetTimm":0:0), %arg11: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_86"} loc("VovnetTimm":0:0), %arg12: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_86_fork_clone519"} loc("VovnetTimm":0:0), %arg13: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_103"} loc("VovnetTimm":0:0), %arg14: tensor<1x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_103_fork_clone523"} loc("VovnetTimm":0:0), %arg15: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_119"} loc("VovnetTimm":0:0), %arg16: tensor<1x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_119_fork_clone413"} loc("VovnetTimm":0:0), %arg17: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_137"} loc("VovnetTimm":0:0), %arg18: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_divide_139"} loc("VovnetTimm":0:0), %arg19: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_145"} loc("VovnetTimm":0:0), %arg20: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_145_fork_clone484"} loc("VovnetTimm":0:0), %arg21: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_162"} loc("VovnetTimm":0:0), %arg22: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_162_fork_clone374"} loc("VovnetTimm":0:0), %arg23: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_179"} loc("VovnetTimm":0:0), %arg24: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_179_fork_clone378"} loc("VovnetTimm":0:0), %arg25: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_196"} loc("VovnetTimm":0:0), %arg26: tensor<1x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_196_fork_clone382"} loc("VovnetTimm":0:0), %arg27: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_212"} loc("VovnetTimm":0:0), %arg28: tensor<1x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_212_fork_clone273"} loc("VovnetTimm":0:0), %arg29: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_230"} loc("VovnetTimm":0:0), %arg30: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_divide_232"} loc("VovnetTimm":0:0), %arg31: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_238"} loc("VovnetTimm":0:0), %arg32: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_238_fork_clone344"} loc("VovnetTimm":0:0), %arg33: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_255"} loc("VovnetTimm":0:0), %arg34: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_255_fork_clone234"} loc("VovnetTimm":0:0), %arg35: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_272"} loc("VovnetTimm":0:0), %arg36: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_272_fork_clone238"} loc("VovnetTimm":0:0), %arg37: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_289"} loc("VovnetTimm":0:0), %arg38: tensor<1x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_289_fork_clone242"} loc("VovnetTimm":0:0), %arg39: tensor<1x768x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_305"} loc("VovnetTimm":0:0), %arg40: tensor<1x768x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_305_fork_clone135"} loc("VovnetTimm":0:0), %arg41: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_323"} loc("VovnetTimm":0:0), %arg42: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_divide_325"} loc("VovnetTimm":0:0), %arg43: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_331"} loc("VovnetTimm":0:0), %arg44: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_331_fork_clone204"} loc("VovnetTimm":0:0), %arg45: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_348"} loc("VovnetTimm":0:0), %arg46: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_348_fork_clone101"} loc("VovnetTimm":0:0), %arg47: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_365"} loc("VovnetTimm":0:0), %arg48: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_365_fork_clone105"} loc("VovnetTimm":0:0), %arg49: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_382"} loc("VovnetTimm":0:0), %arg50: tensor<1x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_382_fork_clone109"} loc("VovnetTimm":0:0), %arg51: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_398"} loc("VovnetTimm":0:0), %arg52: tensor<1x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_0_divide_398_fork_clone37"} loc("VovnetTimm":0:0), %arg53: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_add_416"} loc("VovnetTimm":0:0), %arg54: tensor<1xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "input_1_divide_418"} loc("VovnetTimm":0:0), %arg55: tensor<64x3x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stem.0.conv.weight"} loc("VovnetTimm":0:0), %arg56: tensor<64x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stem.1.conv_dw.weight"} loc("VovnetTimm":0:0), %arg57: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stem.1.conv_pw.weight"} loc("VovnetTimm":0:0), %arg58: tensor<64x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stem.2.conv_dw.weight"} loc("VovnetTimm":0:0), %arg59: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stem.2.conv_pw.weight"} loc("VovnetTimm":0:0), %arg60: tensor<128x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_reduction.conv.weight"} loc("VovnetTimm":0:0), %arg61: tensor<128x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.0.conv_dw.weight"} loc("VovnetTimm":0:0), %arg62: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.0.conv_pw.weight"} loc("VovnetTimm":0:0), %arg63: tensor<128x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.1.conv_dw.weight"} loc("VovnetTimm":0:0), %arg64: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.1.conv_pw.weight"} loc("VovnetTimm":0:0), %arg65: tensor<128x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.2.conv_dw.weight"} loc("VovnetTimm":0:0), %arg66: tensor<128x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_mid.2.conv_pw.weight"} loc("VovnetTimm":0:0), %arg67: tensor<256x448x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.conv_concat.conv.weight"} loc("VovnetTimm":0:0), %arg68: tensor<256x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.attn.fc.weight"} loc("VovnetTimm":0:0), %arg69: tensor<1x1x1x256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.0.blocks.0.attn.fc.bias"} loc("VovnetTimm":0:0), %arg70: tensor<160x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_reduction.conv.weight"} loc("VovnetTimm":0:0), %arg71: tensor<160x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.0.conv_dw.weight"} loc("VovnetTimm":0:0), %arg72: tensor<160x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.0.conv_pw.weight"} loc("VovnetTimm":0:0), %arg73: tensor<160x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.1.conv_dw.weight"} loc("VovnetTimm":0:0), %arg74: tensor<160x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.1.conv_pw.weight"} loc("VovnetTimm":0:0), %arg75: tensor<160x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.2.conv_dw.weight"} loc("VovnetTimm":0:0), %arg76: tensor<160x160x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_mid.2.conv_pw.weight"} loc("VovnetTimm":0:0), %arg77: tensor<512x736x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.conv_concat.conv.weight"} loc("VovnetTimm":0:0), %arg78: tensor<512x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.attn.fc.weight"} loc("VovnetTimm":0:0), %arg79: tensor<1x1x1x512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.1.blocks.0.attn.fc.bias"} loc("VovnetTimm":0:0), %arg80: tensor<192x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_reduction.conv.weight"} loc("VovnetTimm":0:0), %arg81: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.0.conv_dw.weight"} loc("VovnetTimm":0:0), %arg82: tensor<192x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.0.conv_pw.weight"} loc("VovnetTimm":0:0), %arg83: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.1.conv_dw.weight"} loc("VovnetTimm":0:0), %arg84: tensor<192x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.1.conv_pw.weight"} loc("VovnetTimm":0:0), %arg85: tensor<192x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.2.conv_dw.weight"} loc("VovnetTimm":0:0), %arg86: tensor<192x192x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_mid.2.conv_pw.weight"} loc("VovnetTimm":0:0), %arg87: tensor<768x1088x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.conv_concat.conv.weight"} loc("VovnetTimm":0:0), %arg88: tensor<768x768x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.attn.fc.weight"} loc("VovnetTimm":0:0), %arg89: tensor<1x1x1x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.2.blocks.0.attn.fc.bias"} loc("VovnetTimm":0:0), %arg90: tensor<224x768x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_reduction.conv.weight"} loc("VovnetTimm":0:0), %arg91: tensor<224x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.0.conv_dw.weight"} loc("VovnetTimm":0:0), %arg92: tensor<224x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.0.conv_pw.weight"} loc("VovnetTimm":0:0), %arg93: tensor<224x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.1.conv_dw.weight"} loc("VovnetTimm":0:0), %arg94: tensor<224x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.1.conv_pw.weight"} loc("VovnetTimm":0:0), %arg95: tensor<224x1x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.2.conv_dw.weight"} loc("VovnetTimm":0:0), %arg96: tensor<224x224x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_mid.2.conv_pw.weight"} loc("VovnetTimm":0:0), %arg97: tensor<1024x1440x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.conv_concat.conv.weight"} loc("VovnetTimm":0:0), %arg98: tensor<1024x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.attn.fc.weight"} loc("VovnetTimm":0:0), %arg99: tensor<1x1x1x1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "stages.3.blocks.0.attn.fc.bias"} loc("VovnetTimm":0:0), %arg100: tensor<1024x1000xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "head.fc.weight"} loc("VovnetTimm":0:0), %arg101: tensor<1000xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "head.fc.bias"} loc("VovnetTimm":0:0)) -> (tensor<8x1000xbf16> {ttir.name = "VovnetTimm.output_add_427"}) {
    %0 = ttir.empty() : tensor<8x224x3x224xbf16> loc(#loc85)
    %1 = "ttir.transpose"(%arg0, %0) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x3x224x224xbf16>, tensor<8x224x3x224xbf16>) -> tensor<8x224x3x224xbf16> loc(#loc85)
    %2 = ttir.empty() : tensor<8x224x224x3xbf16> loc(#loc86)
    %3 = "ttir.transpose"(%1, %2) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x224x3x224xbf16>, tensor<8x224x224x3xbf16>) -> tensor<8x224x224x3xbf16> loc(#loc86)
    %4 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc87)
    %5 = "ttir.conv2d"(%3, %arg55, %4) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x224x224x3xbf16>, tensor<64x3x3x3xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc87)
    %6 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc88)
    %7 = "ttir.transpose"(%5, %6) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x64xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc88)
    %8 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc89)
    %9 = "ttir.transpose"(%7, %8) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc89)
    %10 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc2)
    %11 = "ttir.multiply"(%9, %arg1, %10) : (tensor<8x64x112x112xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc2)
    %12 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc3)
    %13 = "ttir.add"(%11, %arg2, %12) : (tensor<8x64x112x112xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc3)
    %14 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc138)
    %15 = "ttir.relu"(%13, %14) : (tensor<8x64x112x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc138)
    %16 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc91)
    %17 = "ttir.transpose"(%15, %16) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x112x112xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc91)
    %18 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc92)
    %19 = "ttir.transpose"(%17, %18) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc92)
    %20 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc93)
    %21 = "ttir.conv2d"(%19, %arg56, %20) <{dilation = array<i32: 1, 1>, groups = 64 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x112x112x64xbf16>, tensor<64x1x3x3xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc93)
    %22 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc94)
    %23 = "ttir.transpose"(%21, %22) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x64xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc94)
    %24 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc95)
    %25 = "ttir.transpose"(%23, %24) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc95)
    %26 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc96)
    %27 = "ttir.transpose"(%25, %26) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x112x112xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc96)
    %28 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc97)
    %29 = "ttir.transpose"(%27, %28) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc97)
    %30 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc98)
    %31 = "ttir.conv2d"(%29, %arg57, %30) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x112x112x64xbf16>, tensor<64x64x1x1xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc98)
    %32 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc99)
    %33 = "ttir.transpose"(%31, %32) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x112x64xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc99)
    %34 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc100)
    %35 = "ttir.transpose"(%33, %34) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc100)
    %36 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc4)
    %37 = "ttir.multiply"(%35, %arg3, %36) : (tensor<8x64x112x112xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc4)
    %38 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc5)
    %39 = "ttir.add"(%37, %arg4, %38) : (tensor<8x64x112x112xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc5)
    %40 = ttir.empty() : tensor<8x64x112x112xbf16> loc(#loc139)
    %41 = "ttir.relu"(%39, %40) : (tensor<8x64x112x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16> loc(#loc139)
    %42 = ttir.empty() : tensor<8x112x64x112xbf16> loc(#loc102)
    %43 = "ttir.transpose"(%41, %42) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x112x112xbf16>, tensor<8x112x64x112xbf16>) -> tensor<8x112x64x112xbf16> loc(#loc102)
    %44 = ttir.empty() : tensor<8x112x112x64xbf16> loc(#loc103)
    %45 = "ttir.transpose"(%43, %44) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x112x64x112xbf16>, tensor<8x112x112x64xbf16>) -> tensor<8x112x112x64xbf16> loc(#loc103)
    %46 = ttir.empty() : tensor<8x56x56x64xbf16> loc(#loc104)
    %47 = "ttir.conv2d"(%45, %arg58, %46) <{dilation = array<i32: 1, 1>, groups = 64 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>}> {channel_last = 1 : si32} : (tensor<8x112x112x64xbf16>, tensor<64x1x3x3xbf16>, tensor<8x56x56x64xbf16>) -> tensor<8x56x56x64xbf16> loc(#loc104)
    %48 = ttir.empty() : tensor<8x56x64x56xbf16> loc(#loc105)
    %49 = "ttir.transpose"(%47, %48) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x64xbf16>, tensor<8x56x64x56xbf16>) -> tensor<8x56x64x56xbf16> loc(#loc105)
    %50 = ttir.empty() : tensor<8x64x56x56xbf16> loc(#loc106)
    %51 = "ttir.transpose"(%49, %50) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x64x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16> loc(#loc106)
    %52 = ttir.empty() : tensor<8x56x64x56xbf16> loc(#loc107)
    %53 = "ttir.transpose"(%51, %52) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x56x56xbf16>, tensor<8x56x64x56xbf16>) -> tensor<8x56x64x56xbf16> loc(#loc107)
    %54 = ttir.empty() : tensor<8x56x56x64xbf16> loc(#loc108)
    %55 = "ttir.transpose"(%53, %54) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x64x56xbf16>, tensor<8x56x56x64xbf16>) -> tensor<8x56x56x64xbf16> loc(#loc108)
    %56 = ttir.empty() : tensor<8x56x56x64xbf16> loc(#loc109)
    %57 = "ttir.conv2d"(%55, %arg59, %56) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x64xbf16>, tensor<64x64x1x1xbf16>, tensor<8x56x56x64xbf16>) -> tensor<8x56x56x64xbf16> loc(#loc109)
    %58 = ttir.empty() : tensor<8x56x64x56xbf16> loc(#loc110)
    %59 = "ttir.transpose"(%57, %58) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x64xbf16>, tensor<8x56x64x56xbf16>) -> tensor<8x56x64x56xbf16> loc(#loc110)
    %60 = ttir.empty() : tensor<8x64x56x56xbf16> loc(#loc111)
    %61 = "ttir.transpose"(%59, %60) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x64x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16> loc(#loc111)
    %62 = ttir.empty() : tensor<8x64x56x56xbf16> loc(#loc6)
    %63 = "ttir.multiply"(%61, %arg5, %62) : (tensor<8x64x56x56xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16> loc(#loc6)
    %64 = ttir.empty() : tensor<8x64x56x56xbf16> loc(#loc7)
    %65 = "ttir.add"(%63, %arg6, %64) : (tensor<8x64x56x56xbf16>, tensor<1x64x1x1xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16> loc(#loc7)
    %66 = ttir.empty() : tensor<8x64x56x56xbf16> loc(#loc140)
    %67 = "ttir.relu"(%65, %66) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16> loc(#loc140)
    %68 = ttir.empty() : tensor<8x56x64x56xbf16> loc(#loc205)
    %69 = "ttir.transpose"(%67, %68) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x64x56x56xbf16>, tensor<8x56x64x56xbf16>) -> tensor<8x56x64x56xbf16> loc(#loc205)
    %70 = ttir.empty() : tensor<8x56x56x64xbf16> loc(#loc206)
    %71 = "ttir.transpose"(%69, %70) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x64x56xbf16>, tensor<8x56x56x64xbf16>) -> tensor<8x56x56x64xbf16> loc(#loc206)
    %72 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc207)
    %73 = "ttir.conv2d"(%71, %arg60, %72) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x64xbf16>, tensor<128x64x1x1xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc207)
    %74 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc208)
    %75 = "ttir.transpose"(%73, %74) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc208)
    %76 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc209)
    %77 = "ttir.transpose"(%75, %76) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc209)
    %78 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc8)
    %79 = "ttir.multiply"(%77, %arg7, %78) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc8)
    %80 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc9)
    %81 = "ttir.add"(%79, %arg8, %80) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc9)
    %82 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc321)
    %83 = "ttir.relu"(%81, %82) : (tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc321)
    %84 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc322)
    %85 = "ttir.transpose"(%83, %84) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc322)
    %86 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc323)
    %87 = "ttir.transpose"(%85, %86) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc323)
    %88 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc324)
    %89 = "ttir.conv2d"(%87, %arg61, %88) <{dilation = array<i32: 1, 1>, groups = 128 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x1x3x3xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc324)
    %90 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc325)
    %91 = "ttir.transpose"(%89, %90) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc325)
    %92 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc326)
    %93 = "ttir.transpose"(%91, %92) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc326)
    %94 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc327)
    %95 = "ttir.transpose"(%93, %94) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc327)
    %96 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc328)
    %97 = "ttir.transpose"(%95, %96) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc328)
    %98 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc329)
    %99 = "ttir.conv2d"(%97, %arg62, %98) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x128x1x1xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc329)
    %100 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc330)
    %101 = "ttir.transpose"(%99, %100) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc330)
    %102 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc331)
    %103 = "ttir.transpose"(%101, %102) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc331)
    %104 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc10)
    %105 = "ttir.multiply"(%103, %arg9, %104) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc10)
    %106 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc11)
    %107 = "ttir.add"(%105, %arg10, %106) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc11)
    %108 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc461)
    %109 = "ttir.relu"(%107, %108) : (tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc461)
    %110 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc333)
    %111 = "ttir.transpose"(%109, %110) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc333)
    %112 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc334)
    %113 = "ttir.transpose"(%111, %112) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc334)
    %114 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc335)
    %115 = "ttir.conv2d"(%113, %arg63, %114) <{dilation = array<i32: 1, 1>, groups = 128 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x1x3x3xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc335)
    %116 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc336)
    %117 = "ttir.transpose"(%115, %116) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc336)
    %118 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc337)
    %119 = "ttir.transpose"(%117, %118) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc337)
    %120 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc338)
    %121 = "ttir.transpose"(%119, %120) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc338)
    %122 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc339)
    %123 = "ttir.transpose"(%121, %122) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc339)
    %124 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc340)
    %125 = "ttir.conv2d"(%123, %arg64, %124) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x128x1x1xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc340)
    %126 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc341)
    %127 = "ttir.transpose"(%125, %126) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc341)
    %128 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc342)
    %129 = "ttir.transpose"(%127, %128) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc342)
    %130 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc12)
    %131 = "ttir.multiply"(%129, %arg11, %130) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc12)
    %132 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc13)
    %133 = "ttir.add"(%131, %arg12, %132) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc13)
    %134 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc462)
    %135 = "ttir.relu"(%133, %134) : (tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc462)
    %136 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc344)
    %137 = "ttir.transpose"(%135, %136) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc344)
    %138 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc345)
    %139 = "ttir.transpose"(%137, %138) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc345)
    %140 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc346)
    %141 = "ttir.conv2d"(%139, %arg65, %140) <{dilation = array<i32: 1, 1>, groups = 128 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x1x3x3xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc346)
    %142 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc347)
    %143 = "ttir.transpose"(%141, %142) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc347)
    %144 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc348)
    %145 = "ttir.transpose"(%143, %144) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc348)
    %146 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc349)
    %147 = "ttir.transpose"(%145, %146) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x128x56x56xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc349)
    %148 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc350)
    %149 = "ttir.transpose"(%147, %148) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc350)
    %150 = ttir.empty() : tensor<8x56x56x128xbf16> loc(#loc351)
    %151 = "ttir.conv2d"(%149, %arg66, %150) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x128xbf16>, tensor<128x128x1x1xbf16>, tensor<8x56x56x128xbf16>) -> tensor<8x56x56x128xbf16> loc(#loc351)
    %152 = ttir.empty() : tensor<8x56x128x56xbf16> loc(#loc352)
    %153 = "ttir.transpose"(%151, %152) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x128xbf16>, tensor<8x56x128x56xbf16>) -> tensor<8x56x128x56xbf16> loc(#loc352)
    %154 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc353)
    %155 = "ttir.transpose"(%153, %154) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x128x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc353)
    %156 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc14)
    %157 = "ttir.multiply"(%155, %arg13, %156) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc14)
    %158 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc15)
    %159 = "ttir.add"(%157, %arg14, %158) : (tensor<8x128x56x56xbf16>, tensor<1x128x1x1xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc15)
    %160 = ttir.empty() : tensor<8x128x56x56xbf16> loc(#loc463)
    %161 = "ttir.relu"(%159, %160) : (tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16> loc(#loc463)
    %162 = ttir.empty() : tensor<8x448x56x56xbf16> loc(#loc162)
    %163 = "ttir.concat"(%67, %109, %135, %161, %162) <{dim = -3 : si32}> : (tensor<8x64x56x56xbf16>, tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>, tensor<8x448x56x56xbf16>) -> tensor<8x448x56x56xbf16> loc(#loc162)
    %164 = ttir.empty() : tensor<8x56x448x56xbf16> loc(#loc220)
    %165 = "ttir.transpose"(%163, %164) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x448x56x56xbf16>, tensor<8x56x448x56xbf16>) -> tensor<8x56x448x56xbf16> loc(#loc220)
    %166 = ttir.empty() : tensor<8x56x56x448xbf16> loc(#loc221)
    %167 = "ttir.transpose"(%165, %166) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x448x56xbf16>, tensor<8x56x56x448xbf16>) -> tensor<8x56x56x448xbf16> loc(#loc221)
    %168 = ttir.empty() : tensor<8x56x56x256xbf16> loc(#loc222)
    %169 = "ttir.conv2d"(%167, %arg67, %168) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x56x56x448xbf16>, tensor<256x448x1x1xbf16>, tensor<8x56x56x256xbf16>) -> tensor<8x56x56x256xbf16> loc(#loc222)
    %170 = ttir.empty() : tensor<8x56x256x56xbf16> loc(#loc223)
    %171 = "ttir.transpose"(%169, %170) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x56x256xbf16>, tensor<8x56x256x56xbf16>) -> tensor<8x56x256x56xbf16> loc(#loc223)
    %172 = ttir.empty() : tensor<8x256x56x56xbf16> loc(#loc224)
    %173 = "ttir.transpose"(%171, %172) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x56x256x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16> loc(#loc224)
    %174 = ttir.empty() : tensor<8x256x56x56xbf16> loc(#loc16)
    %175 = "ttir.multiply"(%173, %arg15, %174) : (tensor<8x256x56x56xbf16>, tensor<1x256x1x1xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16> loc(#loc16)
    %176 = ttir.empty() : tensor<8x256x56x56xbf16> loc(#loc17)
    %177 = "ttir.add"(%175, %arg16, %176) : (tensor<8x256x56x56xbf16>, tensor<1x256x1x1xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16> loc(#loc17)
    %178 = ttir.empty() : tensor<8x256x56x56xbf16> loc(#loc355)
    %179 = "ttir.relu"(%177, %178) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16> loc(#loc355)
    %180 = ttir.empty() : tensor<8x256x1x56xbf16> loc(#loc18)
    %181 = "ttir.mean"(%179, %180) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x256x56x56xbf16>, tensor<8x256x1x56xbf16>) -> tensor<8x256x1x56xbf16> loc(#loc18)
    %182 = ttir.empty() : tensor<8x256x1x1xbf16> loc(#loc165)
    %183 = "ttir.mean"(%181, %182) <{dim_arg = [-1 : i32], keep_dim = true}> : (tensor<8x256x1x56xbf16>, tensor<8x256x1x1xbf16>) -> tensor<8x256x1x1xbf16> loc(#loc165)
    %184 = ttir.empty() : tensor<8x1x256x1xbf16> loc(#loc226)
    %185 = "ttir.transpose"(%183, %184) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x256x1x1xbf16>, tensor<8x1x256x1xbf16>) -> tensor<8x1x256x1xbf16> loc(#loc226)
    %186 = ttir.empty() : tensor<8x1x1x256xbf16> loc(#loc227)
    %187 = "ttir.transpose"(%185, %186) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x256x1xbf16>, tensor<8x1x1x256xbf16>) -> tensor<8x1x1x256xbf16> loc(#loc227)
    %188 = ttir.empty() : tensor<8x1x1x256xbf16> loc(#loc228)
    %189 = "ttir.conv2d"(%187, %arg68, %arg69, %188) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x1x1x256xbf16>, tensor<256x256x1x1xbf16>, tensor<1x1x1x256xbf16>, tensor<8x1x1x256xbf16>) -> tensor<8x1x1x256xbf16> loc(#loc228)
    %190 = ttir.empty() : tensor<8x1x256x1xbf16> loc(#loc229)
    %191 = "ttir.transpose"(%189, %190) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x1x256xbf16>, tensor<8x1x256x1xbf16>) -> tensor<8x1x256x1xbf16> loc(#loc229)
    %192 = ttir.empty() : tensor<8x256x1x1xbf16> loc(#loc230)
    %193 = "ttir.transpose"(%191, %192) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1x256x1xbf16>, tensor<8x256x1x1xbf16>) -> tensor<8x256x1x1xbf16> loc(#loc230)
    %194 = ttir.empty() : tensor<8x256x1x1xbf16> loc(#loc231)
    %195 = "ttir.add"(%193, %arg17, %194) : (tensor<8x256x1x1xbf16>, tensor<1xbf16>, tensor<8x256x1x1xbf16>) -> tensor<8x256x1x1xbf16> loc(#loc231)
    %196 = ttir.empty() : tensor<8x256x1x1xbf16> loc(#loc232)
    %197 = "ttir.clamp_scalar"(%195, %196) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x256x1x1xbf16>, tensor<8x256x1x1xbf16>) -> tensor<8x256x1x1xbf16> loc(#loc232)
    %198 = ttir.empty() : tensor<8x256x1x1xbf16> loc(#loc233)
    %199 = "ttir.div"(%197, %arg18, %198) : (tensor<8x256x1x1xbf16>, tensor<1xbf16>, tensor<8x256x1x1xbf16>) -> tensor<8x256x1x1xbf16> loc(#loc233)
    %200 = ttir.empty() : tensor<8x256x56x56xbf16> loc(#loc168)
    %201 = "ttir.multiply"(%179, %199, %200) : (tensor<8x256x56x56xbf16>, tensor<8x256x1x1xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16> loc(#loc168)
    %202 = ttir.empty() : tensor<8x56x256x56xbf16> loc(#loc114)
    %203 = "ttir.transpose"(%201, %202) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x256x56x56xbf16>, tensor<8x56x256x56xbf16>) -> tensor<8x56x256x56xbf16> loc(#loc114)
    %204 = ttir.empty() : tensor<8x56x56x256xbf16> loc(#loc115)
    %205 = "ttir.transpose"(%203, %204) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x56x256x56xbf16>, tensor<8x56x56x256xbf16>) -> tensor<8x56x56x256xbf16> loc(#loc115)
    %206 = ttir.empty() : tensor<8x28x28x256xbf16> loc(#loc116)
    %207 = "ttir.max_pool2d"(%205, %206) <{ceil_mode = true, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 3 : si32, kernel_width = 3 : si32, padding_bottom = 0 : si32, padding_left = 0 : si32, padding_right = 0 : si32, padding_top = 0 : si32, stride_height = 2 : si32, stride_width = 2 : si32}> {channel_last = true} : (tensor<8x56x56x256xbf16>, tensor<8x28x28x256xbf16>) -> tensor<8x28x28x256xbf16> loc(#loc116)
    %208 = ttir.empty() : tensor<8x28x256x28xbf16> loc(#loc117)
    %209 = "ttir.transpose"(%207, %208) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x256xbf16>, tensor<8x28x256x28xbf16>) -> tensor<8x28x256x28xbf16> loc(#loc117)
    %210 = ttir.empty() : tensor<8x256x28x28xbf16> loc(#loc118)
    %211 = "ttir.transpose"(%209, %210) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x256x28xbf16>, tensor<8x256x28x28xbf16>) -> tensor<8x256x28x28xbf16> loc(#loc118)
    %212 = ttir.empty() : tensor<8x28x256x28xbf16> loc(#loc234)
    %213 = "ttir.transpose"(%211, %212) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x256x28x28xbf16>, tensor<8x28x256x28xbf16>) -> tensor<8x28x256x28xbf16> loc(#loc234)
    %214 = ttir.empty() : tensor<8x28x28x256xbf16> loc(#loc235)
    %215 = "ttir.transpose"(%213, %214) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x256x28xbf16>, tensor<8x28x28x256xbf16>) -> tensor<8x28x28x256xbf16> loc(#loc235)
    %216 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc236)
    %217 = "ttir.conv2d"(%215, %arg70, %216) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x256xbf16>, tensor<160x256x1x1xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc236)
    %218 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc237)
    %219 = "ttir.transpose"(%217, %218) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc237)
    %220 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc238)
    %221 = "ttir.transpose"(%219, %220) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc238)
    %222 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc19)
    %223 = "ttir.multiply"(%221, %arg19, %222) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc19)
    %224 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc20)
    %225 = "ttir.add"(%223, %arg20, %224) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc20)
    %226 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc356)
    %227 = "ttir.relu"(%225, %226) : (tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc356)
    %228 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc357)
    %229 = "ttir.transpose"(%227, %228) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc357)
    %230 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc358)
    %231 = "ttir.transpose"(%229, %230) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc358)
    %232 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc359)
    %233 = "ttir.conv2d"(%231, %arg71, %232) <{dilation = array<i32: 1, 1>, groups = 160 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x1x3x3xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc359)
    %234 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc360)
    %235 = "ttir.transpose"(%233, %234) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc360)
    %236 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc361)
    %237 = "ttir.transpose"(%235, %236) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc361)
    %238 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc362)
    %239 = "ttir.transpose"(%237, %238) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc362)
    %240 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc363)
    %241 = "ttir.transpose"(%239, %240) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc363)
    %242 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc364)
    %243 = "ttir.conv2d"(%241, %arg72, %242) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x160x1x1xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc364)
    %244 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc365)
    %245 = "ttir.transpose"(%243, %244) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc365)
    %246 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc366)
    %247 = "ttir.transpose"(%245, %246) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc366)
    %248 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc21)
    %249 = "ttir.multiply"(%247, %arg21, %248) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc21)
    %250 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc22)
    %251 = "ttir.add"(%249, %arg22, %250) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc22)
    %252 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc464)
    %253 = "ttir.relu"(%251, %252) : (tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc464)
    %254 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc368)
    %255 = "ttir.transpose"(%253, %254) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc368)
    %256 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc369)
    %257 = "ttir.transpose"(%255, %256) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc369)
    %258 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc370)
    %259 = "ttir.conv2d"(%257, %arg73, %258) <{dilation = array<i32: 1, 1>, groups = 160 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x1x3x3xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc370)
    %260 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc371)
    %261 = "ttir.transpose"(%259, %260) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc371)
    %262 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc372)
    %263 = "ttir.transpose"(%261, %262) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc372)
    %264 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc373)
    %265 = "ttir.transpose"(%263, %264) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc373)
    %266 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc374)
    %267 = "ttir.transpose"(%265, %266) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc374)
    %268 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc375)
    %269 = "ttir.conv2d"(%267, %arg74, %268) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x160x1x1xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc375)
    %270 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc376)
    %271 = "ttir.transpose"(%269, %270) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc376)
    %272 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc377)
    %273 = "ttir.transpose"(%271, %272) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc377)
    %274 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc23)
    %275 = "ttir.multiply"(%273, %arg23, %274) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc23)
    %276 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc24)
    %277 = "ttir.add"(%275, %arg24, %276) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc24)
    %278 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc465)
    %279 = "ttir.relu"(%277, %278) : (tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc465)
    %280 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc379)
    %281 = "ttir.transpose"(%279, %280) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc379)
    %282 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc380)
    %283 = "ttir.transpose"(%281, %282) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc380)
    %284 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc381)
    %285 = "ttir.conv2d"(%283, %arg75, %284) <{dilation = array<i32: 1, 1>, groups = 160 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x1x3x3xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc381)
    %286 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc382)
    %287 = "ttir.transpose"(%285, %286) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc382)
    %288 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc383)
    %289 = "ttir.transpose"(%287, %288) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc383)
    %290 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc384)
    %291 = "ttir.transpose"(%289, %290) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x160x28x28xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc384)
    %292 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc385)
    %293 = "ttir.transpose"(%291, %292) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc385)
    %294 = ttir.empty() : tensor<8x28x28x160xbf16> loc(#loc386)
    %295 = "ttir.conv2d"(%293, %arg76, %294) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x160xbf16>, tensor<160x160x1x1xbf16>, tensor<8x28x28x160xbf16>) -> tensor<8x28x28x160xbf16> loc(#loc386)
    %296 = ttir.empty() : tensor<8x28x160x28xbf16> loc(#loc387)
    %297 = "ttir.transpose"(%295, %296) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x160xbf16>, tensor<8x28x160x28xbf16>) -> tensor<8x28x160x28xbf16> loc(#loc387)
    %298 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc388)
    %299 = "ttir.transpose"(%297, %298) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x160x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc388)
    %300 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc25)
    %301 = "ttir.multiply"(%299, %arg25, %300) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc25)
    %302 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc26)
    %303 = "ttir.add"(%301, %arg26, %302) : (tensor<8x160x28x28xbf16>, tensor<1x160x1x1xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc26)
    %304 = ttir.empty() : tensor<8x160x28x28xbf16> loc(#loc466)
    %305 = "ttir.relu"(%303, %304) : (tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>) -> tensor<8x160x28x28xbf16> loc(#loc466)
    %306 = ttir.empty() : tensor<8x736x28x28xbf16> loc(#loc174)
    %307 = "ttir.concat"(%211, %253, %279, %305, %306) <{dim = -3 : si32}> : (tensor<8x256x28x28xbf16>, tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>, tensor<8x160x28x28xbf16>, tensor<8x736x28x28xbf16>) -> tensor<8x736x28x28xbf16> loc(#loc174)
    %308 = ttir.empty() : tensor<8x28x736x28xbf16> loc(#loc249)
    %309 = "ttir.transpose"(%307, %308) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x736x28x28xbf16>, tensor<8x28x736x28xbf16>) -> tensor<8x28x736x28xbf16> loc(#loc249)
    %310 = ttir.empty() : tensor<8x28x28x736xbf16> loc(#loc250)
    %311 = "ttir.transpose"(%309, %310) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x736x28xbf16>, tensor<8x28x28x736xbf16>) -> tensor<8x28x28x736xbf16> loc(#loc250)
    %312 = ttir.empty() : tensor<8x28x28x512xbf16> loc(#loc251)
    %313 = "ttir.conv2d"(%311, %arg77, %312) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x28x28x736xbf16>, tensor<512x736x1x1xbf16>, tensor<8x28x28x512xbf16>) -> tensor<8x28x28x512xbf16> loc(#loc251)
    %314 = ttir.empty() : tensor<8x28x512x28xbf16> loc(#loc252)
    %315 = "ttir.transpose"(%313, %314) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x28x512xbf16>, tensor<8x28x512x28xbf16>) -> tensor<8x28x512x28xbf16> loc(#loc252)
    %316 = ttir.empty() : tensor<8x512x28x28xbf16> loc(#loc253)
    %317 = "ttir.transpose"(%315, %316) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x28x512x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16> loc(#loc253)
    %318 = ttir.empty() : tensor<8x512x28x28xbf16> loc(#loc27)
    %319 = "ttir.multiply"(%317, %arg27, %318) : (tensor<8x512x28x28xbf16>, tensor<1x512x1x1xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16> loc(#loc27)
    %320 = ttir.empty() : tensor<8x512x28x28xbf16> loc(#loc28)
    %321 = "ttir.add"(%319, %arg28, %320) : (tensor<8x512x28x28xbf16>, tensor<1x512x1x1xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16> loc(#loc28)
    %322 = ttir.empty() : tensor<8x512x28x28xbf16> loc(#loc390)
    %323 = "ttir.relu"(%321, %322) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16> loc(#loc390)
    %324 = ttir.empty() : tensor<8x512x1x28xbf16> loc(#loc29)
    %325 = "ttir.mean"(%323, %324) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x512x28x28xbf16>, tensor<8x512x1x28xbf16>) -> tensor<8x512x1x28xbf16> loc(#loc29)
    %326 = ttir.empty() : tensor<8x512x1x1xbf16> loc(#loc177)
    %327 = "ttir.mean"(%325, %326) <{dim_arg = [-1 : i32], keep_dim = true}> : (tensor<8x512x1x28xbf16>, tensor<8x512x1x1xbf16>) -> tensor<8x512x1x1xbf16> loc(#loc177)
    %328 = ttir.empty() : tensor<8x1x512x1xbf16> loc(#loc255)
    %329 = "ttir.transpose"(%327, %328) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x512x1x1xbf16>, tensor<8x1x512x1xbf16>) -> tensor<8x1x512x1xbf16> loc(#loc255)
    %330 = ttir.empty() : tensor<8x1x1x512xbf16> loc(#loc256)
    %331 = "ttir.transpose"(%329, %330) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x512x1xbf16>, tensor<8x1x1x512xbf16>) -> tensor<8x1x1x512xbf16> loc(#loc256)
    %332 = ttir.empty() : tensor<8x1x1x512xbf16> loc(#loc257)
    %333 = "ttir.conv2d"(%331, %arg78, %arg79, %332) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x1x1x512xbf16>, tensor<512x512x1x1xbf16>, tensor<1x1x1x512xbf16>, tensor<8x1x1x512xbf16>) -> tensor<8x1x1x512xbf16> loc(#loc257)
    %334 = ttir.empty() : tensor<8x1x512x1xbf16> loc(#loc258)
    %335 = "ttir.transpose"(%333, %334) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x1x512xbf16>, tensor<8x1x512x1xbf16>) -> tensor<8x1x512x1xbf16> loc(#loc258)
    %336 = ttir.empty() : tensor<8x512x1x1xbf16> loc(#loc259)
    %337 = "ttir.transpose"(%335, %336) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1x512x1xbf16>, tensor<8x512x1x1xbf16>) -> tensor<8x512x1x1xbf16> loc(#loc259)
    %338 = ttir.empty() : tensor<8x512x1x1xbf16> loc(#loc260)
    %339 = "ttir.add"(%337, %arg29, %338) : (tensor<8x512x1x1xbf16>, tensor<1xbf16>, tensor<8x512x1x1xbf16>) -> tensor<8x512x1x1xbf16> loc(#loc260)
    %340 = ttir.empty() : tensor<8x512x1x1xbf16> loc(#loc261)
    %341 = "ttir.clamp_scalar"(%339, %340) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x512x1x1xbf16>, tensor<8x512x1x1xbf16>) -> tensor<8x512x1x1xbf16> loc(#loc261)
    %342 = ttir.empty() : tensor<8x512x1x1xbf16> loc(#loc262)
    %343 = "ttir.div"(%341, %arg30, %342) : (tensor<8x512x1x1xbf16>, tensor<1xbf16>, tensor<8x512x1x1xbf16>) -> tensor<8x512x1x1xbf16> loc(#loc262)
    %344 = ttir.empty() : tensor<8x512x28x28xbf16> loc(#loc180)
    %345 = "ttir.multiply"(%323, %343, %344) : (tensor<8x512x28x28xbf16>, tensor<8x512x1x1xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16> loc(#loc180)
    %346 = ttir.empty() : tensor<8x28x512x28xbf16> loc(#loc120)
    %347 = "ttir.transpose"(%345, %346) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x512x28x28xbf16>, tensor<8x28x512x28xbf16>) -> tensor<8x28x512x28xbf16> loc(#loc120)
    %348 = ttir.empty() : tensor<8x28x28x512xbf16> loc(#loc121)
    %349 = "ttir.transpose"(%347, %348) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x28x512x28xbf16>, tensor<8x28x28x512xbf16>) -> tensor<8x28x28x512xbf16> loc(#loc121)
    %350 = ttir.empty() : tensor<8x14x14x512xbf16> loc(#loc122)
    %351 = "ttir.max_pool2d"(%349, %350) <{ceil_mode = true, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 3 : si32, kernel_width = 3 : si32, padding_bottom = 0 : si32, padding_left = 0 : si32, padding_right = 0 : si32, padding_top = 0 : si32, stride_height = 2 : si32, stride_width = 2 : si32}> {channel_last = true} : (tensor<8x28x28x512xbf16>, tensor<8x14x14x512xbf16>) -> tensor<8x14x14x512xbf16> loc(#loc122)
    %352 = ttir.empty() : tensor<8x14x512x14xbf16> loc(#loc123)
    %353 = "ttir.transpose"(%351, %352) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x512xbf16>, tensor<8x14x512x14xbf16>) -> tensor<8x14x512x14xbf16> loc(#loc123)
    %354 = ttir.empty() : tensor<8x512x14x14xbf16> loc(#loc124)
    %355 = "ttir.transpose"(%353, %354) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x512x14xbf16>, tensor<8x512x14x14xbf16>) -> tensor<8x512x14x14xbf16> loc(#loc124)
    %356 = ttir.empty() : tensor<8x14x512x14xbf16> loc(#loc263)
    %357 = "ttir.transpose"(%355, %356) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x512x14x14xbf16>, tensor<8x14x512x14xbf16>) -> tensor<8x14x512x14xbf16> loc(#loc263)
    %358 = ttir.empty() : tensor<8x14x14x512xbf16> loc(#loc264)
    %359 = "ttir.transpose"(%357, %358) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x512x14xbf16>, tensor<8x14x14x512xbf16>) -> tensor<8x14x14x512xbf16> loc(#loc264)
    %360 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc265)
    %361 = "ttir.conv2d"(%359, %arg80, %360) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x512xbf16>, tensor<192x512x1x1xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc265)
    %362 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc266)
    %363 = "ttir.transpose"(%361, %362) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc266)
    %364 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc267)
    %365 = "ttir.transpose"(%363, %364) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc267)
    %366 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc30)
    %367 = "ttir.multiply"(%365, %arg31, %366) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc30)
    %368 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc31)
    %369 = "ttir.add"(%367, %arg32, %368) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc31)
    %370 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc391)
    %371 = "ttir.relu"(%369, %370) : (tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc391)
    %372 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc392)
    %373 = "ttir.transpose"(%371, %372) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc392)
    %374 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc393)
    %375 = "ttir.transpose"(%373, %374) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc393)
    %376 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc394)
    %377 = "ttir.conv2d"(%375, %arg81, %376) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc394)
    %378 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc395)
    %379 = "ttir.transpose"(%377, %378) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc395)
    %380 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc396)
    %381 = "ttir.transpose"(%379, %380) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc396)
    %382 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc397)
    %383 = "ttir.transpose"(%381, %382) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc397)
    %384 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc398)
    %385 = "ttir.transpose"(%383, %384) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc398)
    %386 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc399)
    %387 = "ttir.conv2d"(%385, %arg82, %386) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x192x1x1xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc399)
    %388 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc400)
    %389 = "ttir.transpose"(%387, %388) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc400)
    %390 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc401)
    %391 = "ttir.transpose"(%389, %390) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc401)
    %392 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc32)
    %393 = "ttir.multiply"(%391, %arg33, %392) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc32)
    %394 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc33)
    %395 = "ttir.add"(%393, %arg34, %394) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc33)
    %396 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc467)
    %397 = "ttir.relu"(%395, %396) : (tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc467)
    %398 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc403)
    %399 = "ttir.transpose"(%397, %398) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc403)
    %400 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc404)
    %401 = "ttir.transpose"(%399, %400) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc404)
    %402 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc405)
    %403 = "ttir.conv2d"(%401, %arg83, %402) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc405)
    %404 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc406)
    %405 = "ttir.transpose"(%403, %404) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc406)
    %406 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc407)
    %407 = "ttir.transpose"(%405, %406) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc407)
    %408 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc408)
    %409 = "ttir.transpose"(%407, %408) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc408)
    %410 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc409)
    %411 = "ttir.transpose"(%409, %410) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc409)
    %412 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc410)
    %413 = "ttir.conv2d"(%411, %arg84, %412) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x192x1x1xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc410)
    %414 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc411)
    %415 = "ttir.transpose"(%413, %414) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc411)
    %416 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc412)
    %417 = "ttir.transpose"(%415, %416) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc412)
    %418 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc34)
    %419 = "ttir.multiply"(%417, %arg35, %418) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc34)
    %420 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc35)
    %421 = "ttir.add"(%419, %arg36, %420) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc35)
    %422 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc468)
    %423 = "ttir.relu"(%421, %422) : (tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc468)
    %424 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc414)
    %425 = "ttir.transpose"(%423, %424) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc414)
    %426 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc415)
    %427 = "ttir.transpose"(%425, %426) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc415)
    %428 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc416)
    %429 = "ttir.conv2d"(%427, %arg85, %428) <{dilation = array<i32: 1, 1>, groups = 192 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x1x3x3xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc416)
    %430 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc417)
    %431 = "ttir.transpose"(%429, %430) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc417)
    %432 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc418)
    %433 = "ttir.transpose"(%431, %432) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc418)
    %434 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc419)
    %435 = "ttir.transpose"(%433, %434) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x192x14x14xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc419)
    %436 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc420)
    %437 = "ttir.transpose"(%435, %436) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc420)
    %438 = ttir.empty() : tensor<8x14x14x192xbf16> loc(#loc421)
    %439 = "ttir.conv2d"(%437, %arg86, %438) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x192xbf16>, tensor<192x192x1x1xbf16>, tensor<8x14x14x192xbf16>) -> tensor<8x14x14x192xbf16> loc(#loc421)
    %440 = ttir.empty() : tensor<8x14x192x14xbf16> loc(#loc422)
    %441 = "ttir.transpose"(%439, %440) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x192xbf16>, tensor<8x14x192x14xbf16>) -> tensor<8x14x192x14xbf16> loc(#loc422)
    %442 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc423)
    %443 = "ttir.transpose"(%441, %442) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x192x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc423)
    %444 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc36)
    %445 = "ttir.multiply"(%443, %arg37, %444) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc36)
    %446 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc37)
    %447 = "ttir.add"(%445, %arg38, %446) : (tensor<8x192x14x14xbf16>, tensor<1x192x1x1xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc37)
    %448 = ttir.empty() : tensor<8x192x14x14xbf16> loc(#loc469)
    %449 = "ttir.relu"(%447, %448) : (tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>) -> tensor<8x192x14x14xbf16> loc(#loc469)
    %450 = ttir.empty() : tensor<8x1088x14x14xbf16> loc(#loc186)
    %451 = "ttir.concat"(%355, %397, %423, %449, %450) <{dim = -3 : si32}> : (tensor<8x512x14x14xbf16>, tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>, tensor<8x192x14x14xbf16>, tensor<8x1088x14x14xbf16>) -> tensor<8x1088x14x14xbf16> loc(#loc186)
    %452 = ttir.empty() : tensor<8x14x1088x14xbf16> loc(#loc278)
    %453 = "ttir.transpose"(%451, %452) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1088x14x14xbf16>, tensor<8x14x1088x14xbf16>) -> tensor<8x14x1088x14xbf16> loc(#loc278)
    %454 = ttir.empty() : tensor<8x14x14x1088xbf16> loc(#loc279)
    %455 = "ttir.transpose"(%453, %454) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x1088x14xbf16>, tensor<8x14x14x1088xbf16>) -> tensor<8x14x14x1088xbf16> loc(#loc279)
    %456 = ttir.empty() : tensor<8x14x14x768xbf16> loc(#loc280)
    %457 = "ttir.conv2d"(%455, %arg87, %456) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x14x14x1088xbf16>, tensor<768x1088x1x1xbf16>, tensor<8x14x14x768xbf16>) -> tensor<8x14x14x768xbf16> loc(#loc280)
    %458 = ttir.empty() : tensor<8x14x768x14xbf16> loc(#loc281)
    %459 = "ttir.transpose"(%457, %458) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x14x768xbf16>, tensor<8x14x768x14xbf16>) -> tensor<8x14x768x14xbf16> loc(#loc281)
    %460 = ttir.empty() : tensor<8x768x14x14xbf16> loc(#loc282)
    %461 = "ttir.transpose"(%459, %460) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x14x768x14xbf16>, tensor<8x768x14x14xbf16>) -> tensor<8x768x14x14xbf16> loc(#loc282)
    %462 = ttir.empty() : tensor<8x768x14x14xbf16> loc(#loc38)
    %463 = "ttir.multiply"(%461, %arg39, %462) : (tensor<8x768x14x14xbf16>, tensor<1x768x1x1xbf16>, tensor<8x768x14x14xbf16>) -> tensor<8x768x14x14xbf16> loc(#loc38)
    %464 = ttir.empty() : tensor<8x768x14x14xbf16> loc(#loc39)
    %465 = "ttir.add"(%463, %arg40, %464) : (tensor<8x768x14x14xbf16>, tensor<1x768x1x1xbf16>, tensor<8x768x14x14xbf16>) -> tensor<8x768x14x14xbf16> loc(#loc39)
    %466 = ttir.empty() : tensor<8x768x14x14xbf16> loc(#loc425)
    %467 = "ttir.relu"(%465, %466) : (tensor<8x768x14x14xbf16>, tensor<8x768x14x14xbf16>) -> tensor<8x768x14x14xbf16> loc(#loc425)
    %468 = ttir.empty() : tensor<8x768x1x14xbf16> loc(#loc40)
    %469 = "ttir.mean"(%467, %468) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x768x14x14xbf16>, tensor<8x768x1x14xbf16>) -> tensor<8x768x1x14xbf16> loc(#loc40)
    %470 = ttir.empty() : tensor<8x768x1x1xbf16> loc(#loc189)
    %471 = "ttir.mean"(%469, %470) <{dim_arg = [-1 : i32], keep_dim = true}> : (tensor<8x768x1x14xbf16>, tensor<8x768x1x1xbf16>) -> tensor<8x768x1x1xbf16> loc(#loc189)
    %472 = ttir.empty() : tensor<8x1x768x1xbf16> loc(#loc284)
    %473 = "ttir.transpose"(%471, %472) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x768x1x1xbf16>, tensor<8x1x768x1xbf16>) -> tensor<8x1x768x1xbf16> loc(#loc284)
    %474 = ttir.empty() : tensor<8x1x1x768xbf16> loc(#loc285)
    %475 = "ttir.transpose"(%473, %474) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x768x1xbf16>, tensor<8x1x1x768xbf16>) -> tensor<8x1x1x768xbf16> loc(#loc285)
    %476 = ttir.empty() : tensor<8x1x1x768xbf16> loc(#loc286)
    %477 = "ttir.conv2d"(%475, %arg88, %arg89, %476) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x1x1x768xbf16>, tensor<768x768x1x1xbf16>, tensor<1x1x1x768xbf16>, tensor<8x1x1x768xbf16>) -> tensor<8x1x1x768xbf16> loc(#loc286)
    %478 = ttir.empty() : tensor<8x1x768x1xbf16> loc(#loc287)
    %479 = "ttir.transpose"(%477, %478) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x1x768xbf16>, tensor<8x1x768x1xbf16>) -> tensor<8x1x768x1xbf16> loc(#loc287)
    %480 = ttir.empty() : tensor<8x768x1x1xbf16> loc(#loc288)
    %481 = "ttir.transpose"(%479, %480) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1x768x1xbf16>, tensor<8x768x1x1xbf16>) -> tensor<8x768x1x1xbf16> loc(#loc288)
    %482 = ttir.empty() : tensor<8x768x1x1xbf16> loc(#loc289)
    %483 = "ttir.add"(%481, %arg41, %482) : (tensor<8x768x1x1xbf16>, tensor<1xbf16>, tensor<8x768x1x1xbf16>) -> tensor<8x768x1x1xbf16> loc(#loc289)
    %484 = ttir.empty() : tensor<8x768x1x1xbf16> loc(#loc290)
    %485 = "ttir.clamp_scalar"(%483, %484) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x768x1x1xbf16>, tensor<8x768x1x1xbf16>) -> tensor<8x768x1x1xbf16> loc(#loc290)
    %486 = ttir.empty() : tensor<8x768x1x1xbf16> loc(#loc291)
    %487 = "ttir.div"(%485, %arg42, %486) : (tensor<8x768x1x1xbf16>, tensor<1xbf16>, tensor<8x768x1x1xbf16>) -> tensor<8x768x1x1xbf16> loc(#loc291)
    %488 = ttir.empty() : tensor<8x768x14x14xbf16> loc(#loc192)
    %489 = "ttir.multiply"(%467, %487, %488) : (tensor<8x768x14x14xbf16>, tensor<8x768x1x1xbf16>, tensor<8x768x14x14xbf16>) -> tensor<8x768x14x14xbf16> loc(#loc192)
    %490 = ttir.empty() : tensor<8x14x768x14xbf16> loc(#loc126)
    %491 = "ttir.transpose"(%489, %490) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x768x14x14xbf16>, tensor<8x14x768x14xbf16>) -> tensor<8x14x768x14xbf16> loc(#loc126)
    %492 = ttir.empty() : tensor<8x14x14x768xbf16> loc(#loc127)
    %493 = "ttir.transpose"(%491, %492) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x14x768x14xbf16>, tensor<8x14x14x768xbf16>) -> tensor<8x14x14x768xbf16> loc(#loc127)
    %494 = ttir.empty() : tensor<8x7x7x768xbf16> loc(#loc128)
    %495 = "ttir.max_pool2d"(%493, %494) <{ceil_mode = true, dilation_height = 1 : si32, dilation_width = 1 : si32, kernel_height = 3 : si32, kernel_width = 3 : si32, padding_bottom = 0 : si32, padding_left = 0 : si32, padding_right = 0 : si32, padding_top = 0 : si32, stride_height = 2 : si32, stride_width = 2 : si32}> {channel_last = true} : (tensor<8x14x14x768xbf16>, tensor<8x7x7x768xbf16>) -> tensor<8x7x7x768xbf16> loc(#loc128)
    %496 = ttir.empty() : tensor<8x7x768x7xbf16> loc(#loc129)
    %497 = "ttir.transpose"(%495, %496) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x768xbf16>, tensor<8x7x768x7xbf16>) -> tensor<8x7x768x7xbf16> loc(#loc129)
    %498 = ttir.empty() : tensor<8x768x7x7xbf16> loc(#loc130)
    %499 = "ttir.transpose"(%497, %498) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x768x7xbf16>, tensor<8x768x7x7xbf16>) -> tensor<8x768x7x7xbf16> loc(#loc130)
    %500 = ttir.empty() : tensor<8x7x768x7xbf16> loc(#loc292)
    %501 = "ttir.transpose"(%499, %500) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x768x7x7xbf16>, tensor<8x7x768x7xbf16>) -> tensor<8x7x768x7xbf16> loc(#loc292)
    %502 = ttir.empty() : tensor<8x7x7x768xbf16> loc(#loc293)
    %503 = "ttir.transpose"(%501, %502) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x768x7xbf16>, tensor<8x7x7x768xbf16>) -> tensor<8x7x7x768xbf16> loc(#loc293)
    %504 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc294)
    %505 = "ttir.conv2d"(%503, %arg90, %504) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x768xbf16>, tensor<224x768x1x1xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc294)
    %506 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc295)
    %507 = "ttir.transpose"(%505, %506) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc295)
    %508 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc296)
    %509 = "ttir.transpose"(%507, %508) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc296)
    %510 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc41)
    %511 = "ttir.multiply"(%509, %arg43, %510) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc41)
    %512 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc42)
    %513 = "ttir.add"(%511, %arg44, %512) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc42)
    %514 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc426)
    %515 = "ttir.relu"(%513, %514) : (tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc426)
    %516 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc427)
    %517 = "ttir.transpose"(%515, %516) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc427)
    %518 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc428)
    %519 = "ttir.transpose"(%517, %518) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc428)
    %520 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc429)
    %521 = "ttir.conv2d"(%519, %arg91, %520) <{dilation = array<i32: 1, 1>, groups = 224 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x1x3x3xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc429)
    %522 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc430)
    %523 = "ttir.transpose"(%521, %522) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc430)
    %524 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc431)
    %525 = "ttir.transpose"(%523, %524) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc431)
    %526 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc432)
    %527 = "ttir.transpose"(%525, %526) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc432)
    %528 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc433)
    %529 = "ttir.transpose"(%527, %528) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc433)
    %530 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc434)
    %531 = "ttir.conv2d"(%529, %arg92, %530) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x224x1x1xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc434)
    %532 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc435)
    %533 = "ttir.transpose"(%531, %532) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc435)
    %534 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc436)
    %535 = "ttir.transpose"(%533, %534) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc436)
    %536 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc43)
    %537 = "ttir.multiply"(%535, %arg45, %536) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc43)
    %538 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc44)
    %539 = "ttir.add"(%537, %arg46, %538) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc44)
    %540 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc470)
    %541 = "ttir.relu"(%539, %540) : (tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc470)
    %542 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc438)
    %543 = "ttir.transpose"(%541, %542) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc438)
    %544 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc439)
    %545 = "ttir.transpose"(%543, %544) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc439)
    %546 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc440)
    %547 = "ttir.conv2d"(%545, %arg93, %546) <{dilation = array<i32: 1, 1>, groups = 224 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x1x3x3xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc440)
    %548 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc441)
    %549 = "ttir.transpose"(%547, %548) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc441)
    %550 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc442)
    %551 = "ttir.transpose"(%549, %550) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc442)
    %552 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc443)
    %553 = "ttir.transpose"(%551, %552) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc443)
    %554 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc444)
    %555 = "ttir.transpose"(%553, %554) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc444)
    %556 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc445)
    %557 = "ttir.conv2d"(%555, %arg94, %556) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x224x1x1xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc445)
    %558 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc446)
    %559 = "ttir.transpose"(%557, %558) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc446)
    %560 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc447)
    %561 = "ttir.transpose"(%559, %560) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc447)
    %562 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc45)
    %563 = "ttir.multiply"(%561, %arg47, %562) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc45)
    %564 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc46)
    %565 = "ttir.add"(%563, %arg48, %564) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc46)
    %566 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc471)
    %567 = "ttir.relu"(%565, %566) : (tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc471)
    %568 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc449)
    %569 = "ttir.transpose"(%567, %568) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc449)
    %570 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc450)
    %571 = "ttir.transpose"(%569, %570) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc450)
    %572 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc451)
    %573 = "ttir.conv2d"(%571, %arg95, %572) <{dilation = array<i32: 1, 1>, groups = 224 : i32, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x1x3x3xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc451)
    %574 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc452)
    %575 = "ttir.transpose"(%573, %574) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc452)
    %576 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc453)
    %577 = "ttir.transpose"(%575, %576) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc453)
    %578 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc454)
    %579 = "ttir.transpose"(%577, %578) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x224x7x7xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc454)
    %580 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc455)
    %581 = "ttir.transpose"(%579, %580) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc455)
    %582 = ttir.empty() : tensor<8x7x7x224xbf16> loc(#loc456)
    %583 = "ttir.conv2d"(%581, %arg96, %582) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x224xbf16>, tensor<224x224x1x1xbf16>, tensor<8x7x7x224xbf16>) -> tensor<8x7x7x224xbf16> loc(#loc456)
    %584 = ttir.empty() : tensor<8x7x224x7xbf16> loc(#loc457)
    %585 = "ttir.transpose"(%583, %584) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x224xbf16>, tensor<8x7x224x7xbf16>) -> tensor<8x7x224x7xbf16> loc(#loc457)
    %586 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc458)
    %587 = "ttir.transpose"(%585, %586) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x224x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc458)
    %588 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc47)
    %589 = "ttir.multiply"(%587, %arg49, %588) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc47)
    %590 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc48)
    %591 = "ttir.add"(%589, %arg50, %590) : (tensor<8x224x7x7xbf16>, tensor<1x224x1x1xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc48)
    %592 = ttir.empty() : tensor<8x224x7x7xbf16> loc(#loc472)
    %593 = "ttir.relu"(%591, %592) : (tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>) -> tensor<8x224x7x7xbf16> loc(#loc472)
    %594 = ttir.empty() : tensor<8x1440x7x7xbf16> loc(#loc198)
    %595 = "ttir.concat"(%499, %541, %567, %593, %594) <{dim = -3 : si32}> : (tensor<8x768x7x7xbf16>, tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>, tensor<8x224x7x7xbf16>, tensor<8x1440x7x7xbf16>) -> tensor<8x1440x7x7xbf16> loc(#loc198)
    %596 = ttir.empty() : tensor<8x7x1440x7xbf16> loc(#loc307)
    %597 = "ttir.transpose"(%595, %596) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1440x7x7xbf16>, tensor<8x7x1440x7xbf16>) -> tensor<8x7x1440x7xbf16> loc(#loc307)
    %598 = ttir.empty() : tensor<8x7x7x1440xbf16> loc(#loc308)
    %599 = "ttir.transpose"(%597, %598) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x1440x7xbf16>, tensor<8x7x7x1440xbf16>) -> tensor<8x7x7x1440xbf16> loc(#loc308)
    %600 = ttir.empty() : tensor<8x7x7x1024xbf16> loc(#loc309)
    %601 = "ttir.conv2d"(%599, %arg97, %600) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x7x7x1440xbf16>, tensor<1024x1440x1x1xbf16>, tensor<8x7x7x1024xbf16>) -> tensor<8x7x7x1024xbf16> loc(#loc309)
    %602 = ttir.empty() : tensor<8x7x1024x7xbf16> loc(#loc310)
    %603 = "ttir.transpose"(%601, %602) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x7x7x1024xbf16>, tensor<8x7x1024x7xbf16>) -> tensor<8x7x1024x7xbf16> loc(#loc310)
    %604 = ttir.empty() : tensor<8x1024x7x7xbf16> loc(#loc311)
    %605 = "ttir.transpose"(%603, %604) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x7x1024x7xbf16>, tensor<8x1024x7x7xbf16>) -> tensor<8x1024x7x7xbf16> loc(#loc311)
    %606 = ttir.empty() : tensor<8x1024x7x7xbf16> loc(#loc49)
    %607 = "ttir.multiply"(%605, %arg51, %606) : (tensor<8x1024x7x7xbf16>, tensor<1x1024x1x1xbf16>, tensor<8x1024x7x7xbf16>) -> tensor<8x1024x7x7xbf16> loc(#loc49)
    %608 = ttir.empty() : tensor<8x1024x7x7xbf16> loc(#loc50)
    %609 = "ttir.add"(%607, %arg52, %608) : (tensor<8x1024x7x7xbf16>, tensor<1x1024x1x1xbf16>, tensor<8x1024x7x7xbf16>) -> tensor<8x1024x7x7xbf16> loc(#loc50)
    %610 = ttir.empty() : tensor<8x1024x7x7xbf16> loc(#loc460)
    %611 = "ttir.relu"(%609, %610) : (tensor<8x1024x7x7xbf16>, tensor<8x1024x7x7xbf16>) -> tensor<8x1024x7x7xbf16> loc(#loc460)
    %612 = ttir.empty() : tensor<8x1024x1x7xbf16> loc(#loc51)
    %613 = "ttir.mean"(%611, %612) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x1024x7x7xbf16>, tensor<8x1024x1x7xbf16>) -> tensor<8x1024x1x7xbf16> loc(#loc51)
    %614 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc201)
    %615 = "ttir.mean"(%613, %614) <{dim_arg = [-1 : i32], keep_dim = true}> : (tensor<8x1024x1x7xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc201)
    %616 = ttir.empty() : tensor<8x1x1024x1xbf16> loc(#loc313)
    %617 = "ttir.transpose"(%615, %616) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1024x1x1xbf16>, tensor<8x1x1024x1xbf16>) -> tensor<8x1x1024x1xbf16> loc(#loc313)
    %618 = ttir.empty() : tensor<8x1x1x1024xbf16> loc(#loc314)
    %619 = "ttir.transpose"(%617, %618) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x1024x1xbf16>, tensor<8x1x1x1024xbf16>) -> tensor<8x1x1x1024xbf16> loc(#loc314)
    %620 = ttir.empty() : tensor<8x1x1x1024xbf16> loc(#loc315)
    %621 = "ttir.conv2d"(%619, %arg98, %arg99, %620) <{dilation = array<i32: 1, 1>, groups = 1 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>}> {channel_last = 1 : si32} : (tensor<8x1x1x1024xbf16>, tensor<1024x1024x1x1xbf16>, tensor<1x1x1x1024xbf16>, tensor<8x1x1x1024xbf16>) -> tensor<8x1x1x1024xbf16> loc(#loc315)
    %622 = ttir.empty() : tensor<8x1x1024x1xbf16> loc(#loc316)
    %623 = "ttir.transpose"(%621, %622) <{dim0 = -2 : si32, dim1 = -1 : si32}> : (tensor<8x1x1x1024xbf16>, tensor<8x1x1024x1xbf16>) -> tensor<8x1x1024x1xbf16> loc(#loc316)
    %624 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc317)
    %625 = "ttir.transpose"(%623, %624) <{dim0 = -3 : si32, dim1 = -2 : si32}> : (tensor<8x1x1024x1xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc317)
    %626 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc318)
    %627 = "ttir.add"(%625, %arg53, %626) : (tensor<8x1024x1x1xbf16>, tensor<1xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc318)
    %628 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc319)
    %629 = "ttir.clamp_scalar"(%627, %628) <{max = 6.000000e+00 : f32, min = 0.000000e+00 : f32}> : (tensor<8x1024x1x1xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc319)
    %630 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc320)
    %631 = "ttir.div"(%629, %arg54, %630) : (tensor<8x1024x1x1xbf16>, tensor<1xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc320)
    %632 = ttir.empty() : tensor<8x1024x7x7xbf16> loc(#loc204)
    %633 = "ttir.multiply"(%611, %631, %632) : (tensor<8x1024x7x7xbf16>, tensor<8x1024x1x1xbf16>, tensor<8x1024x7x7xbf16>) -> tensor<8x1024x7x7xbf16> loc(#loc204)
    %634 = ttir.empty() : tensor<8x1x1024x49xbf16> loc(#loc132)
    %635 = "ttir.reshape"(%633, %634) <{shape = [8 : i32, 1 : i32, 1024 : i32, 49 : i32]}> : (tensor<8x1024x7x7xbf16>, tensor<8x1x1024x49xbf16>) -> tensor<8x1x1024x49xbf16> loc(#loc132)
    %636 = ttir.empty() : tensor<8x1x49x1024xbf16> loc(#loc133)
    %637 = "ttir.transpose"(%635, %636) <{dim0 = 2 : si32, dim1 = 3 : si32}> : (tensor<8x1x1024x49xbf16>, tensor<8x1x49x1024xbf16>) -> tensor<8x1x49x1024xbf16> loc(#loc133)
    %638 = ttir.empty() : tensor<8x1x1x1024xbf16> loc(#loc134)
    %639 = "ttir.mean"(%637, %638) <{dim_arg = [-2 : i32], keep_dim = true}> : (tensor<8x1x49x1024xbf16>, tensor<8x1x1x1024xbf16>) -> tensor<8x1x1x1024xbf16> loc(#loc134)
    %640 = ttir.empty() : tensor<8x1x1024x1xbf16> loc(#loc135)
    %641 = "ttir.transpose"(%639, %640) <{dim0 = 2 : si32, dim1 = 3 : si32}> : (tensor<8x1x1x1024xbf16>, tensor<8x1x1024x1xbf16>) -> tensor<8x1x1024x1xbf16> loc(#loc135)
    %642 = ttir.empty() : tensor<8x1024x1x1xbf16> loc(#loc136)
    %643 = "ttir.reshape"(%641, %642) <{shape = [8 : i32, 1024 : i32, 1 : i32, 1 : i32]}> : (tensor<8x1x1024x1xbf16>, tensor<8x1024x1x1xbf16>) -> tensor<8x1024x1x1xbf16> loc(#loc136)
    %644 = ttir.empty() : tensor<8x1024x1xbf16> loc(#loc52)
    %645 = "ttir.squeeze"(%643, %644) <{dim = -2 : si32}> : (tensor<8x1024x1x1xbf16>, tensor<8x1024x1xbf16>) -> tensor<8x1024x1xbf16> loc(#loc52)
    %646 = ttir.empty() : tensor<8x1024xbf16> loc(#loc137)
    %647 = "ttir.squeeze"(%645, %646) <{dim = -1 : si32}> : (tensor<8x1024x1xbf16>, tensor<8x1024xbf16>) -> tensor<8x1024xbf16> loc(#loc137)
    %648 = ttir.empty() : tensor<8x1000xbf16> loc(#loc84)
    %649 = "ttir.matmul"(%647, %arg100, %648) <{transpose_a = false, transpose_b = false}> : (tensor<8x1024xbf16>, tensor<1024x1000xbf16>, tensor<8x1000xbf16>) -> tensor<8x1000xbf16> loc(#loc84)
    %650 = ttir.empty() : tensor<8x1000xbf16> loc(#loc53)
    %651 = "ttir.add"(%649, %arg101, %650) : (tensor<8x1000xbf16>, tensor<1000xbf16>, tensor<8x1000xbf16>) -> tensor<8x1000xbf16> loc(#loc53)
    return %651 : tensor<8x1000xbf16> loc(#loc54)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("timm.models.vovnet.VovNet::")
#loc2 = loc("multiply_7")
#loc3 = loc("add_13")
#loc4 = loc("multiply_24")
#loc5 = loc("add_30")
#loc6 = loc("multiply_41")
#loc7 = loc("add_47")
#loc8 = loc("multiply_56")
#loc9 = loc("add_62")
#loc10 = loc("multiply_73")
#loc11 = loc("add_79")
#loc12 = loc("multiply_90")
#loc13 = loc("add_96")
#loc14 = loc("multiply_107")
#loc15 = loc("add_113")
#loc16 = loc("multiply_123")
#loc17 = loc("add_129")
#loc18 = loc("reduce_avg_131")
#loc19 = loc("multiply_149")
#loc20 = loc("add_155")
#loc21 = loc("multiply_166")
#loc22 = loc("add_172")
#loc23 = loc("multiply_183")
#loc24 = loc("add_189")
#loc25 = loc("multiply_200")
#loc26 = loc("add_206")
#loc27 = loc("multiply_216")
#loc28 = loc("add_222")
#loc29 = loc("reduce_avg_224")
#loc30 = loc("multiply_242")
#loc31 = loc("add_248")
#loc32 = loc("multiply_259")
#loc33 = loc("add_265")
#loc34 = loc("multiply_276")
#loc35 = loc("add_282")
#loc36 = loc("multiply_293")
#loc37 = loc("add_299")
#loc38 = loc("multiply_309")
#loc39 = loc("add_315")
#loc40 = loc("reduce_avg_317")
#loc41 = loc("multiply_335")
#loc42 = loc("add_341")
#loc43 = loc("multiply_352")
#loc44 = loc("add_358")
#loc45 = loc("multiply_369")
#loc46 = loc("add_375")
#loc47 = loc("multiply_386")
#loc48 = loc("add_392")
#loc49 = loc("multiply_402")
#loc50 = loc("add_408")
#loc51 = loc("reduce_avg_410")
#loc52 = loc("squeeze_422")
#loc53 = loc("add_427")
#loc54 = loc(unknown)
#loc55 = loc("torch.nn.modules.container.Sequential::stem"(#loc1))
#loc56 = loc("torch.nn.modules.container.Sequential::stages"(#loc1))
#loc57 = loc("timm.layers.classifier.ClassifierHead::head"(#loc1))
#loc58 = loc("timm.layers.conv_bn_act.ConvNormAct::0"(#loc55))
#loc59 = loc("timm.layers.separable_conv.SeparableConvNormAct::1"(#loc55))
#loc60 = loc("timm.layers.separable_conv.SeparableConvNormAct::2"(#loc55))
#loc61 = loc("timm.models.vovnet.OsaStage::0"(#loc56))
#loc62 = loc("timm.models.vovnet.OsaStage::1"(#loc56))
#loc63 = loc("timm.models.vovnet.OsaStage::2"(#loc56))
#loc64 = loc("timm.models.vovnet.OsaStage::3"(#loc56))
#loc65 = loc("timm.layers.adaptive_avgmax_pool.SelectAdaptivePool2d::global_pool"(#loc57))
#loc66 = loc("torch.nn.modules.linear.Linear::fc"(#loc57))
#loc67 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc58))
#loc68 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc58))
#loc69 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc59))
#loc70 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc59))
#loc71 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc59))
#loc72 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc60))
#loc73 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc60))
#loc74 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc60))
#loc75 = loc("torch.nn.modules.container.Sequential::blocks"(#loc61))
#loc76 = loc("torch.nn.modules.pooling.MaxPool2d::pool"(#loc62))
#loc77 = loc("torch.nn.modules.container.Sequential::blocks"(#loc62))
#loc78 = loc("torch.nn.modules.pooling.MaxPool2d::pool"(#loc63))
#loc79 = loc("torch.nn.modules.container.Sequential::blocks"(#loc63))
#loc80 = loc("torch.nn.modules.pooling.MaxPool2d::pool"(#loc64))
#loc81 = loc("torch.nn.modules.container.Sequential::blocks"(#loc64))
#loc82 = loc("torch.nn.modules.pooling.AdaptiveAvgPool2d::pool"(#loc65))
#loc83 = loc("torch.nn.modules.flatten.Flatten::flatten"(#loc65))
#loc84 = loc("matmul_426"(#loc66))
#loc85 = loc("conv2d_0.dc.transpose.0"(#loc67))
#loc86 = loc("conv2d_0.dc.transpose.1"(#loc67))
#loc87 = loc("conv2d_0.dc.conv2d.2"(#loc67))
#loc88 = loc("conv2d_0.dc.transpose.3"(#loc67))
#loc89 = loc("conv2d_0.dc.transpose.4"(#loc67))
#loc90 = loc("torch.nn.modules.activation.ReLU::act"(#loc68))
#loc91 = loc("conv2d_16.dc.transpose.0"(#loc69))
#loc92 = loc("conv2d_16.dc.transpose.1"(#loc69))
#loc93 = loc("conv2d_16.dc.conv2d.2"(#loc69))
#loc94 = loc("conv2d_16.dc.transpose.3"(#loc69))
#loc95 = loc("conv2d_16.dc.transpose.4"(#loc69))
#loc96 = loc("conv2d_17.dc.transpose.0"(#loc70))
#loc97 = loc("conv2d_17.dc.transpose.1"(#loc70))
#loc98 = loc("conv2d_17.dc.conv2d.2"(#loc70))
#loc99 = loc("conv2d_17.dc.transpose.3"(#loc70))
#loc100 = loc("conv2d_17.dc.transpose.4"(#loc70))
#loc101 = loc("torch.nn.modules.activation.ReLU::act"(#loc71))
#loc102 = loc("conv2d_33.dc.transpose.0"(#loc72))
#loc103 = loc("conv2d_33.dc.transpose.1"(#loc72))
#loc104 = loc("conv2d_33.dc.conv2d.2"(#loc72))
#loc105 = loc("conv2d_33.dc.transpose.3"(#loc72))
#loc106 = loc("conv2d_33.dc.transpose.4"(#loc72))
#loc107 = loc("conv2d_34.dc.transpose.0"(#loc73))
#loc108 = loc("conv2d_34.dc.transpose.1"(#loc73))
#loc109 = loc("conv2d_34.dc.conv2d.2"(#loc73))
#loc110 = loc("conv2d_34.dc.transpose.3"(#loc73))
#loc111 = loc("conv2d_34.dc.transpose.4"(#loc73))
#loc112 = loc("torch.nn.modules.activation.ReLU::act"(#loc74))
#loc113 = loc("timm.models.vovnet.OsaBlock::0"(#loc75))
#loc114 = loc("max_pool2d_141.dc.transpose.0"(#loc76))
#loc115 = loc("max_pool2d_141.dc.transpose.1"(#loc76))
#loc116 = loc("max_pool2d_141.dc.max_pool2d.2"(#loc76))
#loc117 = loc("max_pool2d_141.dc.transpose.3"(#loc76))
#loc118 = loc("max_pool2d_141.dc.transpose.4"(#loc76))
#loc119 = loc("timm.models.vovnet.OsaBlock::0"(#loc77))
#loc120 = loc("max_pool2d_234.dc.transpose.0"(#loc78))
#loc121 = loc("max_pool2d_234.dc.transpose.1"(#loc78))
#loc122 = loc("max_pool2d_234.dc.max_pool2d.2"(#loc78))
#loc123 = loc("max_pool2d_234.dc.transpose.3"(#loc78))
#loc124 = loc("max_pool2d_234.dc.transpose.4"(#loc78))
#loc125 = loc("timm.models.vovnet.OsaBlock::0"(#loc79))
#loc126 = loc("max_pool2d_327.dc.transpose.0"(#loc80))
#loc127 = loc("max_pool2d_327.dc.transpose.1"(#loc80))
#loc128 = loc("max_pool2d_327.dc.max_pool2d.2"(#loc80))
#loc129 = loc("max_pool2d_327.dc.transpose.3"(#loc80))
#loc130 = loc("max_pool2d_327.dc.transpose.4"(#loc80))
#loc131 = loc("timm.models.vovnet.OsaBlock::0"(#loc81))
#loc132 = loc("avg_pool2d_420.dc.reshape.0"(#loc82))
#loc133 = loc("avg_pool2d_420.dc.transpose.1"(#loc82))
#loc134 = loc("avg_pool2d_420.dc.reduce_avg.2"(#loc82))
#loc135 = loc("avg_pool2d_420.dc.transpose.3"(#loc82))
#loc136 = loc("avg_pool2d_420.dc.reshape.4"(#loc82))
#loc137 = loc("squeeze_423"(#loc83))
#loc138 = loc("relu_14"(#loc90))
#loc139 = loc("relu_31"(#loc101))
#loc140 = loc("relu_48"(#loc112))
#loc141 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_reduction"(#loc113))
#loc142 = loc("timm.models.vovnet.SequentialAppendList::conv_mid"(#loc113))
#loc143 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_concat"(#loc113))
#loc144 = loc("timm.layers.squeeze_excite.EffectiveSEModule::attn"(#loc113))
#loc145 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_reduction"(#loc119))
#loc146 = loc("timm.models.vovnet.SequentialAppendList::conv_mid"(#loc119))
#loc147 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_concat"(#loc119))
#loc148 = loc("timm.layers.squeeze_excite.EffectiveSEModule::attn"(#loc119))
#loc149 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_reduction"(#loc125))
#loc150 = loc("timm.models.vovnet.SequentialAppendList::conv_mid"(#loc125))
#loc151 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_concat"(#loc125))
#loc152 = loc("timm.layers.squeeze_excite.EffectiveSEModule::attn"(#loc125))
#loc153 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_reduction"(#loc131))
#loc154 = loc("timm.models.vovnet.SequentialAppendList::conv_mid"(#loc131))
#loc155 = loc("timm.layers.conv_bn_act.ConvNormAct::conv_concat"(#loc131))
#loc156 = loc("timm.layers.squeeze_excite.EffectiveSEModule::attn"(#loc131))
#loc157 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc141))
#loc158 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc141))
#loc159 = loc("timm.layers.separable_conv.SeparableConvNormAct::0"(#loc142))
#loc160 = loc("timm.layers.separable_conv.SeparableConvNormAct::1"(#loc142))
#loc161 = loc("timm.layers.separable_conv.SeparableConvNormAct::2"(#loc142))
#loc162 = loc("concatenate_115"(#loc142))
#loc163 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc143))
#loc164 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc143))
#loc165 = loc("reduce_avg_132"(#loc144))
#loc166 = loc("torch.nn.modules.conv.Conv2d::fc"(#loc144))
#loc167 = loc("torch.nn.modules.activation.Hardsigmoid::gate"(#loc144))
#loc168 = loc("multiply_140"(#loc144))
#loc169 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc145))
#loc170 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc145))
#loc171 = loc("timm.layers.separable_conv.SeparableConvNormAct::0"(#loc146))
#loc172 = loc("timm.layers.separable_conv.SeparableConvNormAct::1"(#loc146))
#loc173 = loc("timm.layers.separable_conv.SeparableConvNormAct::2"(#loc146))
#loc174 = loc("concatenate_208"(#loc146))
#loc175 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc147))
#loc176 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc147))
#loc177 = loc("reduce_avg_225"(#loc148))
#loc178 = loc("torch.nn.modules.conv.Conv2d::fc"(#loc148))
#loc179 = loc("torch.nn.modules.activation.Hardsigmoid::gate"(#loc148))
#loc180 = loc("multiply_233"(#loc148))
#loc181 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc149))
#loc182 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc149))
#loc183 = loc("timm.layers.separable_conv.SeparableConvNormAct::0"(#loc150))
#loc184 = loc("timm.layers.separable_conv.SeparableConvNormAct::1"(#loc150))
#loc185 = loc("timm.layers.separable_conv.SeparableConvNormAct::2"(#loc150))
#loc186 = loc("concatenate_301"(#loc150))
#loc187 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc151))
#loc188 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc151))
#loc189 = loc("reduce_avg_318"(#loc152))
#loc190 = loc("torch.nn.modules.conv.Conv2d::fc"(#loc152))
#loc191 = loc("torch.nn.modules.activation.Hardsigmoid::gate"(#loc152))
#loc192 = loc("multiply_326"(#loc152))
#loc193 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc153))
#loc194 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc153))
#loc195 = loc("timm.layers.separable_conv.SeparableConvNormAct::0"(#loc154))
#loc196 = loc("timm.layers.separable_conv.SeparableConvNormAct::1"(#loc154))
#loc197 = loc("timm.layers.separable_conv.SeparableConvNormAct::2"(#loc154))
#loc198 = loc("concatenate_394"(#loc154))
#loc199 = loc("torch.nn.modules.conv.Conv2d::conv"(#loc155))
#loc200 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc155))
#loc201 = loc("reduce_avg_411"(#loc156))
#loc202 = loc("torch.nn.modules.conv.Conv2d::fc"(#loc156))
#loc203 = loc("torch.nn.modules.activation.Hardsigmoid::gate"(#loc156))
#loc204 = loc("multiply_419"(#loc156))
#loc205 = loc("conv2d_49.dc.transpose.0"(#loc157))
#loc206 = loc("conv2d_49.dc.transpose.1"(#loc157))
#loc207 = loc("conv2d_49.dc.conv2d.2"(#loc157))
#loc208 = loc("conv2d_49.dc.transpose.3"(#loc157))
#loc209 = loc("conv2d_49.dc.transpose.4"(#loc157))
#loc210 = loc("torch.nn.modules.activation.ReLU::act"(#loc158))
#loc211 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc159))
#loc212 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc159))
#loc213 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc159))
#loc214 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc160))
#loc215 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc160))
#loc216 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc160))
#loc217 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc161))
#loc218 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc161))
#loc219 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc161))
#loc220 = loc("conv2d_116.dc.transpose.0"(#loc163))
#loc221 = loc("conv2d_116.dc.transpose.1"(#loc163))
#loc222 = loc("conv2d_116.dc.conv2d.2"(#loc163))
#loc223 = loc("conv2d_116.dc.transpose.3"(#loc163))
#loc224 = loc("conv2d_116.dc.transpose.4"(#loc163))
#loc225 = loc("torch.nn.modules.activation.ReLU::act"(#loc164))
#loc226 = loc("conv2d_133.dc.transpose.0"(#loc166))
#loc227 = loc("conv2d_133.dc.transpose.1"(#loc166))
#loc228 = loc("conv2d_133.dc.conv2d.4"(#loc166))
#loc229 = loc("conv2d_133.dc.transpose.5"(#loc166))
#loc230 = loc("conv2d_133.dc.transpose.6"(#loc166))
#loc231 = loc("add_137"(#loc167))
#loc232 = loc("clip_138"(#loc167))
#loc233 = loc("divide_139"(#loc167))
#loc234 = loc("conv2d_142.dc.transpose.0"(#loc169))
#loc235 = loc("conv2d_142.dc.transpose.1"(#loc169))
#loc236 = loc("conv2d_142.dc.conv2d.2"(#loc169))
#loc237 = loc("conv2d_142.dc.transpose.3"(#loc169))
#loc238 = loc("conv2d_142.dc.transpose.4"(#loc169))
#loc239 = loc("torch.nn.modules.activation.ReLU::act"(#loc170))
#loc240 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc171))
#loc241 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc171))
#loc242 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc171))
#loc243 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc172))
#loc244 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc172))
#loc245 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc172))
#loc246 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc173))
#loc247 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc173))
#loc248 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc173))
#loc249 = loc("conv2d_209.dc.transpose.0"(#loc175))
#loc250 = loc("conv2d_209.dc.transpose.1"(#loc175))
#loc251 = loc("conv2d_209.dc.conv2d.2"(#loc175))
#loc252 = loc("conv2d_209.dc.transpose.3"(#loc175))
#loc253 = loc("conv2d_209.dc.transpose.4"(#loc175))
#loc254 = loc("torch.nn.modules.activation.ReLU::act"(#loc176))
#loc255 = loc("conv2d_226.dc.transpose.0"(#loc178))
#loc256 = loc("conv2d_226.dc.transpose.1"(#loc178))
#loc257 = loc("conv2d_226.dc.conv2d.4"(#loc178))
#loc258 = loc("conv2d_226.dc.transpose.5"(#loc178))
#loc259 = loc("conv2d_226.dc.transpose.6"(#loc178))
#loc260 = loc("add_230"(#loc179))
#loc261 = loc("clip_231"(#loc179))
#loc262 = loc("divide_232"(#loc179))
#loc263 = loc("conv2d_235.dc.transpose.0"(#loc181))
#loc264 = loc("conv2d_235.dc.transpose.1"(#loc181))
#loc265 = loc("conv2d_235.dc.conv2d.2"(#loc181))
#loc266 = loc("conv2d_235.dc.transpose.3"(#loc181))
#loc267 = loc("conv2d_235.dc.transpose.4"(#loc181))
#loc268 = loc("torch.nn.modules.activation.ReLU::act"(#loc182))
#loc269 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc183))
#loc270 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc183))
#loc271 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc183))
#loc272 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc184))
#loc273 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc184))
#loc274 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc184))
#loc275 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc185))
#loc276 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc185))
#loc277 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc185))
#loc278 = loc("conv2d_302.dc.transpose.0"(#loc187))
#loc279 = loc("conv2d_302.dc.transpose.1"(#loc187))
#loc280 = loc("conv2d_302.dc.conv2d.2"(#loc187))
#loc281 = loc("conv2d_302.dc.transpose.3"(#loc187))
#loc282 = loc("conv2d_302.dc.transpose.4"(#loc187))
#loc283 = loc("torch.nn.modules.activation.ReLU::act"(#loc188))
#loc284 = loc("conv2d_319.dc.transpose.0"(#loc190))
#loc285 = loc("conv2d_319.dc.transpose.1"(#loc190))
#loc286 = loc("conv2d_319.dc.conv2d.4"(#loc190))
#loc287 = loc("conv2d_319.dc.transpose.5"(#loc190))
#loc288 = loc("conv2d_319.dc.transpose.6"(#loc190))
#loc289 = loc("add_323"(#loc191))
#loc290 = loc("clip_324"(#loc191))
#loc291 = loc("divide_325"(#loc191))
#loc292 = loc("conv2d_328.dc.transpose.0"(#loc193))
#loc293 = loc("conv2d_328.dc.transpose.1"(#loc193))
#loc294 = loc("conv2d_328.dc.conv2d.2"(#loc193))
#loc295 = loc("conv2d_328.dc.transpose.3"(#loc193))
#loc296 = loc("conv2d_328.dc.transpose.4"(#loc193))
#loc297 = loc("torch.nn.modules.activation.ReLU::act"(#loc194))
#loc298 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc195))
#loc299 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc195))
#loc300 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc195))
#loc301 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc196))
#loc302 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc196))
#loc303 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc196))
#loc304 = loc("torch.nn.modules.conv.Conv2d::conv_dw"(#loc197))
#loc305 = loc("torch.nn.modules.conv.Conv2d::conv_pw"(#loc197))
#loc306 = loc("timm.layers.norm_act.BatchNormAct2d::bn"(#loc197))
#loc307 = loc("conv2d_395.dc.transpose.0"(#loc199))
#loc308 = loc("conv2d_395.dc.transpose.1"(#loc199))
#loc309 = loc("conv2d_395.dc.conv2d.2"(#loc199))
#loc310 = loc("conv2d_395.dc.transpose.3"(#loc199))
#loc311 = loc("conv2d_395.dc.transpose.4"(#loc199))
#loc312 = loc("torch.nn.modules.activation.ReLU::act"(#loc200))
#loc313 = loc("conv2d_412.dc.transpose.0"(#loc202))
#loc314 = loc("conv2d_412.dc.transpose.1"(#loc202))
#loc315 = loc("conv2d_412.dc.conv2d.4"(#loc202))
#loc316 = loc("conv2d_412.dc.transpose.5"(#loc202))
#loc317 = loc("conv2d_412.dc.transpose.6"(#loc202))
#loc318 = loc("add_416"(#loc203))
#loc319 = loc("clip_417"(#loc203))
#loc320 = loc("divide_418"(#loc203))
#loc321 = loc("relu_63"(#loc210))
#loc322 = loc("conv2d_65.dc.transpose.0"(#loc211))
#loc323 = loc("conv2d_65.dc.transpose.1"(#loc211))
#loc324 = loc("conv2d_65.dc.conv2d.2"(#loc211))
#loc325 = loc("conv2d_65.dc.transpose.3"(#loc211))
#loc326 = loc("conv2d_65.dc.transpose.4"(#loc211))
#loc327 = loc("conv2d_66.dc.transpose.0"(#loc212))
#loc328 = loc("conv2d_66.dc.transpose.1"(#loc212))
#loc329 = loc("conv2d_66.dc.conv2d.2"(#loc212))
#loc330 = loc("conv2d_66.dc.transpose.3"(#loc212))
#loc331 = loc("conv2d_66.dc.transpose.4"(#loc212))
#loc332 = loc("torch.nn.modules.activation.ReLU::act"(#loc213))
#loc333 = loc("conv2d_82.dc.transpose.0"(#loc214))
#loc334 = loc("conv2d_82.dc.transpose.1"(#loc214))
#loc335 = loc("conv2d_82.dc.conv2d.2"(#loc214))
#loc336 = loc("conv2d_82.dc.transpose.3"(#loc214))
#loc337 = loc("conv2d_82.dc.transpose.4"(#loc214))
#loc338 = loc("conv2d_83.dc.transpose.0"(#loc215))
#loc339 = loc("conv2d_83.dc.transpose.1"(#loc215))
#loc340 = loc("conv2d_83.dc.conv2d.2"(#loc215))
#loc341 = loc("conv2d_83.dc.transpose.3"(#loc215))
#loc342 = loc("conv2d_83.dc.transpose.4"(#loc215))
#loc343 = loc("torch.nn.modules.activation.ReLU::act"(#loc216))
#loc344 = loc("conv2d_99.dc.transpose.0"(#loc217))
#loc345 = loc("conv2d_99.dc.transpose.1"(#loc217))
#loc346 = loc("conv2d_99.dc.conv2d.2"(#loc217))
#loc347 = loc("conv2d_99.dc.transpose.3"(#loc217))
#loc348 = loc("conv2d_99.dc.transpose.4"(#loc217))
#loc349 = loc("conv2d_100.dc.transpose.0"(#loc218))
#loc350 = loc("conv2d_100.dc.transpose.1"(#loc218))
#loc351 = loc("conv2d_100.dc.conv2d.2"(#loc218))
#loc352 = loc("conv2d_100.dc.transpose.3"(#loc218))
#loc353 = loc("conv2d_100.dc.transpose.4"(#loc218))
#loc354 = loc("torch.nn.modules.activation.ReLU::act"(#loc219))
#loc355 = loc("relu_130"(#loc225))
#loc356 = loc("relu_156"(#loc239))
#loc357 = loc("conv2d_158.dc.transpose.0"(#loc240))
#loc358 = loc("conv2d_158.dc.transpose.1"(#loc240))
#loc359 = loc("conv2d_158.dc.conv2d.2"(#loc240))
#loc360 = loc("conv2d_158.dc.transpose.3"(#loc240))
#loc361 = loc("conv2d_158.dc.transpose.4"(#loc240))
#loc362 = loc("conv2d_159.dc.transpose.0"(#loc241))
#loc363 = loc("conv2d_159.dc.transpose.1"(#loc241))
#loc364 = loc("conv2d_159.dc.conv2d.2"(#loc241))
#loc365 = loc("conv2d_159.dc.transpose.3"(#loc241))
#loc366 = loc("conv2d_159.dc.transpose.4"(#loc241))
#loc367 = loc("torch.nn.modules.activation.ReLU::act"(#loc242))
#loc368 = loc("conv2d_175.dc.transpose.0"(#loc243))
#loc369 = loc("conv2d_175.dc.transpose.1"(#loc243))
#loc370 = loc("conv2d_175.dc.conv2d.2"(#loc243))
#loc371 = loc("conv2d_175.dc.transpose.3"(#loc243))
#loc372 = loc("conv2d_175.dc.transpose.4"(#loc243))
#loc373 = loc("conv2d_176.dc.transpose.0"(#loc244))
#loc374 = loc("conv2d_176.dc.transpose.1"(#loc244))
#loc375 = loc("conv2d_176.dc.conv2d.2"(#loc244))
#loc376 = loc("conv2d_176.dc.transpose.3"(#loc244))
#loc377 = loc("conv2d_176.dc.transpose.4"(#loc244))
#loc378 = loc("torch.nn.modules.activation.ReLU::act"(#loc245))
#loc379 = loc("conv2d_192.dc.transpose.0"(#loc246))
#loc380 = loc("conv2d_192.dc.transpose.1"(#loc246))
#loc381 = loc("conv2d_192.dc.conv2d.2"(#loc246))
#loc382 = loc("conv2d_192.dc.transpose.3"(#loc246))
#loc383 = loc("conv2d_192.dc.transpose.4"(#loc246))
#loc384 = loc("conv2d_193.dc.transpose.0"(#loc247))
#loc385 = loc("conv2d_193.dc.transpose.1"(#loc247))
#loc386 = loc("conv2d_193.dc.conv2d.2"(#loc247))
#loc387 = loc("conv2d_193.dc.transpose.3"(#loc247))
#loc388 = loc("conv2d_193.dc.transpose.4"(#loc247))
#loc389 = loc("torch.nn.modules.activation.ReLU::act"(#loc248))
#loc390 = loc("relu_223"(#loc254))
#loc391 = loc("relu_249"(#loc268))
#loc392 = loc("conv2d_251.dc.transpose.0"(#loc269))
#loc393 = loc("conv2d_251.dc.transpose.1"(#loc269))
#loc394 = loc("conv2d_251.dc.conv2d.2"(#loc269))
#loc395 = loc("conv2d_251.dc.transpose.3"(#loc269))
#loc396 = loc("conv2d_251.dc.transpose.4"(#loc269))
#loc397 = loc("conv2d_252.dc.transpose.0"(#loc270))
#loc398 = loc("conv2d_252.dc.transpose.1"(#loc270))
#loc399 = loc("conv2d_252.dc.conv2d.2"(#loc270))
#loc400 = loc("conv2d_252.dc.transpose.3"(#loc270))
#loc401 = loc("conv2d_252.dc.transpose.4"(#loc270))
#loc402 = loc("torch.nn.modules.activation.ReLU::act"(#loc271))
#loc403 = loc("conv2d_268.dc.transpose.0"(#loc272))
#loc404 = loc("conv2d_268.dc.transpose.1"(#loc272))
#loc405 = loc("conv2d_268.dc.conv2d.2"(#loc272))
#loc406 = loc("conv2d_268.dc.transpose.3"(#loc272))
#loc407 = loc("conv2d_268.dc.transpose.4"(#loc272))
#loc408 = loc("conv2d_269.dc.transpose.0"(#loc273))
#loc409 = loc("conv2d_269.dc.transpose.1"(#loc273))
#loc410 = loc("conv2d_269.dc.conv2d.2"(#loc273))
#loc411 = loc("conv2d_269.dc.transpose.3"(#loc273))
#loc412 = loc("conv2d_269.dc.transpose.4"(#loc273))
#loc413 = loc("torch.nn.modules.activation.ReLU::act"(#loc274))
#loc414 = loc("conv2d_285.dc.transpose.0"(#loc275))
#loc415 = loc("conv2d_285.dc.transpose.1"(#loc275))
#loc416 = loc("conv2d_285.dc.conv2d.2"(#loc275))
#loc417 = loc("conv2d_285.dc.transpose.3"(#loc275))
#loc418 = loc("conv2d_285.dc.transpose.4"(#loc275))
#loc419 = loc("conv2d_286.dc.transpose.0"(#loc276))
#loc420 = loc("conv2d_286.dc.transpose.1"(#loc276))
#loc421 = loc("conv2d_286.dc.conv2d.2"(#loc276))
#loc422 = loc("conv2d_286.dc.transpose.3"(#loc276))
#loc423 = loc("conv2d_286.dc.transpose.4"(#loc276))
#loc424 = loc("torch.nn.modules.activation.ReLU::act"(#loc277))
#loc425 = loc("relu_316"(#loc283))
#loc426 = loc("relu_342"(#loc297))
#loc427 = loc("conv2d_344.dc.transpose.0"(#loc298))
#loc428 = loc("conv2d_344.dc.transpose.1"(#loc298))
#loc429 = loc("conv2d_344.dc.conv2d.2"(#loc298))
#loc430 = loc("conv2d_344.dc.transpose.3"(#loc298))
#loc431 = loc("conv2d_344.dc.transpose.4"(#loc298))
#loc432 = loc("conv2d_345.dc.transpose.0"(#loc299))
#loc433 = loc("conv2d_345.dc.transpose.1"(#loc299))
#loc434 = loc("conv2d_345.dc.conv2d.2"(#loc299))
#loc435 = loc("conv2d_345.dc.transpose.3"(#loc299))
#loc436 = loc("conv2d_345.dc.transpose.4"(#loc299))
#loc437 = loc("torch.nn.modules.activation.ReLU::act"(#loc300))
#loc438 = loc("conv2d_361.dc.transpose.0"(#loc301))
#loc439 = loc("conv2d_361.dc.transpose.1"(#loc301))
#loc440 = loc("conv2d_361.dc.conv2d.2"(#loc301))
#loc441 = loc("conv2d_361.dc.transpose.3"(#loc301))
#loc442 = loc("conv2d_361.dc.transpose.4"(#loc301))
#loc443 = loc("conv2d_362.dc.transpose.0"(#loc302))
#loc444 = loc("conv2d_362.dc.transpose.1"(#loc302))
#loc445 = loc("conv2d_362.dc.conv2d.2"(#loc302))
#loc446 = loc("conv2d_362.dc.transpose.3"(#loc302))
#loc447 = loc("conv2d_362.dc.transpose.4"(#loc302))
#loc448 = loc("torch.nn.modules.activation.ReLU::act"(#loc303))
#loc449 = loc("conv2d_378.dc.transpose.0"(#loc304))
#loc450 = loc("conv2d_378.dc.transpose.1"(#loc304))
#loc451 = loc("conv2d_378.dc.conv2d.2"(#loc304))
#loc452 = loc("conv2d_378.dc.transpose.3"(#loc304))
#loc453 = loc("conv2d_378.dc.transpose.4"(#loc304))
#loc454 = loc("conv2d_379.dc.transpose.0"(#loc305))
#loc455 = loc("conv2d_379.dc.transpose.1"(#loc305))
#loc456 = loc("conv2d_379.dc.conv2d.2"(#loc305))
#loc457 = loc("conv2d_379.dc.transpose.3"(#loc305))
#loc458 = loc("conv2d_379.dc.transpose.4"(#loc305))
#loc459 = loc("torch.nn.modules.activation.ReLU::act"(#loc306))
#loc460 = loc("relu_409"(#loc312))
#loc461 = loc("relu_80"(#loc332))
#loc462 = loc("relu_97"(#loc343))
#loc463 = loc("relu_114"(#loc354))
#loc464 = loc("relu_173"(#loc367))
#loc465 = loc("relu_190"(#loc378))
#loc466 = loc("relu_207"(#loc389))
#loc467 = loc("relu_266"(#loc402))
#loc468 = loc("relu_283"(#loc413))
#loc469 = loc("relu_300"(#loc424))
#loc470 = loc("relu_359"(#loc437))
#loc471 = loc("relu_376"(#loc448))
#loc472 = loc("relu_393"(#loc459))
